{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# change the seed before anything else\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(7)\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = 101\n",
    "bands = 60\n",
    "feature_size = bands * frames\n",
    "num_channels = 3\n",
    "num_labels = 10\n",
    "data_dir = 'folds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_folds(test_fold):\n",
    "    assert (type(test_fold) == int)\n",
    "    assert (test_fold > 0 and test_fold < 11)\n",
    "    subsequent_fold = False\n",
    "\n",
    "    train_set_range = list(range(1, 11))\n",
    "    train_set_range.remove(test_fold)\n",
    "    valid_fold = train_set_range.pop()\n",
    "\n",
    "    for k in train_set_range:\n",
    "        fold_name = 'fold' + str(k)\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        # flip the spectrogram for each channel\n",
    "        loaded_features = np.transpose(loaded_features, (0, 2, 1, 3))\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print(\"Adding \", fold_name, \"New Features: \", loaded_features.shape)\n",
    "\n",
    "        if subsequent_fold:\n",
    "            train_x_loaded = np.concatenate((train_x_loaded, loaded_features))\n",
    "            train_y_loaded = np.concatenate((train_y_loaded, loaded_labels))\n",
    "        else:\n",
    "            train_x_loaded = loaded_features\n",
    "            train_y_loaded = loaded_labels\n",
    "            subsequent_fold = True\n",
    "\n",
    "    # use the penultimate fold for validation\n",
    "    valid_fold_name = 'fold' + str(valid_fold)\n",
    "    feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "    valid_x = np.load(feature_file)\n",
    "    # flip the spectrogram for each channel\n",
    "    valid_x = np.transpose(valid_x, (0, 2, 1, 3))\n",
    "    valid_y = np.load(labels_file)\n",
    "\n",
    "    # and use the last fold for testing\n",
    "    test_fold_name = 'fold' + str(test_fold)\n",
    "    feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "    test_x = np.load(feature_file)\n",
    "    test_x = np.transpose(test_x, (0, 2, 1, 3))\n",
    "    test_y = np.load(labels_file)\n",
    "    return train_x_loaded, train_y_loaded, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y):\n",
    "    y_prob = model.predict(test_x, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "    y_true = np.argmax(test_y, 1)\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "    print(\"\\nAccuracy = {:.4f}\".format(accuracy))\n",
    "    print(\"\\nError Rate = {:.4f}\".format(1. - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # create model (BASELINE)\n",
    "    visible = Input(shape=(frames, bands, num_channels))\n",
    "    \n",
    "    # 2 conv + 2 pool layers\n",
    "    conv1 = Conv2D(80, kernel_size=(57, 6), strides=(1, 1), activation='relu', kernel_regularizer=l2(0.001))(visible)\n",
    "    dropout1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(4, 3), strides=(1, 3))(conv1) \n",
    "    conv2 =Conv2D(80, kernel_size=(1, 3), strides=(1, 1), activation='relu', kernel_regularizer=l2(0.001))(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(conv2)\n",
    "    # flatten from 4 to only 2 dimensions\n",
    "    flatten = Flatten()(pool2)\n",
    "    # 2 fully connected Layers\n",
    "    fc1 = Dense(5000, activation = \"relu\", kernel_regularizer=l2(0.001))(flatten)\n",
    "    fc1 = Dropout(0.5)(fc1)\n",
    "    fc2 = Dense(5000, activation = \"relu\", kernel_regularizer=l2(0.001))(fc1)\n",
    "    fc2 = Dropout(0.5)(fc2)\n",
    "    # softmax output layer\n",
    "    softmax = Dense(10, activation = \"softmax\", kernel_regularizer=l2(0.001))(fc2)\n",
    "    model = Model(inputs=visible, outputs=softmax)\n",
    "    # print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply scaling factor to a dataset - train, validation or test\n",
    "def do_scale(x4d, verbose = True):\n",
    "    \"\"\"Do scale on the input sequence data.\n",
    "\n",
    "    Args:\n",
    "      x34d: ndarray, input sequence data, shape: (n_clips, n_time, n_freq, channel)      \n",
    "      verbose: boolean\n",
    "\n",
    "    Returns:\n",
    "      Scaled input sequence data.\n",
    "    \"\"\"\n",
    "    t1 = time.time()    \n",
    "    (n_clips, n_time, n_freq, n_channel) = x4d.shape\n",
    "    x4d_scaled = np.zeros(x4d.shape)\n",
    "    for channel in range(n_channel):\n",
    "        x2d = x4d[:,:,:,channel].reshape((n_clips * n_time, n_freq))\n",
    "        x2d_scaled = scaler_list[channel].transform(x2d)\n",
    "        x3d_scaled = x2d_scaled.reshape((n_clips, n_time, n_freq))\n",
    "        x4d_scaled[:,:,:,channel] = x3d_scaled\n",
    "\n",
    "    if verbose == 1:\n",
    "        print(\"Scaling time: %s\" % (time.time() - t1,))\n",
    "\n",
    "    return x4d_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening fold: 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8154292106628418\n",
      "Scaling time: 0.22392773628234863\n",
      "Scaling time: 0.23287320137023926\n",
      "training model...hold tight\n",
      "Train on 7021 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7021/7021 [==============================] - 14s - loss: 15.1289 - acc: 0.1135 - val_loss: 15.0616 - val_acc: 0.1493\n",
      "Epoch 2/150\n",
      "7021/7021 [==============================] - 2s - loss: 15.0643 - acc: 0.1413 - val_loss: 14.9936 - val_acc: 0.1935\n",
      "Epoch 3/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.9989 - acc: 0.1787 - val_loss: 14.9232 - val_acc: 0.1971\n",
      "Epoch 4/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.9411 - acc: 0.1994 - val_loss: 14.8614 - val_acc: 0.2867\n",
      "Epoch 5/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.8873 - acc: 0.2209 - val_loss: 14.8068 - val_acc: 0.2879\n",
      "Epoch 6/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.8351 - acc: 0.2390 - val_loss: 14.7504 - val_acc: 0.3357\n",
      "Epoch 7/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.7893 - acc: 0.2510 - val_loss: 14.7035 - val_acc: 0.2210\n",
      "Epoch 8/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.7405 - acc: 0.2628 - val_loss: 14.6474 - val_acc: 0.3011\n",
      "Epoch 9/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.6800 - acc: 0.2910 - val_loss: 14.6036 - val_acc: 0.2843\n",
      "Epoch 10/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.6417 - acc: 0.2910 - val_loss: 14.5512 - val_acc: 0.3417\n",
      "Epoch 11/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5833 - acc: 0.3163 - val_loss: 14.5176 - val_acc: 0.3584\n",
      "Epoch 12/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5444 - acc: 0.3326 - val_loss: 14.4878 - val_acc: 0.3584\n",
      "Epoch 13/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5162 - acc: 0.3363 - val_loss: 14.4592 - val_acc: 0.3345\n",
      "Epoch 14/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.4685 - acc: 0.3696 - val_loss: 14.4526 - val_acc: 0.4158\n",
      "Epoch 15/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.4431 - acc: 0.3763 - val_loss: 14.5164 - val_acc: 0.2772\n",
      "Epoch 16/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.4474 - acc: 0.3639 - val_loss: 14.4069 - val_acc: 0.4038\n",
      "Epoch 17/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3881 - acc: 0.3972 - val_loss: 14.3654 - val_acc: 0.3536\n",
      "Epoch 18/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3573 - acc: 0.4102 - val_loss: 14.3634 - val_acc: 0.3931\n",
      "Epoch 19/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3270 - acc: 0.4216 - val_loss: 14.3476 - val_acc: 0.3859\n",
      "Epoch 20/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2939 - acc: 0.4264 - val_loss: 14.3177 - val_acc: 0.4265\n",
      "Epoch 21/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2630 - acc: 0.4394 - val_loss: 14.2927 - val_acc: 0.4277\n",
      "Epoch 22/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2510 - acc: 0.4450 - val_loss: 14.3005 - val_acc: 0.3847\n",
      "Epoch 23/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.2198 - acc: 0.4481 - val_loss: 14.2754 - val_acc: 0.3787\n",
      "Epoch 24/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.2034 - acc: 0.4498 - val_loss: 14.2833 - val_acc: 0.3417\n",
      "Epoch 25/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.1794 - acc: 0.4673 - val_loss: 14.3052 - val_acc: 0.4409\n",
      "Epoch 26/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.1815 - acc: 0.4555 - val_loss: 14.2421 - val_acc: 0.4170\n",
      "Epoch 27/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.1495 - acc: 0.4682 - val_loss: 14.2274 - val_acc: 0.3787\n",
      "Epoch 28/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.1304 - acc: 0.4788 - val_loss: 14.2272 - val_acc: 0.4552\n",
      "Epoch 29/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.1107 - acc: 0.4818 - val_loss: 14.2223 - val_acc: 0.3799\n",
      "Epoch 30/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0950 - acc: 0.4854 - val_loss: 14.2097 - val_acc: 0.3907\n",
      "Epoch 31/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0831 - acc: 0.4882 - val_loss: 14.2019 - val_acc: 0.4134\n",
      "Epoch 32/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.0563 - acc: 0.4968 - val_loss: 14.1852 - val_acc: 0.4349\n",
      "Epoch 33/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.0482 - acc: 0.4938 - val_loss: 14.1724 - val_acc: 0.4349\n",
      "Epoch 34/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.0310 - acc: 0.4962 - val_loss: 14.2000 - val_acc: 0.4492\n",
      "Epoch 35/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.0121 - acc: 0.5073 - val_loss: 14.1544 - val_acc: 0.4361\n",
      "Epoch 36/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9976 - acc: 0.5129 - val_loss: 14.1824 - val_acc: 0.4421\n",
      "Epoch 37/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9905 - acc: 0.5109 - val_loss: 14.1712 - val_acc: 0.4468\n",
      "Epoch 38/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9908 - acc: 0.5016 - val_loss: 14.1518 - val_acc: 0.4158\n",
      "Epoch 39/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9589 - acc: 0.5209 - val_loss: 14.1398 - val_acc: 0.4432\n",
      "Epoch 40/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9513 - acc: 0.5140 - val_loss: 14.1172 - val_acc: 0.4480\n",
      "Epoch 41/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9323 - acc: 0.5267 - val_loss: 14.1130 - val_acc: 0.4624\n",
      "Epoch 42/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9244 - acc: 0.5251 - val_loss: 14.1065 - val_acc: 0.4444\n",
      "Epoch 43/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9079 - acc: 0.5313 - val_loss: 14.0998 - val_acc: 0.4516\n",
      "Epoch 44/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8994 - acc: 0.5324 - val_loss: 14.1618 - val_acc: 0.4026\n",
      "Epoch 45/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8879 - acc: 0.5395 - val_loss: 14.0904 - val_acc: 0.4946\n",
      "Epoch 46/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8856 - acc: 0.5351 - val_loss: 14.0919 - val_acc: 0.4994\n",
      "Epoch 47/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.8617 - acc: 0.5367 - val_loss: 14.1333 - val_acc: 0.4409\n",
      "Epoch 48/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.8518 - acc: 0.5462 - val_loss: 14.0955 - val_acc: 0.4397\n",
      "Epoch 49/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8458 - acc: 0.5485 - val_loss: 14.0872 - val_acc: 0.4576\n",
      "Epoch 50/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8322 - acc: 0.5532 - val_loss: 14.1776 - val_acc: 0.4707\n",
      "Epoch 51/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8226 - acc: 0.5513 - val_loss: 14.0571 - val_acc: 0.4767\n",
      "Epoch 52/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8137 - acc: 0.5539 - val_loss: 14.0696 - val_acc: 0.4265\n",
      "Epoch 53/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.8123 - acc: 0.5519 - val_loss: 14.0826 - val_acc: 0.4540\n",
      "Epoch 54/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8017 - acc: 0.5660 - val_loss: 14.0574 - val_acc: 0.4432\n",
      "Epoch 55/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7781 - acc: 0.5644 - val_loss: 14.0626 - val_acc: 0.4385\n",
      "Epoch 56/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7714 - acc: 0.5643 - val_loss: 14.0261 - val_acc: 0.4468\n",
      "Epoch 57/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.7507 - acc: 0.5756 - val_loss: 14.0316 - val_acc: 0.4576\n",
      "Epoch 58/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.7471 - acc: 0.5761 - val_loss: 14.0093 - val_acc: 0.5018\n",
      "Epoch 59/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7379 - acc: 0.5778 - val_loss: 13.9925 - val_acc: 0.4815\n",
      "Epoch 60/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.7227 - acc: 0.5808 - val_loss: 14.0352 - val_acc: 0.4385\n",
      "Epoch 61/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7174 - acc: 0.5814 - val_loss: 14.1029 - val_acc: 0.4994\n",
      "Epoch 62/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7035 - acc: 0.5818 - val_loss: 14.0158 - val_acc: 0.4421\n",
      "Epoch 63/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.7087 - acc: 0.5777 - val_loss: 14.0086 - val_acc: 0.4648\n",
      "Epoch 64/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6780 - acc: 0.5860 - val_loss: 14.0676 - val_acc: 0.4194\n",
      "Epoch 65/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6803 - acc: 0.5805 - val_loss: 14.0513 - val_acc: 0.4468\n",
      "Epoch 66/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6629 - acc: 0.5909 - val_loss: 14.0917 - val_acc: 0.4719\n",
      "Epoch 67/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6630 - acc: 0.5907 - val_loss: 13.9794 - val_acc: 0.4289\n",
      "Epoch 68/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6521 - acc: 0.5862 - val_loss: 13.9761 - val_acc: 0.4576\n",
      "Epoch 69/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6522 - acc: 0.5912 - val_loss: 14.2793 - val_acc: 0.3931\n",
      "Epoch 70/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6643 - acc: 0.5848 - val_loss: 13.9463 - val_acc: 0.4576\n",
      "Epoch 71/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6197 - acc: 0.6075 - val_loss: 13.9409 - val_acc: 0.4588\n",
      "Epoch 72/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6195 - acc: 0.5968 - val_loss: 13.9575 - val_acc: 0.4958\n",
      "Epoch 73/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6062 - acc: 0.6015 - val_loss: 13.9620 - val_acc: 0.4624\n",
      "Epoch 74/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5994 - acc: 0.6072 - val_loss: 13.9225 - val_acc: 0.5317\n",
      "Epoch 75/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5803 - acc: 0.6095 - val_loss: 13.9035 - val_acc: 0.4385\n",
      "Epoch 76/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.5772 - acc: 0.6093 - val_loss: 13.8975 - val_acc: 0.4612\n",
      "Epoch 77/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5502 - acc: 0.6221 - val_loss: 13.8803 - val_acc: 0.4731\n",
      "Epoch 78/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5508 - acc: 0.6180 - val_loss: 13.8969 - val_acc: 0.4863\n",
      "Epoch 79/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5388 - acc: 0.6241 - val_loss: 13.9035 - val_acc: 0.4767\n",
      "Epoch 80/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5281 - acc: 0.6243 - val_loss: 13.9553 - val_acc: 0.4803\n",
      "Epoch 81/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5437 - acc: 0.6211 - val_loss: 13.8607 - val_acc: 0.5221\n",
      "Epoch 82/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5151 - acc: 0.6287 - val_loss: 13.8832 - val_acc: 0.4815\n",
      "Epoch 83/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4922 - acc: 0.6398 - val_loss: 13.8888 - val_acc: 0.5018\n",
      "Epoch 84/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4957 - acc: 0.6327 - val_loss: 13.8601 - val_acc: 0.5364\n",
      "Epoch 85/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4814 - acc: 0.6367 - val_loss: 13.9200 - val_acc: 0.4922\n",
      "Epoch 86/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.4770 - acc: 0.6432 - val_loss: 13.8395 - val_acc: 0.5197\n",
      "Epoch 87/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4588 - acc: 0.6522 - val_loss: 13.8451 - val_acc: 0.4970\n",
      "Epoch 88/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4590 - acc: 0.6394 - val_loss: 13.8382 - val_acc: 0.4552\n",
      "Epoch 89/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4547 - acc: 0.6404 - val_loss: 13.8340 - val_acc: 0.5114\n",
      "Epoch 90/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4351 - acc: 0.6522 - val_loss: 13.9472 - val_acc: 0.5137\n",
      "Epoch 91/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4393 - acc: 0.6479 - val_loss: 13.8575 - val_acc: 0.5341\n",
      "Epoch 92/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.4230 - acc: 0.6510 - val_loss: 13.8432 - val_acc: 0.4767\n",
      "Epoch 93/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4192 - acc: 0.6545 - val_loss: 13.8238 - val_acc: 0.5687\n",
      "Epoch 94/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4056 - acc: 0.6577 - val_loss: 13.8875 - val_acc: 0.5556\n",
      "Epoch 95/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3972 - acc: 0.6614 - val_loss: 13.8998 - val_acc: 0.5388\n",
      "Epoch 96/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4118 - acc: 0.6520 - val_loss: 13.8000 - val_acc: 0.5066\n",
      "Epoch 97/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3700 - acc: 0.6716 - val_loss: 13.8035 - val_acc: 0.5615\n",
      "Epoch 98/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3648 - acc: 0.6666 - val_loss: 13.9345 - val_acc: 0.5054\n",
      "Epoch 99/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3798 - acc: 0.6553 - val_loss: 13.7989 - val_acc: 0.5137\n",
      "Epoch 100/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.3510 - acc: 0.6718 - val_loss: 13.9016 - val_acc: 0.5376\n",
      "Epoch 101/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3480 - acc: 0.6669 - val_loss: 13.8094 - val_acc: 0.5472\n",
      "Epoch 102/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3332 - acc: 0.6724 - val_loss: 13.7866 - val_acc: 0.5627\n",
      "Epoch 103/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.3165 - acc: 0.6808 - val_loss: 13.7841 - val_acc: 0.4803\n",
      "Epoch 104/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3106 - acc: 0.6710 - val_loss: 13.7829 - val_acc: 0.5412\n",
      "Epoch 105/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3111 - acc: 0.6787 - val_loss: 13.7789 - val_acc: 0.5137\n",
      "Epoch 106/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3015 - acc: 0.6750 - val_loss: 13.9674 - val_acc: 0.5006\n",
      "Epoch 107/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3213 - acc: 0.6773 - val_loss: 13.7353 - val_acc: 0.5795\n",
      "Epoch 108/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2815 - acc: 0.6792 - val_loss: 13.7571 - val_acc: 0.5329\n",
      "Epoch 109/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.2653 - acc: 0.6882 - val_loss: 13.7778 - val_acc: 0.4994\n",
      "Epoch 110/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2687 - acc: 0.6898 - val_loss: 13.8052 - val_acc: 0.4958\n",
      "Epoch 111/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2698 - acc: 0.6814 - val_loss: 13.8286 - val_acc: 0.5520\n",
      "Epoch 112/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.2646 - acc: 0.6837 - val_loss: 13.7334 - val_acc: 0.5818\n",
      "Epoch 113/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2301 - acc: 0.6980 - val_loss: 13.7803 - val_acc: 0.5556\n",
      "Epoch 114/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2433 - acc: 0.6918 - val_loss: 13.7291 - val_acc: 0.5771\n",
      "Epoch 115/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2203 - acc: 0.6995 - val_loss: 13.7109 - val_acc: 0.5806\n",
      "Epoch 116/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.2202 - acc: 0.6972 - val_loss: 13.7001 - val_acc: 0.5651\n",
      "Epoch 117/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2031 - acc: 0.6968 - val_loss: 13.6653 - val_acc: 0.6201\n",
      "Epoch 118/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1956 - acc: 0.7009 - val_loss: 13.6761 - val_acc: 0.5842\n",
      "Epoch 119/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1905 - acc: 0.7053 - val_loss: 13.7361 - val_acc: 0.5496\n",
      "Epoch 120/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1917 - acc: 0.6975 - val_loss: 13.6813 - val_acc: 0.5448\n",
      "Epoch 121/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1653 - acc: 0.7114 - val_loss: 13.7242 - val_acc: 0.5436\n",
      "Epoch 122/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1721 - acc: 0.7100 - val_loss: 13.6814 - val_acc: 0.5508\n",
      "Epoch 123/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1637 - acc: 0.7084 - val_loss: 13.9088 - val_acc: 0.5233\n",
      "Epoch 124/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1850 - acc: 0.7030 - val_loss: 13.6622 - val_acc: 0.5603\n",
      "Epoch 125/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1422 - acc: 0.7100 - val_loss: 13.6268 - val_acc: 0.5950\n",
      "Epoch 126/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1414 - acc: 0.7129 - val_loss: 13.6340 - val_acc: 0.5723\n",
      "Epoch 127/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1301 - acc: 0.7168 - val_loss: 13.6854 - val_acc: 0.6069\n",
      "Epoch 128/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1145 - acc: 0.7230 - val_loss: 13.6493 - val_acc: 0.5424\n",
      "Epoch 129/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1259 - acc: 0.7140 - val_loss: 13.7852 - val_acc: 0.4886\n",
      "Epoch 130/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1326 - acc: 0.7141 - val_loss: 13.6788 - val_acc: 0.5484\n",
      "Epoch 131/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1023 - acc: 0.7230 - val_loss: 13.8988 - val_acc: 0.5639\n",
      "Epoch 132/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1286 - acc: 0.7131 - val_loss: 13.6730 - val_acc: 0.5185\n",
      "Epoch 133/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0934 - acc: 0.7200 - val_loss: 13.6145 - val_acc: 0.5854\n",
      "Epoch 134/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0674 - acc: 0.7328 - val_loss: 13.6261 - val_acc: 0.5125\n",
      "Epoch 135/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0677 - acc: 0.7275 - val_loss: 13.6076 - val_acc: 0.5890\n",
      "Epoch 136/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0626 - acc: 0.7357 - val_loss: 13.6005 - val_acc: 0.5532\n",
      "Epoch 137/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0591 - acc: 0.7287 - val_loss: 13.6020 - val_acc: 0.5532\n",
      "Epoch 138/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0473 - acc: 0.7361 - val_loss: 13.5829 - val_acc: 0.5974\n",
      "Epoch 139/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.0286 - acc: 0.7364 - val_loss: 13.6046 - val_acc: 0.5986\n",
      "Epoch 140/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0191 - acc: 0.7399 - val_loss: 13.6570 - val_acc: 0.5508\n",
      "Epoch 141/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0299 - acc: 0.7308 - val_loss: 13.6540 - val_acc: 0.6093\n",
      "Epoch 142/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0121 - acc: 0.7386 - val_loss: 13.5791 - val_acc: 0.6237\n",
      "Epoch 143/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0143 - acc: 0.7352 - val_loss: 13.6517 - val_acc: 0.5161\n",
      "Epoch 144/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.0244 - acc: 0.7223 - val_loss: 13.6158 - val_acc: 0.5579\n",
      "Epoch 145/150\n",
      "7021/7021 [==============================] - 2s - loss: 12.9905 - acc: 0.7419 - val_loss: 13.7942 - val_acc: 0.5508\n",
      "Epoch 146/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0088 - acc: 0.7342 - val_loss: 13.5855 - val_acc: 0.6057\n",
      "Epoch 147/150\n",
      "7021/7021 [==============================] - 3s - loss: 12.9749 - acc: 0.7411 - val_loss: 13.7794 - val_acc: 0.5615\n",
      "Epoch 148/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.0268 - acc: 0.7258 - val_loss: 13.6163 - val_acc: 0.5938\n",
      "Epoch 149/150\n",
      "7021/7021 [==============================] - 3s - loss: 12.9674 - acc: 0.7489 - val_loss: 13.5934 - val_acc: 0.6129\n",
      "Epoch 150/150\n",
      "7021/7021 [==============================] - 3s - loss: 12.9642 - acc: 0.7422 - val_loss: 13.5644 - val_acc: 0.6045\n",
      "training time: 463.63500213623047\n",
      "800/869 [==========================>...] - ETA: 0s\n",
      "Accuracy = 0.6513\n",
      "\n",
      "Error Rate = 0.3487\n",
      "training time: 0.7152454853057861\n",
      "opening fold: 2\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8193252086639404\n",
      "Scaling time: 0.2228703498840332\n",
      "Scaling time: 0.23669099807739258\n",
      "training model...hold tight\n",
      "Train on 7003 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7003/7003 [==============================] - 9s - loss: 15.1266 - acc: 0.1087 - val_loss: 15.0386 - val_acc: 0.1302\n",
      "Epoch 2/150\n",
      "7003/7003 [==============================] - 2s - loss: 15.0519 - acc: 0.1534 - val_loss: 14.9663 - val_acc: 0.2186\n",
      "Epoch 3/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.9884 - acc: 0.1925 - val_loss: 14.9272 - val_acc: 0.1840\n",
      "Epoch 4/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.9631 - acc: 0.2019 - val_loss: 14.8539 - val_acc: 0.2246\n",
      "Epoch 5/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.8768 - acc: 0.2133 - val_loss: 14.8098 - val_acc: 0.2605\n",
      "Epoch 6/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.8373 - acc: 0.2052 - val_loss: 14.7559 - val_acc: 0.1768\n",
      "Epoch 7/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7846 - acc: 0.2392 - val_loss: 14.6823 - val_acc: 0.2772\n",
      "Epoch 8/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7187 - acc: 0.2677 - val_loss: 14.6497 - val_acc: 0.2270\n",
      "Epoch 9/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.7085 - acc: 0.2488 - val_loss: 14.6115 - val_acc: 0.2736\n",
      "Epoch 10/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.6837 - acc: 0.2837 - val_loss: 14.6045 - val_acc: 0.3274\n",
      "Epoch 11/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.6851 - acc: 0.2657 - val_loss: 14.5874 - val_acc: 0.2784\n",
      "Epoch 12/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.6384 - acc: 0.2984 - val_loss: 14.6014 - val_acc: 0.2843\n",
      "Epoch 13/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.6024 - acc: 0.3087 - val_loss: 14.5039 - val_acc: 0.3883\n",
      "Epoch 14/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5563 - acc: 0.3316 - val_loss: 14.5070 - val_acc: 0.3357\n",
      "Epoch 15/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5468 - acc: 0.3159 - val_loss: 14.4945 - val_acc: 0.3775\n",
      "Epoch 16/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4855 - acc: 0.3570 - val_loss: 14.5474 - val_acc: 0.3118\n",
      "Epoch 17/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.5347 - acc: 0.3239 - val_loss: 14.4638 - val_acc: 0.3142\n",
      "Epoch 18/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.5124 - acc: 0.3401 - val_loss: 14.4706 - val_acc: 0.3668\n",
      "Epoch 19/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5141 - acc: 0.3626 - val_loss: 14.4400 - val_acc: 0.3393\n",
      "Epoch 20/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4762 - acc: 0.3530 - val_loss: 14.4516 - val_acc: 0.3548\n",
      "Epoch 21/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4896 - acc: 0.3700 - val_loss: 14.4411 - val_acc: 0.3990\n",
      "Epoch 22/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4498 - acc: 0.3656 - val_loss: 14.4623 - val_acc: 0.3130\n",
      "Epoch 23/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4554 - acc: 0.3717 - val_loss: 14.4625 - val_acc: 0.3584\n",
      "Epoch 24/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3975 - acc: 0.3806 - val_loss: 14.3996 - val_acc: 0.2891\n",
      "Epoch 25/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3832 - acc: 0.3938 - val_loss: 14.3159 - val_acc: 0.4098\n",
      "Epoch 26/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3059 - acc: 0.4208 - val_loss: 14.3708 - val_acc: 0.3477\n",
      "Epoch 27/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2878 - acc: 0.4367 - val_loss: 14.2944 - val_acc: 0.4456\n",
      "Epoch 28/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.2417 - acc: 0.4360 - val_loss: 14.2749 - val_acc: 0.4552\n",
      "Epoch 29/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.2347 - acc: 0.4328 - val_loss: 14.3339 - val_acc: 0.4050\n",
      "Epoch 30/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2335 - acc: 0.4328 - val_loss: 14.2675 - val_acc: 0.3907\n",
      "Epoch 31/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2070 - acc: 0.4407 - val_loss: 14.2447 - val_acc: 0.4146\n",
      "Epoch 32/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1825 - acc: 0.4494 - val_loss: 14.2400 - val_acc: 0.4516\n",
      "Epoch 33/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1973 - acc: 0.4460 - val_loss: 14.4074 - val_acc: 0.2927\n",
      "Epoch 34/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2605 - acc: 0.4054 - val_loss: 14.2928 - val_acc: 0.4385\n",
      "Epoch 35/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.2227 - acc: 0.4185 - val_loss: 14.2803 - val_acc: 0.4253\n",
      "Epoch 36/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1613 - acc: 0.4524 - val_loss: 14.2799 - val_acc: 0.4217\n",
      "Epoch 37/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1381 - acc: 0.4432 - val_loss: 14.1897 - val_acc: 0.4755\n",
      "Epoch 38/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1212 - acc: 0.4587 - val_loss: 14.1337 - val_acc: 0.4719\n",
      "Epoch 39/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0583 - acc: 0.4755 - val_loss: 14.1479 - val_acc: 0.4086\n",
      "Epoch 40/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0498 - acc: 0.4878 - val_loss: 14.1606 - val_acc: 0.4552\n",
      "Epoch 41/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0269 - acc: 0.4856 - val_loss: 14.1290 - val_acc: 0.5090\n",
      "Epoch 42/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0166 - acc: 0.4886 - val_loss: 14.6961 - val_acc: 0.3142\n",
      "Epoch 43/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0663 - acc: 0.4859 - val_loss: 14.2936 - val_acc: 0.4002\n",
      "Epoch 44/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0937 - acc: 0.4874 - val_loss: 14.1730 - val_acc: 0.4205\n",
      "Epoch 45/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0227 - acc: 0.4922 - val_loss: 14.1248 - val_acc: 0.4743\n",
      "Epoch 46/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9685 - acc: 0.4982 - val_loss: 14.1412 - val_acc: 0.4588\n",
      "Epoch 47/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.9614 - acc: 0.5012 - val_loss: 14.1067 - val_acc: 0.4970\n",
      "Epoch 48/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9319 - acc: 0.5156 - val_loss: 14.1423 - val_acc: 0.4851\n",
      "Epoch 49/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9778 - acc: 0.4892 - val_loss: 14.0846 - val_acc: 0.4612\n",
      "Epoch 50/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9250 - acc: 0.5092 - val_loss: 14.0813 - val_acc: 0.4397\n",
      "Epoch 51/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9115 - acc: 0.5225 - val_loss: 14.0280 - val_acc: 0.4683\n",
      "Epoch 52/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9018 - acc: 0.5223 - val_loss: 14.1067 - val_acc: 0.4576\n",
      "Epoch 53/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9024 - acc: 0.5171 - val_loss: 15.3743 - val_acc: 0.3214\n",
      "Epoch 54/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0398 - acc: 0.4968 - val_loss: 14.1117 - val_acc: 0.4229\n",
      "Epoch 55/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9245 - acc: 0.5221 - val_loss: 14.0644 - val_acc: 0.4958\n",
      "Epoch 56/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.8872 - acc: 0.5059 - val_loss: 14.1247 - val_acc: 0.5245\n",
      "Epoch 57/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8987 - acc: 0.5121 - val_loss: 14.1364 - val_acc: 0.4146\n",
      "Epoch 58/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8872 - acc: 0.5105 - val_loss: 14.0935 - val_acc: 0.4671\n",
      "Epoch 59/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8983 - acc: 0.5028 - val_loss: 14.1482 - val_acc: 0.4110\n",
      "Epoch 60/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8862 - acc: 0.5106 - val_loss: 14.0016 - val_acc: 0.4779\n",
      "Epoch 61/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8494 - acc: 0.5303 - val_loss: 14.4471 - val_acc: 0.3632\n",
      "Epoch 62/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1565 - acc: 0.4628 - val_loss: 14.1712 - val_acc: 0.3608\n",
      "Epoch 63/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9475 - acc: 0.4891 - val_loss: 14.1133 - val_acc: 0.3823\n",
      "Epoch 64/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.8742 - acc: 0.5291 - val_loss: 14.0531 - val_acc: 0.5090\n",
      "Epoch 65/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.8499 - acc: 0.5238 - val_loss: 14.1088 - val_acc: 0.4827\n",
      "Epoch 66/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8520 - acc: 0.5206 - val_loss: 14.0977 - val_acc: 0.4397\n",
      "Epoch 67/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8354 - acc: 0.5195 - val_loss: 14.1489 - val_acc: 0.4098\n",
      "Epoch 68/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8204 - acc: 0.5409 - val_loss: 15.8843 - val_acc: 0.2915\n",
      "Epoch 69/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1635 - acc: 0.4632 - val_loss: 14.1598 - val_acc: 0.4385\n",
      "Epoch 70/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9203 - acc: 0.5012 - val_loss: 14.0974 - val_acc: 0.4182\n",
      "Epoch 71/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8581 - acc: 0.5222 - val_loss: 13.9984 - val_acc: 0.5412\n",
      "Epoch 72/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8419 - acc: 0.5086 - val_loss: 13.9955 - val_acc: 0.5424\n",
      "Epoch 73/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7925 - acc: 0.5349 - val_loss: 13.9793 - val_acc: 0.5042\n",
      "Epoch 74/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7608 - acc: 0.5321 - val_loss: 13.9990 - val_acc: 0.4301\n",
      "Epoch 75/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.7407 - acc: 0.5433 - val_loss: 14.0222 - val_acc: 0.4456\n",
      "Epoch 76/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.7194 - acc: 0.5503 - val_loss: 14.0002 - val_acc: 0.4946\n",
      "Epoch 77/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7211 - acc: 0.5479 - val_loss: 13.9730 - val_acc: 0.4934\n",
      "Epoch 78/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6892 - acc: 0.5662 - val_loss: 14.0481 - val_acc: 0.4875\n",
      "Epoch 79/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6927 - acc: 0.5606 - val_loss: 14.0619 - val_acc: 0.4122\n",
      "Epoch 80/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7394 - acc: 0.5465 - val_loss: 14.0376 - val_acc: 0.4600\n",
      "Epoch 81/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6874 - acc: 0.5753 - val_loss: 13.9844 - val_acc: 0.5508\n",
      "Epoch 82/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6535 - acc: 0.5740 - val_loss: 15.1802 - val_acc: 0.3214\n",
      "Epoch 83/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.9026 - acc: 0.5165 - val_loss: 14.0230 - val_acc: 0.4600\n",
      "Epoch 84/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7428 - acc: 0.5455 - val_loss: 14.0056 - val_acc: 0.4397\n",
      "Epoch 85/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6851 - acc: 0.5618 - val_loss: 13.9423 - val_acc: 0.4982\n",
      "Epoch 86/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6929 - acc: 0.5558 - val_loss: 14.0785 - val_acc: 0.4265\n",
      "Epoch 87/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7441 - acc: 0.5398 - val_loss: 14.0022 - val_acc: 0.4241\n",
      "Epoch 88/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6445 - acc: 0.5679 - val_loss: 14.1101 - val_acc: 0.4444\n",
      "Epoch 89/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6506 - acc: 0.5668 - val_loss: 13.8999 - val_acc: 0.5233\n",
      "Epoch 90/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6095 - acc: 0.5829 - val_loss: 13.9137 - val_acc: 0.5472\n",
      "Epoch 91/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6567 - acc: 0.5475 - val_loss: 14.0116 - val_acc: 0.4528\n",
      "Epoch 92/150\n",
      "7003/7003 [==============================] - 4s - loss: 13.6749 - acc: 0.5598 - val_loss: 13.9188 - val_acc: 0.4839\n",
      "Epoch 93/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5785 - acc: 0.5837 - val_loss: 13.9931 - val_acc: 0.4731\n",
      "Epoch 94/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5977 - acc: 0.5850 - val_loss: 14.3172 - val_acc: 0.3740\n",
      "Epoch 95/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6361 - acc: 0.5828 - val_loss: 13.8635 - val_acc: 0.5568\n",
      "Epoch 96/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5566 - acc: 0.5925 - val_loss: 13.8922 - val_acc: 0.5544\n",
      "Epoch 97/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.5389 - acc: 0.6103 - val_loss: 13.9175 - val_acc: 0.5030\n",
      "Epoch 98/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.6002 - acc: 0.5835 - val_loss: 13.8711 - val_acc: 0.5245\n",
      "Epoch 99/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5533 - acc: 0.5876 - val_loss: 13.8484 - val_acc: 0.5197\n",
      "Epoch 100/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5214 - acc: 0.5979 - val_loss: 13.8535 - val_acc: 0.5125\n",
      "Epoch 101/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5096 - acc: 0.6040 - val_loss: 13.8843 - val_acc: 0.5305\n",
      "Epoch 102/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5233 - acc: 0.5977 - val_loss: 13.8405 - val_acc: 0.5030\n",
      "Epoch 103/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4690 - acc: 0.6213 - val_loss: 13.8372 - val_acc: 0.4863\n",
      "Epoch 104/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4663 - acc: 0.6160 - val_loss: 13.8843 - val_acc: 0.5078\n",
      "Epoch 105/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5417 - acc: 0.5933 - val_loss: 13.8313 - val_acc: 0.5400\n",
      "Epoch 106/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4806 - acc: 0.6020 - val_loss: 13.8130 - val_acc: 0.5173\n",
      "Epoch 107/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.4431 - acc: 0.6273 - val_loss: 13.8100 - val_acc: 0.5376\n",
      "Epoch 108/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4932 - acc: 0.6013 - val_loss: 13.8125 - val_acc: 0.5066\n",
      "Epoch 109/150\n",
      "7003/7003 [==============================] - 4s - loss: 13.4295 - acc: 0.6239 - val_loss: 13.7996 - val_acc: 0.5209\n",
      "Epoch 110/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4297 - acc: 0.6310 - val_loss: 13.8718 - val_acc: 0.4779\n",
      "Epoch 111/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.4839 - acc: 0.5939 - val_loss: 13.8251 - val_acc: 0.4910\n",
      "Epoch 112/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4121 - acc: 0.6230 - val_loss: 13.7778 - val_acc: 0.5388\n",
      "Epoch 113/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3914 - acc: 0.6307 - val_loss: 13.8321 - val_acc: 0.4791\n",
      "Epoch 114/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3975 - acc: 0.6339 - val_loss: 13.7944 - val_acc: 0.5149\n",
      "Epoch 115/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3824 - acc: 0.6336 - val_loss: 14.3541 - val_acc: 0.3644\n",
      "Epoch 116/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4890 - acc: 0.6115 - val_loss: 13.7889 - val_acc: 0.4827\n",
      "Epoch 117/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3729 - acc: 0.6337 - val_loss: 13.8022 - val_acc: 0.5042\n",
      "Epoch 118/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3955 - acc: 0.6234 - val_loss: 13.8229 - val_acc: 0.5125\n",
      "Epoch 119/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3826 - acc: 0.6222 - val_loss: 13.8718 - val_acc: 0.4827\n",
      "Epoch 120/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3742 - acc: 0.6283 - val_loss: 13.7535 - val_acc: 0.5388\n",
      "Epoch 121/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3562 - acc: 0.6322 - val_loss: 14.1727 - val_acc: 0.3823\n",
      "Epoch 122/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5008 - acc: 0.5886 - val_loss: 13.8512 - val_acc: 0.4301\n",
      "Epoch 123/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.3891 - acc: 0.6136 - val_loss: 13.7136 - val_acc: 0.5376\n",
      "Epoch 124/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3460 - acc: 0.6270 - val_loss: 13.7185 - val_acc: 0.5125\n",
      "Epoch 125/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3265 - acc: 0.6379 - val_loss: 13.7328 - val_acc: 0.4815\n",
      "Epoch 126/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2929 - acc: 0.6541 - val_loss: 13.6855 - val_acc: 0.5197\n",
      "Epoch 127/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2709 - acc: 0.6641 - val_loss: 13.6776 - val_acc: 0.5472\n",
      "Epoch 128/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2553 - acc: 0.6630 - val_loss: 13.7636 - val_acc: 0.5448\n",
      "Epoch 129/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3645 - acc: 0.6100 - val_loss: 13.7676 - val_acc: 0.4528\n",
      "Epoch 130/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4218 - acc: 0.6079 - val_loss: 13.7874 - val_acc: 0.4731\n",
      "Epoch 131/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3151 - acc: 0.6396 - val_loss: 13.7534 - val_acc: 0.4731\n",
      "Epoch 132/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2677 - acc: 0.6519 - val_loss: 13.7628 - val_acc: 0.4659\n",
      "Epoch 133/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2821 - acc: 0.6379 - val_loss: 13.7695 - val_acc: 0.4516\n",
      "Epoch 134/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3003 - acc: 0.6362 - val_loss: 13.6612 - val_acc: 0.5018\n",
      "Epoch 135/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2643 - acc: 0.6520 - val_loss: 13.6868 - val_acc: 0.4982\n",
      "Epoch 136/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2417 - acc: 0.6564 - val_loss: 13.6950 - val_acc: 0.4958\n",
      "Epoch 137/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2150 - acc: 0.6609 - val_loss: 13.7274 - val_acc: 0.4564\n",
      "Epoch 138/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2362 - acc: 0.6440 - val_loss: 13.6824 - val_acc: 0.5078\n",
      "Epoch 139/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1955 - acc: 0.6646 - val_loss: 13.6535 - val_acc: 0.5305\n",
      "Epoch 140/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1778 - acc: 0.6780 - val_loss: 13.7944 - val_acc: 0.4803\n",
      "Epoch 141/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2435 - acc: 0.6569 - val_loss: 13.7314 - val_acc: 0.5233\n",
      "Epoch 142/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2768 - acc: 0.6287 - val_loss: 13.7297 - val_acc: 0.4851\n",
      "Epoch 143/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2315 - acc: 0.6499 - val_loss: 13.7525 - val_acc: 0.4612\n",
      "Epoch 144/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1987 - acc: 0.6674 - val_loss: 13.7028 - val_acc: 0.4970\n",
      "Epoch 145/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2693 - acc: 0.6369 - val_loss: 13.6096 - val_acc: 0.5281\n",
      "Epoch 146/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.1758 - acc: 0.6686 - val_loss: 13.6943 - val_acc: 0.4731\n",
      "Epoch 147/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1709 - acc: 0.6724 - val_loss: 13.6767 - val_acc: 0.5197\n",
      "Epoch 148/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1446 - acc: 0.6796 - val_loss: 13.6924 - val_acc: 0.5137\n",
      "Epoch 149/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1496 - acc: 0.6713 - val_loss: 13.7945 - val_acc: 0.4731\n",
      "Epoch 150/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.1365 - acc: 0.6881 - val_loss: 15.6306 - val_acc: 0.3250\n",
      "training time: 473.44097232818604\n",
      "800/887 [==========================>...] - ETA: 0s\n",
      "Accuracy = 0.3596\n",
      "\n",
      "Error Rate = 0.6404\n",
      "training time: 0.6791071891784668\n",
      "opening fold: 3\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8209853172302246\n",
      "Scaling time: 0.22464847564697266\n",
      "Scaling time: 0.2487022876739502\n",
      "training model...hold tight\n",
      "Train on 6965 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "6965/6965 [==============================] - 10s - loss: 15.1318 - acc: 0.1153 - val_loss: 15.0610 - val_acc: 0.1601\n",
      "Epoch 2/150\n",
      "6965/6965 [==============================] - 2s - loss: 15.0605 - acc: 0.1464 - val_loss: 14.9895 - val_acc: 0.1816\n",
      "Epoch 3/150\n",
      "6965/6965 [==============================] - 2s - loss: 15.0012 - acc: 0.1734 - val_loss: 14.9247 - val_acc: 0.1971\n",
      "Epoch 4/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.9365 - acc: 0.2017 - val_loss: 14.8630 - val_acc: 0.2091\n",
      "Epoch 5/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.8810 - acc: 0.2283 - val_loss: 14.8059 - val_acc: 0.2485\n",
      "Epoch 6/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.8251 - acc: 0.2498 - val_loss: 14.7501 - val_acc: 0.2808\n",
      "Epoch 7/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.7733 - acc: 0.2665 - val_loss: 14.6949 - val_acc: 0.2832\n",
      "Epoch 8/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.7323 - acc: 0.2782 - val_loss: 14.6439 - val_acc: 0.2843\n",
      "Epoch 9/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.6733 - acc: 0.2985 - val_loss: 14.5953 - val_acc: 0.2903\n",
      "Epoch 10/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.6227 - acc: 0.3057 - val_loss: 14.5529 - val_acc: 0.2951\n",
      "Epoch 11/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.5865 - acc: 0.3207 - val_loss: 14.5126 - val_acc: 0.3274\n",
      "Epoch 12/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.5467 - acc: 0.3268 - val_loss: 14.4818 - val_acc: 0.3190\n",
      "Epoch 13/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.5047 - acc: 0.3410 - val_loss: 14.4520 - val_acc: 0.3393\n",
      "Epoch 14/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.4673 - acc: 0.3651 - val_loss: 14.4247 - val_acc: 0.3381\n",
      "Epoch 15/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.4317 - acc: 0.3818 - val_loss: 14.4025 - val_acc: 0.3489\n",
      "Epoch 16/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.3961 - acc: 0.4011 - val_loss: 14.3757 - val_acc: 0.3895\n",
      "Epoch 17/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.3668 - acc: 0.4083 - val_loss: 14.3595 - val_acc: 0.3668\n",
      "Epoch 18/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.3342 - acc: 0.4197 - val_loss: 14.3332 - val_acc: 0.3596\n",
      "Epoch 19/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.3113 - acc: 0.4281 - val_loss: 14.3150 - val_acc: 0.3716\n",
      "Epoch 20/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2758 - acc: 0.4491 - val_loss: 14.2962 - val_acc: 0.3835\n",
      "Epoch 21/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2443 - acc: 0.4491 - val_loss: 14.2774 - val_acc: 0.3811\n",
      "Epoch 22/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2300 - acc: 0.4504 - val_loss: 14.2631 - val_acc: 0.4074\n",
      "Epoch 23/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2045 - acc: 0.4615 - val_loss: 14.2478 - val_acc: 0.3787\n",
      "Epoch 24/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1812 - acc: 0.4686 - val_loss: 14.2416 - val_acc: 0.3704\n",
      "Epoch 25/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1664 - acc: 0.4731 - val_loss: 14.2221 - val_acc: 0.4074\n",
      "Epoch 26/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1375 - acc: 0.4803 - val_loss: 14.2130 - val_acc: 0.3955\n",
      "Epoch 27/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1237 - acc: 0.4797 - val_loss: 14.1985 - val_acc: 0.3883\n",
      "Epoch 28/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0989 - acc: 0.4834 - val_loss: 14.1874 - val_acc: 0.3943\n",
      "Epoch 29/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0921 - acc: 0.4884 - val_loss: 14.1753 - val_acc: 0.4217\n",
      "Epoch 30/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0671 - acc: 0.4899 - val_loss: 14.1724 - val_acc: 0.4194\n",
      "Epoch 31/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0521 - acc: 0.4989 - val_loss: 14.1630 - val_acc: 0.4432\n",
      "Epoch 32/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.0328 - acc: 0.5052 - val_loss: 14.1561 - val_acc: 0.4289\n",
      "Epoch 33/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0237 - acc: 0.5070 - val_loss: 14.1480 - val_acc: 0.4170\n",
      "Epoch 34/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.0099 - acc: 0.5154 - val_loss: 14.1393 - val_acc: 0.4480\n",
      "Epoch 35/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9922 - acc: 0.5143 - val_loss: 14.1254 - val_acc: 0.4576\n",
      "Epoch 36/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.9689 - acc: 0.5238 - val_loss: 14.1235 - val_acc: 0.4313\n",
      "Epoch 37/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9673 - acc: 0.5212 - val_loss: 14.1254 - val_acc: 0.4409\n",
      "Epoch 38/150\n",
      "6965/6965 [==============================] - 4s - loss: 13.9480 - acc: 0.5238 - val_loss: 14.1084 - val_acc: 0.4552\n",
      "Epoch 39/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9297 - acc: 0.5394 - val_loss: 14.1054 - val_acc: 0.4528\n",
      "Epoch 40/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.9253 - acc: 0.5262 - val_loss: 14.1069 - val_acc: 0.4564\n",
      "Epoch 41/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9127 - acc: 0.5361 - val_loss: 14.0955 - val_acc: 0.4719\n",
      "Epoch 42/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.8901 - acc: 0.5475 - val_loss: 14.0827 - val_acc: 0.4564\n",
      "Epoch 43/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.8804 - acc: 0.5509 - val_loss: 14.0793 - val_acc: 0.4576\n",
      "Epoch 44/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8674 - acc: 0.5492 - val_loss: 14.0700 - val_acc: 0.4576\n",
      "Epoch 45/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8594 - acc: 0.5558 - val_loss: 14.0645 - val_acc: 0.4683\n",
      "Epoch 46/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8510 - acc: 0.5483 - val_loss: 14.0650 - val_acc: 0.4540\n",
      "Epoch 47/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8418 - acc: 0.5655 - val_loss: 14.0555 - val_acc: 0.4731\n",
      "Epoch 48/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8262 - acc: 0.5585 - val_loss: 14.0445 - val_acc: 0.4791\n",
      "Epoch 49/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.8082 - acc: 0.5632 - val_loss: 14.0478 - val_acc: 0.4707\n",
      "Epoch 50/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7999 - acc: 0.5681 - val_loss: 14.0239 - val_acc: 0.4815\n",
      "Epoch 51/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7910 - acc: 0.5754 - val_loss: 14.0190 - val_acc: 0.4767\n",
      "Epoch 52/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7771 - acc: 0.5848 - val_loss: 14.0203 - val_acc: 0.4695\n",
      "Epoch 53/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7663 - acc: 0.5810 - val_loss: 14.0402 - val_acc: 0.5221\n",
      "Epoch 54/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7604 - acc: 0.5927 - val_loss: 14.0088 - val_acc: 0.4863\n",
      "Epoch 55/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7397 - acc: 0.5888 - val_loss: 14.0058 - val_acc: 0.4851\n",
      "Epoch 56/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7357 - acc: 0.5908 - val_loss: 14.0077 - val_acc: 0.5137\n",
      "Epoch 57/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7232 - acc: 0.5922 - val_loss: 13.9965 - val_acc: 0.4994\n",
      "Epoch 58/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7111 - acc: 0.5999 - val_loss: 13.9871 - val_acc: 0.5317\n",
      "Epoch 59/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7095 - acc: 0.6000 - val_loss: 13.9797 - val_acc: 0.5054\n",
      "Epoch 60/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6846 - acc: 0.6155 - val_loss: 13.9907 - val_acc: 0.5161\n",
      "Epoch 61/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6846 - acc: 0.6085 - val_loss: 13.9827 - val_acc: 0.5161\n",
      "Epoch 62/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6701 - acc: 0.6155 - val_loss: 13.9741 - val_acc: 0.5197\n",
      "Epoch 63/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6615 - acc: 0.6146 - val_loss: 13.9703 - val_acc: 0.5221\n",
      "Epoch 64/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6527 - acc: 0.6161 - val_loss: 13.9597 - val_acc: 0.5293\n",
      "Epoch 65/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6399 - acc: 0.6296 - val_loss: 13.9597 - val_acc: 0.5137\n",
      "Epoch 66/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6285 - acc: 0.6313 - val_loss: 13.9548 - val_acc: 0.5233\n",
      "Epoch 67/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6197 - acc: 0.6358 - val_loss: 13.9519 - val_acc: 0.5281\n",
      "Epoch 68/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6097 - acc: 0.6385 - val_loss: 13.9414 - val_acc: 0.5412\n",
      "Epoch 69/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5945 - acc: 0.6403 - val_loss: 13.9402 - val_acc: 0.5197\n",
      "Epoch 70/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5915 - acc: 0.6395 - val_loss: 13.9300 - val_acc: 0.5329\n",
      "Epoch 71/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5849 - acc: 0.6487 - val_loss: 13.9263 - val_acc: 0.5388\n",
      "Epoch 72/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5723 - acc: 0.6459 - val_loss: 13.9138 - val_acc: 0.5532\n",
      "Epoch 73/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5645 - acc: 0.6442 - val_loss: 13.9027 - val_acc: 0.5806\n",
      "Epoch 74/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5571 - acc: 0.6536 - val_loss: 13.9116 - val_acc: 0.5675\n",
      "Epoch 75/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5511 - acc: 0.6484 - val_loss: 13.9150 - val_acc: 0.5341\n",
      "Epoch 76/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5362 - acc: 0.6567 - val_loss: 13.9029 - val_acc: 0.5424\n",
      "Epoch 77/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5234 - acc: 0.6600 - val_loss: 13.8914 - val_acc: 0.5639\n",
      "Epoch 78/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5154 - acc: 0.6643 - val_loss: 13.8810 - val_acc: 0.5866\n",
      "Epoch 79/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5084 - acc: 0.6633 - val_loss: 13.8986 - val_acc: 0.5508\n",
      "Epoch 80/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4885 - acc: 0.6718 - val_loss: 13.8822 - val_acc: 0.5735\n",
      "Epoch 81/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4925 - acc: 0.6686 - val_loss: 13.8857 - val_acc: 0.5329\n",
      "Epoch 82/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4825 - acc: 0.6732 - val_loss: 13.8716 - val_acc: 0.5878\n",
      "Epoch 83/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4734 - acc: 0.6714 - val_loss: 13.8654 - val_acc: 0.5998\n",
      "Epoch 84/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4712 - acc: 0.6702 - val_loss: 13.8672 - val_acc: 0.5603\n",
      "Epoch 85/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4549 - acc: 0.6793 - val_loss: 13.8669 - val_acc: 0.5603\n",
      "Epoch 86/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4438 - acc: 0.6813 - val_loss: 13.8537 - val_acc: 0.5926\n",
      "Epoch 87/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4269 - acc: 0.6879 - val_loss: 13.8708 - val_acc: 0.5591\n",
      "Epoch 88/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4235 - acc: 0.6840 - val_loss: 13.8734 - val_acc: 0.5532\n",
      "Epoch 89/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4104 - acc: 0.6917 - val_loss: 13.8462 - val_acc: 0.5579\n",
      "Epoch 90/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4050 - acc: 0.6927 - val_loss: 13.8451 - val_acc: 0.5998\n",
      "Epoch 91/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4051 - acc: 0.6950 - val_loss: 13.8431 - val_acc: 0.5962\n",
      "Epoch 92/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3884 - acc: 0.6917 - val_loss: 13.8412 - val_acc: 0.5795\n",
      "Epoch 93/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3909 - acc: 0.6899 - val_loss: 13.8318 - val_acc: 0.5902\n",
      "Epoch 94/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3748 - acc: 0.6983 - val_loss: 13.8252 - val_acc: 0.5878\n",
      "Epoch 95/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3609 - acc: 0.7006 - val_loss: 13.8270 - val_acc: 0.5890\n",
      "Epoch 96/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3545 - acc: 0.7031 - val_loss: 13.8200 - val_acc: 0.5986\n",
      "Epoch 97/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3554 - acc: 0.7028 - val_loss: 13.8167 - val_acc: 0.5795\n",
      "Epoch 98/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3410 - acc: 0.7038 - val_loss: 13.8300 - val_acc: 0.5711\n",
      "Epoch 99/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3354 - acc: 0.7078 - val_loss: 13.8086 - val_acc: 0.5866\n",
      "Epoch 100/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3293 - acc: 0.7064 - val_loss: 13.7993 - val_acc: 0.5902\n",
      "Epoch 101/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3131 - acc: 0.7098 - val_loss: 13.8111 - val_acc: 0.5902\n",
      "Epoch 102/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3173 - acc: 0.7078 - val_loss: 13.8118 - val_acc: 0.5842\n",
      "Epoch 103/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3018 - acc: 0.7094 - val_loss: 13.7892 - val_acc: 0.5938\n",
      "Epoch 104/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2979 - acc: 0.7160 - val_loss: 13.8006 - val_acc: 0.5902\n",
      "Epoch 105/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2843 - acc: 0.7206 - val_loss: 13.7843 - val_acc: 0.5914\n",
      "Epoch 106/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2763 - acc: 0.7189 - val_loss: 13.7667 - val_acc: 0.5998\n",
      "Epoch 107/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2690 - acc: 0.7238 - val_loss: 13.7698 - val_acc: 0.6033\n",
      "Epoch 108/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2653 - acc: 0.7236 - val_loss: 13.7804 - val_acc: 0.5878\n",
      "Epoch 109/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2580 - acc: 0.7236 - val_loss: 13.7766 - val_acc: 0.5795\n",
      "Epoch 110/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2498 - acc: 0.7249 - val_loss: 13.7691 - val_acc: 0.5938\n",
      "Epoch 111/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2368 - acc: 0.7274 - val_loss: 13.7638 - val_acc: 0.5950\n",
      "Epoch 112/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2298 - acc: 0.7281 - val_loss: 13.7516 - val_acc: 0.5986\n",
      "Epoch 113/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2308 - acc: 0.7296 - val_loss: 13.7467 - val_acc: 0.5902\n",
      "Epoch 114/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2183 - acc: 0.7325 - val_loss: 13.7431 - val_acc: 0.5974\n",
      "Epoch 115/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2087 - acc: 0.7344 - val_loss: 13.7456 - val_acc: 0.5998\n",
      "Epoch 116/150\n",
      "6965/6965 [==============================] - 4s - loss: 13.1979 - acc: 0.7334 - val_loss: 13.7193 - val_acc: 0.6093\n",
      "Epoch 117/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1899 - acc: 0.7334 - val_loss: 13.7610 - val_acc: 0.5914\n",
      "Epoch 118/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1889 - acc: 0.7397 - val_loss: 13.7287 - val_acc: 0.6081\n",
      "Epoch 119/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1785 - acc: 0.7408 - val_loss: 13.7365 - val_acc: 0.5854\n",
      "Epoch 120/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1763 - acc: 0.7351 - val_loss: 13.7199 - val_acc: 0.5938\n",
      "Epoch 121/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1724 - acc: 0.7416 - val_loss: 13.6996 - val_acc: 0.6129\n",
      "Epoch 122/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1518 - acc: 0.7486 - val_loss: 13.7127 - val_acc: 0.6105\n",
      "Epoch 123/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1511 - acc: 0.7464 - val_loss: 13.7211 - val_acc: 0.5986\n",
      "Epoch 124/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1462 - acc: 0.7439 - val_loss: 13.6984 - val_acc: 0.6105\n",
      "Epoch 125/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1285 - acc: 0.7509 - val_loss: 13.7001 - val_acc: 0.6057\n",
      "Epoch 126/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1177 - acc: 0.7499 - val_loss: 13.7123 - val_acc: 0.5938\n",
      "Epoch 127/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1220 - acc: 0.7519 - val_loss: 13.6919 - val_acc: 0.6045\n",
      "Epoch 128/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1163 - acc: 0.7506 - val_loss: 13.6881 - val_acc: 0.6153\n",
      "Epoch 129/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1019 - acc: 0.7571 - val_loss: 13.6788 - val_acc: 0.6308\n",
      "Epoch 130/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0957 - acc: 0.7558 - val_loss: 13.6819 - val_acc: 0.6069\n",
      "Epoch 131/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0905 - acc: 0.7564 - val_loss: 13.6710 - val_acc: 0.6153\n",
      "Epoch 132/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0817 - acc: 0.7546 - val_loss: 13.6756 - val_acc: 0.6057\n",
      "Epoch 133/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0767 - acc: 0.7601 - val_loss: 13.6763 - val_acc: 0.6105\n",
      "Epoch 134/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0742 - acc: 0.7611 - val_loss: 13.6825 - val_acc: 0.5950\n",
      "Epoch 135/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.0657 - acc: 0.7621 - val_loss: 13.6599 - val_acc: 0.6165\n",
      "Epoch 136/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.0543 - acc: 0.7604 - val_loss: 13.6466 - val_acc: 0.6141\n",
      "Epoch 137/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.0520 - acc: 0.7631 - val_loss: 13.6508 - val_acc: 0.6189\n",
      "Epoch 138/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.0415 - acc: 0.7684 - val_loss: 13.6535 - val_acc: 0.6165\n",
      "Epoch 139/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0308 - acc: 0.7642 - val_loss: 13.6577 - val_acc: 0.6141\n",
      "Epoch 140/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.0255 - acc: 0.7700 - val_loss: 13.6438 - val_acc: 0.6105\n",
      "Epoch 141/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0196 - acc: 0.7714 - val_loss: 13.6522 - val_acc: 0.6141\n",
      "Epoch 142/150\n",
      "6965/6965 [==============================] - 4s - loss: 13.0134 - acc: 0.7713 - val_loss: 13.6224 - val_acc: 0.6213\n",
      "Epoch 143/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.0083 - acc: 0.7739 - val_loss: 13.6301 - val_acc: 0.6284\n",
      "Epoch 144/150\n",
      "6965/6965 [==============================] - 2s - loss: 12.9997 - acc: 0.7716 - val_loss: 13.6139 - val_acc: 0.6308\n",
      "Epoch 145/150\n",
      "6965/6965 [==============================] - 2s - loss: 12.9836 - acc: 0.7756 - val_loss: 13.6230 - val_acc: 0.6201\n",
      "Epoch 146/150\n",
      "6965/6965 [==============================] - 3s - loss: 12.9852 - acc: 0.7783 - val_loss: 13.6170 - val_acc: 0.6260\n",
      "Epoch 147/150\n",
      "6965/6965 [==============================] - 2s - loss: 12.9737 - acc: 0.7767 - val_loss: 13.6119 - val_acc: 0.6260\n",
      "Epoch 148/150\n",
      "6965/6965 [==============================] - 2s - loss: 12.9709 - acc: 0.7808 - val_loss: 13.6063 - val_acc: 0.6272\n",
      "Epoch 149/150\n",
      "6965/6965 [==============================] - 3s - loss: 12.9630 - acc: 0.7799 - val_loss: 13.6081 - val_acc: 0.6260\n",
      "Epoch 150/150\n",
      "6965/6965 [==============================] - 2s - loss: 12.9551 - acc: 0.7789 - val_loss: 13.5912 - val_acc: 0.6308\n",
      "training time: 471.55916953086853\n",
      "925/925 [==============================] - 0s     \n",
      "\n",
      "Accuracy = 0.5405\n",
      "\n",
      "Error Rate = 0.4595\n",
      "training time: 0.7436349391937256\n",
      "opening fold: 4\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.7927722930908203\n",
      "Scaling time: 0.22389888763427734\n",
      "Scaling time: 0.26371073722839355\n",
      "training model...hold tight\n",
      "Train on 6900 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "6900/6900 [==============================] - 10s - loss: 15.1300 - acc: 0.1072 - val_loss: 15.0577 - val_acc: 0.1231\n",
      "Epoch 2/150\n",
      "6900/6900 [==============================] - 2s - loss: 15.0575 - acc: 0.1417 - val_loss: 14.9926 - val_acc: 0.1613\n",
      "Epoch 3/150\n",
      "6900/6900 [==============================] - 2s - loss: 15.0077 - acc: 0.1654 - val_loss: 14.9382 - val_acc: 0.1924\n",
      "Epoch 4/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.9500 - acc: 0.1912 - val_loss: 14.8825 - val_acc: 0.1912\n",
      "Epoch 5/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.8976 - acc: 0.2122 - val_loss: 14.8286 - val_acc: 0.2031\n",
      "Epoch 6/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.8398 - acc: 0.2358 - val_loss: 14.7790 - val_acc: 0.2843\n",
      "Epoch 7/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.7934 - acc: 0.2626 - val_loss: 14.7292 - val_acc: 0.3130\n",
      "Epoch 8/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.7528 - acc: 0.2755 - val_loss: 14.6818 - val_acc: 0.3274\n",
      "Epoch 9/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.7045 - acc: 0.2901 - val_loss: 14.6384 - val_acc: 0.3178\n",
      "Epoch 10/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.6582 - acc: 0.3057 - val_loss: 14.5939 - val_acc: 0.3190\n",
      "Epoch 11/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.6163 - acc: 0.3201 - val_loss: 14.5560 - val_acc: 0.3286\n",
      "Epoch 12/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5680 - acc: 0.3297 - val_loss: 14.5223 - val_acc: 0.3082\n",
      "Epoch 13/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5382 - acc: 0.3401 - val_loss: 14.4904 - val_acc: 0.3286\n",
      "Epoch 14/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5033 - acc: 0.3562 - val_loss: 14.4658 - val_acc: 0.3011\n",
      "Epoch 15/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.4616 - acc: 0.3783 - val_loss: 14.4370 - val_acc: 0.3513\n",
      "Epoch 16/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.4246 - acc: 0.3909 - val_loss: 14.4136 - val_acc: 0.3369\n",
      "Epoch 17/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.3970 - acc: 0.4010 - val_loss: 14.3925 - val_acc: 0.3524\n",
      "Epoch 18/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.3703 - acc: 0.4087 - val_loss: 14.3660 - val_acc: 0.3548\n",
      "Epoch 19/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.3425 - acc: 0.4090 - val_loss: 14.3477 - val_acc: 0.3536\n",
      "Epoch 20/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.3059 - acc: 0.4275 - val_loss: 14.3302 - val_acc: 0.3453\n",
      "Epoch 21/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.2830 - acc: 0.4371 - val_loss: 14.3096 - val_acc: 0.3990\n",
      "Epoch 22/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.2558 - acc: 0.4396 - val_loss: 14.2870 - val_acc: 0.3955\n",
      "Epoch 23/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.2234 - acc: 0.4522 - val_loss: 14.2741 - val_acc: 0.4074\n",
      "Epoch 24/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.2266 - acc: 0.4497 - val_loss: 14.2592 - val_acc: 0.4158\n",
      "Epoch 25/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1893 - acc: 0.4645 - val_loss: 14.2467 - val_acc: 0.4062\n",
      "Epoch 26/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1682 - acc: 0.4697 - val_loss: 14.2346 - val_acc: 0.4313\n",
      "Epoch 27/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1535 - acc: 0.4690 - val_loss: 14.2203 - val_acc: 0.4289\n",
      "Epoch 28/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1325 - acc: 0.4770 - val_loss: 14.2059 - val_acc: 0.4361\n",
      "Epoch 29/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.1224 - acc: 0.4749 - val_loss: 14.2020 - val_acc: 0.4337\n",
      "Epoch 30/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.0958 - acc: 0.4823 - val_loss: 14.1862 - val_acc: 0.4134\n",
      "Epoch 31/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0859 - acc: 0.4897 - val_loss: 14.1822 - val_acc: 0.4182\n",
      "Epoch 32/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0694 - acc: 0.4875 - val_loss: 14.1675 - val_acc: 0.4253\n",
      "Epoch 33/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0550 - acc: 0.5001 - val_loss: 14.1610 - val_acc: 0.4205\n",
      "Epoch 34/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.0390 - acc: 0.5022 - val_loss: 14.1532 - val_acc: 0.4265\n",
      "Epoch 35/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0227 - acc: 0.5042 - val_loss: 14.1436 - val_acc: 0.4205\n",
      "Epoch 36/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0112 - acc: 0.5043 - val_loss: 14.1294 - val_acc: 0.4265\n",
      "Epoch 37/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9913 - acc: 0.5191 - val_loss: 14.1340 - val_acc: 0.4337\n",
      "Epoch 38/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.9829 - acc: 0.5133 - val_loss: 14.1241 - val_acc: 0.4217\n",
      "Epoch 39/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.9563 - acc: 0.5223 - val_loss: 14.1181 - val_acc: 0.4325\n",
      "Epoch 40/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9595 - acc: 0.5155 - val_loss: 14.1047 - val_acc: 0.4397\n",
      "Epoch 41/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9395 - acc: 0.5328 - val_loss: 14.1014 - val_acc: 0.4492\n",
      "Epoch 42/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9233 - acc: 0.5290 - val_loss: 14.0914 - val_acc: 0.4564\n",
      "Epoch 43/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9171 - acc: 0.5365 - val_loss: 14.0859 - val_acc: 0.4540\n",
      "Epoch 44/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.9040 - acc: 0.5412 - val_loss: 14.0720 - val_acc: 0.4707\n",
      "Epoch 45/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8923 - acc: 0.5399 - val_loss: 14.0662 - val_acc: 0.4719\n",
      "Epoch 46/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8770 - acc: 0.5459 - val_loss: 14.0676 - val_acc: 0.4659\n",
      "Epoch 47/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8630 - acc: 0.5520 - val_loss: 14.0587 - val_acc: 0.4803\n",
      "Epoch 48/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8544 - acc: 0.5529 - val_loss: 14.0406 - val_acc: 0.4743\n",
      "Epoch 49/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8431 - acc: 0.5574 - val_loss: 14.0365 - val_acc: 0.4851\n",
      "Epoch 50/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8321 - acc: 0.5542 - val_loss: 14.0301 - val_acc: 0.4791\n",
      "Epoch 51/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.8277 - acc: 0.5571 - val_loss: 14.0274 - val_acc: 0.4779\n",
      "Epoch 52/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8035 - acc: 0.5686 - val_loss: 14.0184 - val_acc: 0.4743\n",
      "Epoch 53/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7917 - acc: 0.5672 - val_loss: 14.0087 - val_acc: 0.4851\n",
      "Epoch 54/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7809 - acc: 0.5675 - val_loss: 14.0038 - val_acc: 0.4779\n",
      "Epoch 55/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7755 - acc: 0.5742 - val_loss: 13.9993 - val_acc: 0.4851\n",
      "Epoch 56/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7622 - acc: 0.5780 - val_loss: 13.9860 - val_acc: 0.4946\n",
      "Epoch 57/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.7514 - acc: 0.5838 - val_loss: 13.9884 - val_acc: 0.4863\n",
      "Epoch 58/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7400 - acc: 0.5803 - val_loss: 13.9744 - val_acc: 0.5006\n",
      "Epoch 59/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7288 - acc: 0.5871 - val_loss: 13.9750 - val_acc: 0.5066\n",
      "Epoch 60/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.7182 - acc: 0.5932 - val_loss: 13.9842 - val_acc: 0.4934\n",
      "Epoch 61/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7041 - acc: 0.5994 - val_loss: 13.9618 - val_acc: 0.5030\n",
      "Epoch 62/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6988 - acc: 0.6039 - val_loss: 13.9526 - val_acc: 0.5341\n",
      "Epoch 63/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6772 - acc: 0.6071 - val_loss: 13.9511 - val_acc: 0.5341\n",
      "Epoch 64/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6730 - acc: 0.6090 - val_loss: 13.9513 - val_acc: 0.5376\n",
      "Epoch 65/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6645 - acc: 0.6084 - val_loss: 13.9420 - val_acc: 0.5281\n",
      "Epoch 66/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6523 - acc: 0.6125 - val_loss: 13.9371 - val_acc: 0.5269\n",
      "Epoch 67/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6451 - acc: 0.6148 - val_loss: 13.9383 - val_acc: 0.5125\n",
      "Epoch 68/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6295 - acc: 0.6257 - val_loss: 13.9301 - val_acc: 0.5400\n",
      "Epoch 69/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6294 - acc: 0.6158 - val_loss: 13.9265 - val_acc: 0.5149\n",
      "Epoch 70/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6148 - acc: 0.6248 - val_loss: 13.9054 - val_acc: 0.5544\n",
      "Epoch 71/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6033 - acc: 0.6304 - val_loss: 13.9044 - val_acc: 0.5472\n",
      "Epoch 72/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5927 - acc: 0.6328 - val_loss: 13.9037 - val_acc: 0.5735\n",
      "Epoch 73/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5877 - acc: 0.6268 - val_loss: 13.9049 - val_acc: 0.5090\n",
      "Epoch 74/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5717 - acc: 0.6371 - val_loss: 13.8889 - val_acc: 0.5627\n",
      "Epoch 75/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5705 - acc: 0.6290 - val_loss: 13.8868 - val_acc: 0.5520\n",
      "Epoch 76/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5596 - acc: 0.6351 - val_loss: 13.8922 - val_acc: 0.5568\n",
      "Epoch 77/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5390 - acc: 0.6462 - val_loss: 13.8827 - val_acc: 0.5603\n",
      "Epoch 78/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5340 - acc: 0.6471 - val_loss: 13.8814 - val_acc: 0.5544\n",
      "Epoch 79/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5291 - acc: 0.6474 - val_loss: 13.8751 - val_acc: 0.5591\n",
      "Epoch 80/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5144 - acc: 0.6504 - val_loss: 13.8668 - val_acc: 0.5747\n",
      "Epoch 81/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5076 - acc: 0.6571 - val_loss: 13.8649 - val_acc: 0.5687\n",
      "Epoch 82/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4987 - acc: 0.6616 - val_loss: 13.8691 - val_acc: 0.5293\n",
      "Epoch 83/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4928 - acc: 0.6567 - val_loss: 13.8609 - val_acc: 0.5735\n",
      "Epoch 84/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4783 - acc: 0.6630 - val_loss: 13.8386 - val_acc: 0.6010\n",
      "Epoch 85/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.4681 - acc: 0.6678 - val_loss: 13.8284 - val_acc: 0.6105\n",
      "Epoch 86/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4625 - acc: 0.6680 - val_loss: 13.8310 - val_acc: 0.5806\n",
      "Epoch 87/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4527 - acc: 0.6655 - val_loss: 13.8331 - val_acc: 0.6081\n",
      "Epoch 88/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4498 - acc: 0.6703 - val_loss: 13.8374 - val_acc: 0.5854\n",
      "Epoch 89/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4333 - acc: 0.6712 - val_loss: 13.8218 - val_acc: 0.5854\n",
      "Epoch 90/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.4316 - acc: 0.6733 - val_loss: 13.8354 - val_acc: 0.5795\n",
      "Epoch 91/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4176 - acc: 0.6799 - val_loss: 13.8247 - val_acc: 0.6129\n",
      "Epoch 92/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4044 - acc: 0.6825 - val_loss: 13.8224 - val_acc: 0.6141\n",
      "Epoch 93/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.4057 - acc: 0.6793 - val_loss: 13.8194 - val_acc: 0.6093\n",
      "Epoch 94/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3920 - acc: 0.6826 - val_loss: 13.8043 - val_acc: 0.6105\n",
      "Epoch 95/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3791 - acc: 0.6846 - val_loss: 13.8076 - val_acc: 0.6057\n",
      "Epoch 96/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3634 - acc: 0.6949 - val_loss: 13.8079 - val_acc: 0.6105\n",
      "Epoch 97/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3712 - acc: 0.6855 - val_loss: 13.7868 - val_acc: 0.6213\n",
      "Epoch 98/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3519 - acc: 0.6974 - val_loss: 13.8027 - val_acc: 0.6105\n",
      "Epoch 99/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3449 - acc: 0.6932 - val_loss: 13.7838 - val_acc: 0.6189\n",
      "Epoch 100/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3503 - acc: 0.6922 - val_loss: 13.7993 - val_acc: 0.5986\n",
      "Epoch 101/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3332 - acc: 0.6965 - val_loss: 13.7716 - val_acc: 0.6129\n",
      "Epoch 102/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3216 - acc: 0.6984 - val_loss: 13.7880 - val_acc: 0.6105\n",
      "Epoch 103/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3187 - acc: 0.6978 - val_loss: 13.7841 - val_acc: 0.6045\n",
      "Epoch 104/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3072 - acc: 0.7086 - val_loss: 13.7658 - val_acc: 0.6117\n",
      "Epoch 105/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2996 - acc: 0.7138 - val_loss: 13.7571 - val_acc: 0.6189\n",
      "Epoch 106/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2931 - acc: 0.7039 - val_loss: 13.7720 - val_acc: 0.6081\n",
      "Epoch 107/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2830 - acc: 0.7117 - val_loss: 13.7669 - val_acc: 0.6177\n",
      "Epoch 108/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2725 - acc: 0.7142 - val_loss: 13.7478 - val_acc: 0.6213\n",
      "Epoch 109/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2682 - acc: 0.7087 - val_loss: 13.7498 - val_acc: 0.6189\n",
      "Epoch 110/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2514 - acc: 0.7165 - val_loss: 13.7498 - val_acc: 0.6153\n",
      "Epoch 111/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2548 - acc: 0.7136 - val_loss: 13.7261 - val_acc: 0.6237\n",
      "Epoch 112/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2504 - acc: 0.7154 - val_loss: 13.7325 - val_acc: 0.6249\n",
      "Epoch 113/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2363 - acc: 0.7197 - val_loss: 13.7275 - val_acc: 0.6320\n",
      "Epoch 114/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2313 - acc: 0.7171 - val_loss: 13.7216 - val_acc: 0.6213\n",
      "Epoch 115/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2241 - acc: 0.7162 - val_loss: 13.7134 - val_acc: 0.6284\n",
      "Epoch 116/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2192 - acc: 0.7274 - val_loss: 13.7276 - val_acc: 0.6272\n",
      "Epoch 117/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2135 - acc: 0.7207 - val_loss: 13.7095 - val_acc: 0.6368\n",
      "Epoch 118/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2060 - acc: 0.7245 - val_loss: 13.7330 - val_acc: 0.6296\n",
      "Epoch 119/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1911 - acc: 0.7275 - val_loss: 13.7140 - val_acc: 0.6332\n",
      "Epoch 120/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.1939 - acc: 0.7245 - val_loss: 13.7131 - val_acc: 0.6141\n",
      "Epoch 121/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1752 - acc: 0.7361 - val_loss: 13.7044 - val_acc: 0.6213\n",
      "Epoch 122/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1742 - acc: 0.7300 - val_loss: 13.6959 - val_acc: 0.6320\n",
      "Epoch 123/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1696 - acc: 0.7284 - val_loss: 13.6976 - val_acc: 0.6260\n",
      "Epoch 124/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1508 - acc: 0.7335 - val_loss: 13.6976 - val_acc: 0.6249\n",
      "Epoch 125/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.1508 - acc: 0.7361 - val_loss: 13.6916 - val_acc: 0.6249\n",
      "Epoch 126/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1464 - acc: 0.7357 - val_loss: 13.6815 - val_acc: 0.6260\n",
      "Epoch 127/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.1360 - acc: 0.7401 - val_loss: 13.6931 - val_acc: 0.6141\n",
      "Epoch 128/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.1229 - acc: 0.7420 - val_loss: 13.6693 - val_acc: 0.6332\n",
      "Epoch 129/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1148 - acc: 0.7422 - val_loss: 13.6986 - val_acc: 0.6189\n",
      "Epoch 130/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.1194 - acc: 0.7362 - val_loss: 13.6625 - val_acc: 0.6332\n",
      "Epoch 131/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1064 - acc: 0.7390 - val_loss: 13.6715 - val_acc: 0.6344\n",
      "Epoch 132/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0963 - acc: 0.7486 - val_loss: 13.6611 - val_acc: 0.6284\n",
      "Epoch 133/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0945 - acc: 0.7526 - val_loss: 13.6524 - val_acc: 0.6284\n",
      "Epoch 134/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0906 - acc: 0.7474 - val_loss: 13.6430 - val_acc: 0.6440\n",
      "Epoch 135/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.0748 - acc: 0.7493 - val_loss: 13.6504 - val_acc: 0.6464\n",
      "Epoch 136/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.0675 - acc: 0.7522 - val_loss: 13.6586 - val_acc: 0.6296\n",
      "Epoch 137/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0634 - acc: 0.7468 - val_loss: 13.6692 - val_acc: 0.6308\n",
      "Epoch 138/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0558 - acc: 0.7510 - val_loss: 13.6598 - val_acc: 0.6368\n",
      "Epoch 139/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0641 - acc: 0.7493 - val_loss: 13.6289 - val_acc: 0.6404\n",
      "Epoch 140/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0416 - acc: 0.7499 - val_loss: 13.6368 - val_acc: 0.6344\n",
      "Epoch 141/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.0399 - acc: 0.7567 - val_loss: 13.6432 - val_acc: 0.6225\n",
      "Epoch 142/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.0241 - acc: 0.7578 - val_loss: 13.6067 - val_acc: 0.6392\n",
      "Epoch 143/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0305 - acc: 0.7594 - val_loss: 13.6171 - val_acc: 0.6380\n",
      "Epoch 144/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0124 - acc: 0.7616 - val_loss: 13.6199 - val_acc: 0.6452\n",
      "Epoch 145/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.0096 - acc: 0.7641 - val_loss: 13.6229 - val_acc: 0.6344\n",
      "Epoch 146/150\n",
      "6900/6900 [==============================] - 2s - loss: 12.9944 - acc: 0.7632 - val_loss: 13.6136 - val_acc: 0.6392\n",
      "Epoch 147/150\n",
      "6900/6900 [==============================] - 3s - loss: 12.9926 - acc: 0.7675 - val_loss: 13.6113 - val_acc: 0.6416\n",
      "Epoch 148/150\n",
      "6900/6900 [==============================] - 3s - loss: 12.9957 - acc: 0.7594 - val_loss: 13.5926 - val_acc: 0.6499\n",
      "Epoch 149/150\n",
      "6900/6900 [==============================] - 2s - loss: 12.9871 - acc: 0.7662 - val_loss: 13.6387 - val_acc: 0.6392\n",
      "Epoch 150/150\n",
      "6900/6900 [==============================] - 2s - loss: 12.9753 - acc: 0.7686 - val_loss: 13.6016 - val_acc: 0.6535\n",
      "training time: 470.9915249347687\n",
      "928/990 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.6586\n",
      "\n",
      "Error Rate = 0.3414\n",
      "training time: 0.7745399475097656\n",
      "opening fold: 5\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8217296600341797\n",
      "Scaling time: 0.2256777286529541\n",
      "Scaling time: 0.25048255920410156\n",
      "training model...hold tight\n",
      "Train on 6954 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "6954/6954 [==============================] - 10s - loss: 15.1258 - acc: 0.1076 - val_loss: 15.0291 - val_acc: 0.1613\n",
      "Epoch 2/150\n",
      "6954/6954 [==============================] - 2s - loss: 15.0497 - acc: 0.1517 - val_loss: 14.9626 - val_acc: 0.1852\n",
      "Epoch 3/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.9761 - acc: 0.1825 - val_loss: 14.8977 - val_acc: 0.2007\n",
      "Epoch 4/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.9115 - acc: 0.2117 - val_loss: 14.8364 - val_acc: 0.2222\n",
      "Epoch 5/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.8467 - acc: 0.2332 - val_loss: 14.7762 - val_acc: 0.2533\n",
      "Epoch 6/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.7901 - acc: 0.2522 - val_loss: 14.7193 - val_acc: 0.2939\n",
      "Epoch 7/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.7265 - acc: 0.2853 - val_loss: 14.6641 - val_acc: 0.3250\n",
      "Epoch 8/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.6714 - acc: 0.3004 - val_loss: 14.6136 - val_acc: 0.3369\n",
      "Epoch 9/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.6103 - acc: 0.3228 - val_loss: 14.5671 - val_acc: 0.3608\n",
      "Epoch 10/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.5693 - acc: 0.3250 - val_loss: 14.5285 - val_acc: 0.3668\n",
      "Epoch 11/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.5239 - acc: 0.3525 - val_loss: 14.4948 - val_acc: 0.3632\n",
      "Epoch 12/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.4743 - acc: 0.3581 - val_loss: 14.4663 - val_acc: 0.3775\n",
      "Epoch 13/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.4410 - acc: 0.3851 - val_loss: 14.4353 - val_acc: 0.3787\n",
      "Epoch 14/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.4054 - acc: 0.3923 - val_loss: 14.4109 - val_acc: 0.3775\n",
      "Epoch 15/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.3683 - acc: 0.4226 - val_loss: 14.3887 - val_acc: 0.3883\n",
      "Epoch 16/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.3331 - acc: 0.4275 - val_loss: 14.3615 - val_acc: 0.3847\n",
      "Epoch 17/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.3085 - acc: 0.4347 - val_loss: 14.3399 - val_acc: 0.3931\n",
      "Epoch 18/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.2893 - acc: 0.4393 - val_loss: 14.3273 - val_acc: 0.3931\n",
      "Epoch 19/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.2532 - acc: 0.4466 - val_loss: 14.3076 - val_acc: 0.3931\n",
      "Epoch 20/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.2216 - acc: 0.4599 - val_loss: 14.2913 - val_acc: 0.4062\n",
      "Epoch 21/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1939 - acc: 0.4655 - val_loss: 14.2778 - val_acc: 0.3955\n",
      "Epoch 22/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1745 - acc: 0.4796 - val_loss: 14.2630 - val_acc: 0.4038\n",
      "Epoch 23/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1479 - acc: 0.4882 - val_loss: 14.2504 - val_acc: 0.4038\n",
      "Epoch 24/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.1369 - acc: 0.4791 - val_loss: 14.2392 - val_acc: 0.4002\n",
      "Epoch 25/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1140 - acc: 0.4927 - val_loss: 14.2326 - val_acc: 0.4074\n",
      "Epoch 26/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.0947 - acc: 0.4968 - val_loss: 14.2186 - val_acc: 0.4253\n",
      "Epoch 27/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0793 - acc: 0.4947 - val_loss: 14.2061 - val_acc: 0.4038\n",
      "Epoch 28/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0622 - acc: 0.5082 - val_loss: 14.2042 - val_acc: 0.3943\n",
      "Epoch 29/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.0371 - acc: 0.5147 - val_loss: 14.1983 - val_acc: 0.3847\n",
      "Epoch 30/150\n",
      "6954/6954 [==============================] - 4s - loss: 14.0303 - acc: 0.5144 - val_loss: 14.1820 - val_acc: 0.4134\n",
      "Epoch 31/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0083 - acc: 0.5165 - val_loss: 14.1732 - val_acc: 0.3967\n",
      "Epoch 32/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9972 - acc: 0.5250 - val_loss: 14.1651 - val_acc: 0.3967\n",
      "Epoch 33/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9784 - acc: 0.5328 - val_loss: 14.1623 - val_acc: 0.4038\n",
      "Epoch 34/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.9643 - acc: 0.5282 - val_loss: 14.1516 - val_acc: 0.4062\n",
      "Epoch 35/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9513 - acc: 0.5398 - val_loss: 14.1420 - val_acc: 0.4134\n",
      "Epoch 36/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9513 - acc: 0.5370 - val_loss: 14.1335 - val_acc: 0.4205\n",
      "Epoch 37/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9338 - acc: 0.5454 - val_loss: 14.1291 - val_acc: 0.4062\n",
      "Epoch 38/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9241 - acc: 0.5450 - val_loss: 14.1179 - val_acc: 0.4277\n",
      "Epoch 39/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9080 - acc: 0.5444 - val_loss: 14.1100 - val_acc: 0.4301\n",
      "Epoch 40/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8969 - acc: 0.5493 - val_loss: 14.1086 - val_acc: 0.4229\n",
      "Epoch 41/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.8853 - acc: 0.5541 - val_loss: 14.0988 - val_acc: 0.4540\n",
      "Epoch 42/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8733 - acc: 0.5555 - val_loss: 14.0912 - val_acc: 0.4492\n",
      "Epoch 43/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.8632 - acc: 0.5600 - val_loss: 14.0905 - val_acc: 0.4277\n",
      "Epoch 44/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.8439 - acc: 0.5647 - val_loss: 14.0762 - val_acc: 0.4492\n",
      "Epoch 45/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8332 - acc: 0.5700 - val_loss: 14.0742 - val_acc: 0.4397\n",
      "Epoch 46/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8197 - acc: 0.5672 - val_loss: 14.0664 - val_acc: 0.4361\n",
      "Epoch 47/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8116 - acc: 0.5692 - val_loss: 14.0575 - val_acc: 0.4612\n",
      "Epoch 48/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7905 - acc: 0.5759 - val_loss: 14.0571 - val_acc: 0.4659\n",
      "Epoch 49/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7915 - acc: 0.5768 - val_loss: 14.0494 - val_acc: 0.4791\n",
      "Epoch 50/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.7861 - acc: 0.5804 - val_loss: 14.0539 - val_acc: 0.4528\n",
      "Epoch 51/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7673 - acc: 0.5814 - val_loss: 14.0395 - val_acc: 0.4492\n",
      "Epoch 52/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7617 - acc: 0.5869 - val_loss: 14.0216 - val_acc: 0.4707\n",
      "Epoch 53/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7460 - acc: 0.5902 - val_loss: 14.0158 - val_acc: 0.4767\n",
      "Epoch 54/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7360 - acc: 0.5933 - val_loss: 14.0284 - val_acc: 0.4648\n",
      "Epoch 55/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7246 - acc: 0.5873 - val_loss: 14.0154 - val_acc: 0.4755\n",
      "Epoch 56/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7178 - acc: 0.5963 - val_loss: 14.0128 - val_acc: 0.4743\n",
      "Epoch 57/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7099 - acc: 0.6030 - val_loss: 13.9999 - val_acc: 0.4695\n",
      "Epoch 58/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6950 - acc: 0.6038 - val_loss: 14.0007 - val_acc: 0.4743\n",
      "Epoch 59/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6791 - acc: 0.6142 - val_loss: 13.9871 - val_acc: 0.4946\n",
      "Epoch 60/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6759 - acc: 0.6077 - val_loss: 13.9889 - val_acc: 0.4875\n",
      "Epoch 61/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6667 - acc: 0.6106 - val_loss: 13.9852 - val_acc: 0.4851\n",
      "Epoch 62/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6494 - acc: 0.6159 - val_loss: 13.9760 - val_acc: 0.4886\n",
      "Epoch 63/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6518 - acc: 0.6176 - val_loss: 13.9795 - val_acc: 0.5066\n",
      "Epoch 64/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6417 - acc: 0.6209 - val_loss: 13.9806 - val_acc: 0.4779\n",
      "Epoch 65/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.6293 - acc: 0.6183 - val_loss: 13.9602 - val_acc: 0.5245\n",
      "Epoch 66/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6159 - acc: 0.6225 - val_loss: 13.9565 - val_acc: 0.5090\n",
      "Epoch 67/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6095 - acc: 0.6300 - val_loss: 13.9365 - val_acc: 0.5496\n",
      "Epoch 68/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5966 - acc: 0.6278 - val_loss: 13.9351 - val_acc: 0.5066\n",
      "Epoch 69/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5985 - acc: 0.6283 - val_loss: 13.9328 - val_acc: 0.5352\n",
      "Epoch 70/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5828 - acc: 0.6313 - val_loss: 13.9313 - val_acc: 0.5221\n",
      "Epoch 71/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5636 - acc: 0.6415 - val_loss: 13.9244 - val_acc: 0.5496\n",
      "Epoch 72/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5663 - acc: 0.6418 - val_loss: 13.9292 - val_acc: 0.5329\n",
      "Epoch 73/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5534 - acc: 0.6391 - val_loss: 13.9179 - val_acc: 0.5412\n",
      "Epoch 74/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5463 - acc: 0.6421 - val_loss: 13.9182 - val_acc: 0.5424\n",
      "Epoch 75/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5356 - acc: 0.6465 - val_loss: 13.9071 - val_acc: 0.5496\n",
      "Epoch 76/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5156 - acc: 0.6544 - val_loss: 13.9025 - val_acc: 0.5388\n",
      "Epoch 77/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5168 - acc: 0.6507 - val_loss: 13.8980 - val_acc: 0.5317\n",
      "Epoch 78/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5003 - acc: 0.6619 - val_loss: 13.9039 - val_acc: 0.5484\n",
      "Epoch 79/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4969 - acc: 0.6567 - val_loss: 13.8714 - val_acc: 0.5783\n",
      "Epoch 80/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4871 - acc: 0.6589 - val_loss: 13.8929 - val_acc: 0.5364\n",
      "Epoch 81/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4813 - acc: 0.6605 - val_loss: 13.8680 - val_acc: 0.5747\n",
      "Epoch 82/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4701 - acc: 0.6612 - val_loss: 13.8757 - val_acc: 0.5591\n",
      "Epoch 83/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4599 - acc: 0.6711 - val_loss: 13.8778 - val_acc: 0.5508\n",
      "Epoch 84/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4570 - acc: 0.6651 - val_loss: 13.8598 - val_acc: 0.5556\n",
      "Epoch 85/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4375 - acc: 0.6744 - val_loss: 13.8642 - val_acc: 0.5675\n",
      "Epoch 86/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4373 - acc: 0.6718 - val_loss: 13.8635 - val_acc: 0.5591\n",
      "Epoch 87/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4270 - acc: 0.6746 - val_loss: 13.8641 - val_acc: 0.5579\n",
      "Epoch 88/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4197 - acc: 0.6777 - val_loss: 13.8511 - val_acc: 0.5962\n",
      "Epoch 89/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4083 - acc: 0.6855 - val_loss: 13.8441 - val_acc: 0.5818\n",
      "Epoch 90/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4053 - acc: 0.6805 - val_loss: 13.8395 - val_acc: 0.5759\n",
      "Epoch 91/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3846 - acc: 0.6891 - val_loss: 13.8269 - val_acc: 0.6141\n",
      "Epoch 92/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3876 - acc: 0.6835 - val_loss: 13.8293 - val_acc: 0.6081\n",
      "Epoch 93/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3750 - acc: 0.6879 - val_loss: 13.8406 - val_acc: 0.5544\n",
      "Epoch 94/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3685 - acc: 0.6937 - val_loss: 13.8257 - val_acc: 0.6177\n",
      "Epoch 95/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3644 - acc: 0.6891 - val_loss: 13.8218 - val_acc: 0.5759\n",
      "Epoch 96/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3491 - acc: 0.6937 - val_loss: 13.8287 - val_acc: 0.5759\n",
      "Epoch 97/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3411 - acc: 0.7003 - val_loss: 13.8086 - val_acc: 0.6057\n",
      "Epoch 98/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3373 - acc: 0.6934 - val_loss: 13.7962 - val_acc: 0.6225\n",
      "Epoch 99/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3340 - acc: 0.7002 - val_loss: 13.8158 - val_acc: 0.5902\n",
      "Epoch 100/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3216 - acc: 0.7026 - val_loss: 13.7884 - val_acc: 0.6308\n",
      "Epoch 101/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3132 - acc: 0.7055 - val_loss: 13.8012 - val_acc: 0.5938\n",
      "Epoch 102/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3087 - acc: 0.7025 - val_loss: 13.8024 - val_acc: 0.6057\n",
      "Epoch 103/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2972 - acc: 0.7069 - val_loss: 13.7745 - val_acc: 0.6201\n",
      "Epoch 104/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.2914 - acc: 0.7055 - val_loss: 13.7870 - val_acc: 0.6117\n",
      "Epoch 105/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2804 - acc: 0.7123 - val_loss: 13.7791 - val_acc: 0.5986\n",
      "Epoch 106/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2750 - acc: 0.7141 - val_loss: 13.7627 - val_acc: 0.6332\n",
      "Epoch 107/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2669 - acc: 0.7110 - val_loss: 13.7801 - val_acc: 0.5890\n",
      "Epoch 108/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2584 - acc: 0.7146 - val_loss: 13.7593 - val_acc: 0.6284\n",
      "Epoch 109/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2533 - acc: 0.7170 - val_loss: 13.7568 - val_acc: 0.6237\n",
      "Epoch 110/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2457 - acc: 0.7187 - val_loss: 13.7506 - val_acc: 0.6237\n",
      "Epoch 111/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2339 - acc: 0.7220 - val_loss: 13.7558 - val_acc: 0.6260\n",
      "Epoch 112/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2328 - acc: 0.7203 - val_loss: 13.7614 - val_acc: 0.6117\n",
      "Epoch 113/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2181 - acc: 0.7243 - val_loss: 13.7523 - val_acc: 0.6153\n",
      "Epoch 114/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2093 - acc: 0.7255 - val_loss: 13.7474 - val_acc: 0.6129\n",
      "Epoch 115/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2024 - acc: 0.7262 - val_loss: 13.7465 - val_acc: 0.6237\n",
      "Epoch 116/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2024 - acc: 0.7243 - val_loss: 13.7508 - val_acc: 0.6081\n",
      "Epoch 117/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1927 - acc: 0.7272 - val_loss: 13.7284 - val_acc: 0.6332\n",
      "Epoch 118/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1814 - acc: 0.7330 - val_loss: 13.7223 - val_acc: 0.6237\n",
      "Epoch 119/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1851 - acc: 0.7288 - val_loss: 13.7140 - val_acc: 0.6380\n",
      "Epoch 120/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1678 - acc: 0.7340 - val_loss: 13.7244 - val_acc: 0.6213\n",
      "Epoch 121/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1688 - acc: 0.7279 - val_loss: 13.7023 - val_acc: 0.6320\n",
      "Epoch 122/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1582 - acc: 0.7284 - val_loss: 13.7003 - val_acc: 0.6368\n",
      "Epoch 123/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1515 - acc: 0.7354 - val_loss: 13.6957 - val_acc: 0.6356\n",
      "Epoch 124/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1419 - acc: 0.7400 - val_loss: 13.7110 - val_acc: 0.6284\n",
      "Epoch 125/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.1344 - acc: 0.7366 - val_loss: 13.7066 - val_acc: 0.6332\n",
      "Epoch 126/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1193 - acc: 0.7378 - val_loss: 13.6938 - val_acc: 0.6320\n",
      "Epoch 127/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1212 - acc: 0.7439 - val_loss: 13.6970 - val_acc: 0.6356\n",
      "Epoch 128/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1222 - acc: 0.7371 - val_loss: 13.6873 - val_acc: 0.6344\n",
      "Epoch 129/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1019 - acc: 0.7439 - val_loss: 13.6847 - val_acc: 0.6320\n",
      "Epoch 130/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.0890 - acc: 0.7456 - val_loss: 13.7021 - val_acc: 0.6177\n",
      "Epoch 131/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0992 - acc: 0.7443 - val_loss: 13.6725 - val_acc: 0.6392\n",
      "Epoch 132/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.0821 - acc: 0.7498 - val_loss: 13.6749 - val_acc: 0.6428\n",
      "Epoch 133/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.0814 - acc: 0.7521 - val_loss: 13.6738 - val_acc: 0.6368\n",
      "Epoch 134/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0758 - acc: 0.7481 - val_loss: 13.6786 - val_acc: 0.6332\n",
      "Epoch 135/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0599 - acc: 0.7551 - val_loss: 13.6470 - val_acc: 0.6416\n",
      "Epoch 136/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0540 - acc: 0.7619 - val_loss: 13.6512 - val_acc: 0.6404\n",
      "Epoch 137/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0523 - acc: 0.7524 - val_loss: 13.6707 - val_acc: 0.6404\n",
      "Epoch 138/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.0461 - acc: 0.7578 - val_loss: 13.6414 - val_acc: 0.6428\n",
      "Epoch 139/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0399 - acc: 0.7570 - val_loss: 13.6439 - val_acc: 0.6404\n",
      "Epoch 140/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.0337 - acc: 0.7597 - val_loss: 13.6319 - val_acc: 0.6356\n",
      "Epoch 141/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.0261 - acc: 0.7560 - val_loss: 13.6360 - val_acc: 0.6392\n",
      "Epoch 142/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.0099 - acc: 0.7683 - val_loss: 13.6421 - val_acc: 0.6416\n",
      "Epoch 143/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.0009 - acc: 0.7666 - val_loss: 13.6332 - val_acc: 0.6368\n",
      "Epoch 144/150\n",
      "6954/6954 [==============================] - 3s - loss: 12.9948 - acc: 0.7649 - val_loss: 13.6430 - val_acc: 0.6404\n",
      "Epoch 145/150\n",
      "6954/6954 [==============================] - 3s - loss: 12.9948 - acc: 0.7663 - val_loss: 13.6455 - val_acc: 0.6308\n",
      "Epoch 146/150\n",
      "6954/6954 [==============================] - 2s - loss: 12.9982 - acc: 0.7622 - val_loss: 13.6465 - val_acc: 0.6296\n",
      "Epoch 147/150\n",
      "6954/6954 [==============================] - 3s - loss: 12.9813 - acc: 0.7722 - val_loss: 13.6248 - val_acc: 0.6392\n",
      "Epoch 148/150\n",
      "6954/6954 [==============================] - 3s - loss: 12.9732 - acc: 0.7682 - val_loss: 13.6278 - val_acc: 0.6356\n",
      "Epoch 149/150\n",
      "6954/6954 [==============================] - 3s - loss: 12.9642 - acc: 0.7748 - val_loss: 13.6240 - val_acc: 0.6380\n",
      "Epoch 150/150\n",
      "6954/6954 [==============================] - 3s - loss: 12.9595 - acc: 0.7744 - val_loss: 13.6083 - val_acc: 0.6404\n",
      "training time: 475.4227273464203\n",
      "928/936 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.6517\n",
      "\n",
      "Error Rate = 0.3483\n",
      "training time: 0.7722606658935547\n",
      "opening fold: 6\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8425071239471436\n",
      "Scaling time: 0.22333455085754395\n",
      "Scaling time: 0.21905994415283203\n",
      "training model...hold tight\n",
      "Train on 7067 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7067/7067 [==============================] - 9s - loss: 15.1388 - acc: 0.1136 - val_loss: 15.0371 - val_acc: 0.1924\n",
      "Epoch 2/150\n",
      "7067/7067 [==============================] - 3s - loss: 15.0504 - acc: 0.1524 - val_loss: 14.9609 - val_acc: 0.1995\n",
      "Epoch 3/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.9844 - acc: 0.1825 - val_loss: 14.8832 - val_acc: 0.2652\n",
      "Epoch 4/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.9062 - acc: 0.2258 - val_loss: 14.8075 - val_acc: 0.2832\n",
      "Epoch 5/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.8391 - acc: 0.2376 - val_loss: 14.7366 - val_acc: 0.3082\n",
      "Epoch 6/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.7662 - acc: 0.2578 - val_loss: 14.6650 - val_acc: 0.2748\n",
      "Epoch 7/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.7087 - acc: 0.2747 - val_loss: 14.6059 - val_acc: 0.3023\n",
      "Epoch 8/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.6440 - acc: 0.2863 - val_loss: 14.5584 - val_acc: 0.3214\n",
      "Epoch 9/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.6011 - acc: 0.3099 - val_loss: 14.5224 - val_acc: 0.3489\n",
      "Epoch 10/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.5573 - acc: 0.3280 - val_loss: 14.4954 - val_acc: 0.3059\n",
      "Epoch 11/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.5157 - acc: 0.3460 - val_loss: 14.4659 - val_acc: 0.3238\n",
      "Epoch 12/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.4786 - acc: 0.3533 - val_loss: 14.4323 - val_acc: 0.3286\n",
      "Epoch 13/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.4414 - acc: 0.3689 - val_loss: 14.4092 - val_acc: 0.3333\n",
      "Epoch 14/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.4181 - acc: 0.3877 - val_loss: 14.3908 - val_acc: 0.3716\n",
      "Epoch 15/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3871 - acc: 0.4022 - val_loss: 14.3539 - val_acc: 0.3799\n",
      "Epoch 16/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3476 - acc: 0.4037 - val_loss: 14.3214 - val_acc: 0.4421\n",
      "Epoch 17/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3055 - acc: 0.4338 - val_loss: 14.3090 - val_acc: 0.4026\n",
      "Epoch 18/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2922 - acc: 0.4329 - val_loss: 14.2799 - val_acc: 0.4194\n",
      "Epoch 19/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2509 - acc: 0.4392 - val_loss: 14.2675 - val_acc: 0.4612\n",
      "Epoch 20/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2313 - acc: 0.4515 - val_loss: 14.2503 - val_acc: 0.4432\n",
      "Epoch 21/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1960 - acc: 0.4603 - val_loss: 14.2438 - val_acc: 0.4922\n",
      "Epoch 22/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1775 - acc: 0.4617 - val_loss: 14.2268 - val_acc: 0.4421\n",
      "Epoch 23/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1619 - acc: 0.4733 - val_loss: 14.2066 - val_acc: 0.4659\n",
      "Epoch 24/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1307 - acc: 0.4834 - val_loss: 14.1744 - val_acc: 0.4839\n",
      "Epoch 25/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1186 - acc: 0.4729 - val_loss: 14.1762 - val_acc: 0.4456\n",
      "Epoch 26/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1038 - acc: 0.4863 - val_loss: 14.1695 - val_acc: 0.4122\n",
      "Epoch 27/150\n",
      "7067/7067 [==============================] - 4s - loss: 14.0818 - acc: 0.4842 - val_loss: 14.1663 - val_acc: 0.4588\n",
      "Epoch 28/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0604 - acc: 0.4933 - val_loss: 14.1420 - val_acc: 0.4468\n",
      "Epoch 29/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0460 - acc: 0.4975 - val_loss: 14.1674 - val_acc: 0.4217\n",
      "Epoch 30/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0381 - acc: 0.4989 - val_loss: 14.1408 - val_acc: 0.4182\n",
      "Epoch 31/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0055 - acc: 0.5131 - val_loss: 14.1702 - val_acc: 0.4803\n",
      "Epoch 32/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0018 - acc: 0.5046 - val_loss: 14.1354 - val_acc: 0.4815\n",
      "Epoch 33/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9827 - acc: 0.5226 - val_loss: 14.0961 - val_acc: 0.4767\n",
      "Epoch 34/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9721 - acc: 0.5108 - val_loss: 14.0996 - val_acc: 0.4480\n",
      "Epoch 35/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9474 - acc: 0.5250 - val_loss: 14.0747 - val_acc: 0.5114\n",
      "Epoch 36/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9462 - acc: 0.5321 - val_loss: 14.0704 - val_acc: 0.4707\n",
      "Epoch 37/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9192 - acc: 0.5414 - val_loss: 14.0778 - val_acc: 0.4385\n",
      "Epoch 38/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9044 - acc: 0.5362 - val_loss: 14.0454 - val_acc: 0.5388\n",
      "Epoch 39/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8918 - acc: 0.5417 - val_loss: 14.0583 - val_acc: 0.4970\n",
      "Epoch 40/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8784 - acc: 0.5437 - val_loss: 14.0343 - val_acc: 0.5376\n",
      "Epoch 41/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8656 - acc: 0.5517 - val_loss: 14.0424 - val_acc: 0.4695\n",
      "Epoch 42/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8578 - acc: 0.5565 - val_loss: 14.0412 - val_acc: 0.4779\n",
      "Epoch 43/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8477 - acc: 0.5596 - val_loss: 14.0135 - val_acc: 0.4958\n",
      "Epoch 44/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8308 - acc: 0.5572 - val_loss: 14.0150 - val_acc: 0.5078\n",
      "Epoch 45/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8188 - acc: 0.5618 - val_loss: 14.0100 - val_acc: 0.4731\n",
      "Epoch 46/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8051 - acc: 0.5700 - val_loss: 13.9922 - val_acc: 0.4910\n",
      "Epoch 47/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7878 - acc: 0.5694 - val_loss: 13.9833 - val_acc: 0.4851\n",
      "Epoch 48/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7735 - acc: 0.5762 - val_loss: 14.0045 - val_acc: 0.5173\n",
      "Epoch 49/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7696 - acc: 0.5738 - val_loss: 13.9881 - val_acc: 0.5472\n",
      "Epoch 50/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7516 - acc: 0.5804 - val_loss: 14.0257 - val_acc: 0.4421\n",
      "Epoch 51/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7507 - acc: 0.5800 - val_loss: 13.9660 - val_acc: 0.5639\n",
      "Epoch 52/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7373 - acc: 0.5828 - val_loss: 13.9566 - val_acc: 0.5054\n",
      "Epoch 53/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7276 - acc: 0.5837 - val_loss: 13.9524 - val_acc: 0.4863\n",
      "Epoch 54/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7213 - acc: 0.5932 - val_loss: 13.9619 - val_acc: 0.5460\n",
      "Epoch 55/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.7036 - acc: 0.5964 - val_loss: 13.9502 - val_acc: 0.4982\n",
      "Epoch 56/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6851 - acc: 0.6052 - val_loss: 13.9522 - val_acc: 0.5030\n",
      "Epoch 57/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6858 - acc: 0.6039 - val_loss: 13.9358 - val_acc: 0.5400\n",
      "Epoch 58/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6613 - acc: 0.6126 - val_loss: 13.9188 - val_acc: 0.5018\n",
      "Epoch 59/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6514 - acc: 0.6140 - val_loss: 13.9060 - val_acc: 0.5866\n",
      "Epoch 60/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6472 - acc: 0.6134 - val_loss: 13.8986 - val_acc: 0.5591\n",
      "Epoch 61/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6467 - acc: 0.6123 - val_loss: 13.9118 - val_acc: 0.5508\n",
      "Epoch 62/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6225 - acc: 0.6203 - val_loss: 13.9187 - val_acc: 0.5496\n",
      "Epoch 63/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6206 - acc: 0.6202 - val_loss: 13.9166 - val_acc: 0.5472\n",
      "Epoch 64/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6058 - acc: 0.6199 - val_loss: 13.8812 - val_acc: 0.5699\n",
      "Epoch 65/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5927 - acc: 0.6303 - val_loss: 13.9061 - val_acc: 0.5281\n",
      "Epoch 66/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5820 - acc: 0.6317 - val_loss: 13.8748 - val_acc: 0.5054\n",
      "Epoch 67/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5645 - acc: 0.6382 - val_loss: 13.8805 - val_acc: 0.5460\n",
      "Epoch 68/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5582 - acc: 0.6441 - val_loss: 13.8797 - val_acc: 0.5568\n",
      "Epoch 69/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5456 - acc: 0.6472 - val_loss: 13.9366 - val_acc: 0.5496\n",
      "Epoch 70/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5469 - acc: 0.6403 - val_loss: 13.8801 - val_acc: 0.5830\n",
      "Epoch 71/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5317 - acc: 0.6430 - val_loss: 13.8614 - val_acc: 0.5424\n",
      "Epoch 72/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5219 - acc: 0.6471 - val_loss: 13.9123 - val_acc: 0.5747\n",
      "Epoch 73/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5219 - acc: 0.6535 - val_loss: 13.8454 - val_acc: 0.5114\n",
      "Epoch 74/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.5070 - acc: 0.6605 - val_loss: 13.8324 - val_acc: 0.5735\n",
      "Epoch 75/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4949 - acc: 0.6621 - val_loss: 13.8637 - val_acc: 0.5508\n",
      "Epoch 76/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4822 - acc: 0.6644 - val_loss: 13.8234 - val_acc: 0.5842\n",
      "Epoch 77/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4716 - acc: 0.6645 - val_loss: 13.8268 - val_acc: 0.5137\n",
      "Epoch 78/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4575 - acc: 0.6723 - val_loss: 13.8151 - val_acc: 0.6033\n",
      "Epoch 79/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4565 - acc: 0.6624 - val_loss: 13.8508 - val_acc: 0.5544\n",
      "Epoch 80/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4407 - acc: 0.6757 - val_loss: 13.8060 - val_acc: 0.5783\n",
      "Epoch 81/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4294 - acc: 0.6731 - val_loss: 13.8809 - val_acc: 0.5412\n",
      "Epoch 82/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4328 - acc: 0.6706 - val_loss: 13.8358 - val_acc: 0.5400\n",
      "Epoch 83/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4222 - acc: 0.6753 - val_loss: 13.8002 - val_acc: 0.5854\n",
      "Epoch 84/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4040 - acc: 0.6789 - val_loss: 13.8202 - val_acc: 0.5627\n",
      "Epoch 85/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3922 - acc: 0.6854 - val_loss: 13.8520 - val_acc: 0.5245\n",
      "Epoch 86/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4045 - acc: 0.6743 - val_loss: 13.7926 - val_acc: 0.5890\n",
      "Epoch 87/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3759 - acc: 0.6887 - val_loss: 13.8245 - val_acc: 0.5054\n",
      "Epoch 88/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3801 - acc: 0.6811 - val_loss: 13.7742 - val_acc: 0.6129\n",
      "Epoch 89/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3638 - acc: 0.6884 - val_loss: 13.7561 - val_acc: 0.6153\n",
      "Epoch 90/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3555 - acc: 0.6852 - val_loss: 13.8682 - val_acc: 0.5747\n",
      "Epoch 91/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3556 - acc: 0.6895 - val_loss: 13.7602 - val_acc: 0.5950\n",
      "Epoch 92/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3388 - acc: 0.6938 - val_loss: 13.7413 - val_acc: 0.6225\n",
      "Epoch 93/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3236 - acc: 0.6985 - val_loss: 13.7733 - val_acc: 0.5866\n",
      "Epoch 94/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3084 - acc: 0.7006 - val_loss: 13.7519 - val_acc: 0.6129\n",
      "Epoch 95/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3010 - acc: 0.6987 - val_loss: 13.7935 - val_acc: 0.5687\n",
      "Epoch 96/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2902 - acc: 0.7074 - val_loss: 13.8256 - val_acc: 0.5699\n",
      "Epoch 97/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2820 - acc: 0.7037 - val_loss: 13.7453 - val_acc: 0.5914\n",
      "Epoch 98/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2750 - acc: 0.7075 - val_loss: 13.7380 - val_acc: 0.6010\n",
      "Epoch 99/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2687 - acc: 0.7079 - val_loss: 13.7625 - val_acc: 0.5699\n",
      "Epoch 100/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2825 - acc: 0.6996 - val_loss: 13.7161 - val_acc: 0.6081\n",
      "Epoch 101/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2595 - acc: 0.7085 - val_loss: 13.7386 - val_acc: 0.6249\n",
      "Epoch 102/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2503 - acc: 0.7102 - val_loss: 13.7265 - val_acc: 0.6069\n",
      "Epoch 103/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2351 - acc: 0.7170 - val_loss: 13.7734 - val_acc: 0.5974\n",
      "Epoch 104/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2278 - acc: 0.7210 - val_loss: 13.7162 - val_acc: 0.6105\n",
      "Epoch 105/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2098 - acc: 0.7221 - val_loss: 13.7030 - val_acc: 0.6165\n",
      "Epoch 106/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2179 - acc: 0.7139 - val_loss: 13.7103 - val_acc: 0.6022\n",
      "Epoch 107/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2043 - acc: 0.7224 - val_loss: 13.7093 - val_acc: 0.5591\n",
      "Epoch 108/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2062 - acc: 0.7160 - val_loss: 13.6847 - val_acc: 0.6093\n",
      "Epoch 109/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1896 - acc: 0.7218 - val_loss: 13.6880 - val_acc: 0.5687\n",
      "Epoch 110/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.1765 - acc: 0.7299 - val_loss: 13.6827 - val_acc: 0.6308\n",
      "Epoch 111/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1755 - acc: 0.7263 - val_loss: 13.6862 - val_acc: 0.6093\n",
      "Epoch 112/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1580 - acc: 0.7297 - val_loss: 13.7775 - val_acc: 0.6033\n",
      "Epoch 113/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1586 - acc: 0.7280 - val_loss: 13.6894 - val_acc: 0.6093\n",
      "Epoch 114/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1463 - acc: 0.7330 - val_loss: 13.6701 - val_acc: 0.6010\n",
      "Epoch 115/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1451 - acc: 0.7286 - val_loss: 13.6854 - val_acc: 0.6117\n",
      "Epoch 116/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1326 - acc: 0.7394 - val_loss: 13.6816 - val_acc: 0.6225\n",
      "Epoch 117/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1253 - acc: 0.7398 - val_loss: 13.6526 - val_acc: 0.6153\n",
      "Epoch 118/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1228 - acc: 0.7343 - val_loss: 13.6534 - val_acc: 0.6260\n",
      "Epoch 119/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1145 - acc: 0.7381 - val_loss: 13.6617 - val_acc: 0.6177\n",
      "Epoch 120/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1049 - acc: 0.7447 - val_loss: 13.6320 - val_acc: 0.6404\n",
      "Epoch 121/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0919 - acc: 0.7396 - val_loss: 13.6452 - val_acc: 0.6284\n",
      "Epoch 122/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0921 - acc: 0.7403 - val_loss: 13.6462 - val_acc: 0.6010\n",
      "Epoch 123/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0889 - acc: 0.7429 - val_loss: 13.6518 - val_acc: 0.6260\n",
      "Epoch 124/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0692 - acc: 0.7505 - val_loss: 13.6342 - val_acc: 0.6105\n",
      "Epoch 125/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0694 - acc: 0.7484 - val_loss: 13.6120 - val_acc: 0.6189\n",
      "Epoch 126/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0546 - acc: 0.7504 - val_loss: 13.6131 - val_acc: 0.6129\n",
      "Epoch 127/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0389 - acc: 0.7542 - val_loss: 13.6620 - val_acc: 0.5986\n",
      "Epoch 128/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0397 - acc: 0.7484 - val_loss: 13.6081 - val_acc: 0.6249\n",
      "Epoch 129/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0215 - acc: 0.7589 - val_loss: 13.6220 - val_acc: 0.6189\n",
      "Epoch 130/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0369 - acc: 0.7469 - val_loss: 13.5765 - val_acc: 0.6428\n",
      "Epoch 131/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.0143 - acc: 0.7548 - val_loss: 13.5920 - val_acc: 0.6368\n",
      "Epoch 132/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0136 - acc: 0.7495 - val_loss: 13.5751 - val_acc: 0.6225\n",
      "Epoch 133/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0069 - acc: 0.7552 - val_loss: 13.6025 - val_acc: 0.6057\n",
      "Epoch 134/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9949 - acc: 0.7586 - val_loss: 13.5791 - val_acc: 0.6284\n",
      "Epoch 135/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9879 - acc: 0.7566 - val_loss: 13.5946 - val_acc: 0.6129\n",
      "Epoch 136/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9889 - acc: 0.7539 - val_loss: 13.5922 - val_acc: 0.6022\n",
      "Epoch 137/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9734 - acc: 0.7579 - val_loss: 13.5932 - val_acc: 0.6117\n",
      "Epoch 138/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9745 - acc: 0.7602 - val_loss: 13.5825 - val_acc: 0.6093\n",
      "Epoch 139/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9544 - acc: 0.7664 - val_loss: 13.5700 - val_acc: 0.6153\n",
      "Epoch 140/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9483 - acc: 0.7677 - val_loss: 13.5496 - val_acc: 0.6272\n",
      "Epoch 141/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9316 - acc: 0.7740 - val_loss: 13.5433 - val_acc: 0.6272\n",
      "Epoch 142/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9388 - acc: 0.7716 - val_loss: 13.5356 - val_acc: 0.6225\n",
      "Epoch 143/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9234 - acc: 0.7726 - val_loss: 13.5958 - val_acc: 0.6284\n",
      "Epoch 144/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9238 - acc: 0.7655 - val_loss: 13.5672 - val_acc: 0.6057\n",
      "Epoch 145/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9112 - acc: 0.7712 - val_loss: 13.5789 - val_acc: 0.5806\n",
      "Epoch 146/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9144 - acc: 0.7688 - val_loss: 13.5097 - val_acc: 0.6464\n",
      "Epoch 147/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.9000 - acc: 0.7767 - val_loss: 13.5045 - val_acc: 0.6535\n",
      "Epoch 148/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.8963 - acc: 0.7785 - val_loss: 13.5174 - val_acc: 0.6249\n",
      "Epoch 149/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.8921 - acc: 0.7749 - val_loss: 13.5598 - val_acc: 0.6177\n",
      "Epoch 150/150\n",
      "7067/7067 [==============================] - 3s - loss: 12.8912 - acc: 0.7735 - val_loss: 13.5023 - val_acc: 0.6296\n",
      "training time: 479.446683883667\n",
      "800/823 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.5942\n",
      "\n",
      "Error Rate = 0.4058\n",
      "training time: 0.6723911762237549\n",
      "opening fold: 7\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8387424945831299\n",
      "Scaling time: 0.22417449951171875\n",
      "Scaling time: 0.22487759590148926\n",
      "training model...hold tight\n",
      "Train on 7052 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7052/7052 [==============================] - 9s - loss: 15.1424 - acc: 0.0967 - val_loss: 15.0647 - val_acc: 0.1888\n",
      "Epoch 2/150\n",
      "7052/7052 [==============================] - 2s - loss: 15.0645 - acc: 0.1536 - val_loss: 14.9956 - val_acc: 0.1971\n",
      "Epoch 3/150\n",
      "7052/7052 [==============================] - 3s - loss: 15.0031 - acc: 0.1763 - val_loss: 14.9341 - val_acc: 0.2330\n",
      "Epoch 4/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.9395 - acc: 0.2067 - val_loss: 14.8696 - val_acc: 0.2616\n",
      "Epoch 5/150\n",
      "7052/7052 [==============================] - 2s - loss: 14.8792 - acc: 0.2328 - val_loss: 14.8060 - val_acc: 0.2688\n",
      "Epoch 6/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.8179 - acc: 0.2509 - val_loss: 14.7445 - val_acc: 0.2855\n",
      "Epoch 7/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.7580 - acc: 0.2646 - val_loss: 14.6843 - val_acc: 0.2915\n",
      "Epoch 8/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.6951 - acc: 0.2900 - val_loss: 14.6279 - val_acc: 0.3178\n",
      "Epoch 9/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.6480 - acc: 0.2884 - val_loss: 14.5827 - val_acc: 0.3333\n",
      "Epoch 10/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5957 - acc: 0.3084 - val_loss: 14.5503 - val_acc: 0.2963\n",
      "Epoch 11/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5562 - acc: 0.3274 - val_loss: 14.5238 - val_acc: 0.2891\n",
      "Epoch 12/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5151 - acc: 0.3412 - val_loss: 14.4947 - val_acc: 0.3572\n",
      "Epoch 13/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.4786 - acc: 0.3619 - val_loss: 14.4621 - val_acc: 0.3775\n",
      "Epoch 14/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.4446 - acc: 0.3666 - val_loss: 14.4332 - val_acc: 0.3811\n",
      "Epoch 15/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.4075 - acc: 0.3897 - val_loss: 14.4109 - val_acc: 0.3967\n",
      "Epoch 16/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3688 - acc: 0.4058 - val_loss: 14.3658 - val_acc: 0.3704\n",
      "Epoch 17/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3370 - acc: 0.4159 - val_loss: 14.3609 - val_acc: 0.3883\n",
      "Epoch 18/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3197 - acc: 0.4236 - val_loss: 14.3341 - val_acc: 0.4074\n",
      "Epoch 19/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2816 - acc: 0.4358 - val_loss: 14.3038 - val_acc: 0.3775\n",
      "Epoch 20/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2453 - acc: 0.4343 - val_loss: 14.2965 - val_acc: 0.3883\n",
      "Epoch 21/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2237 - acc: 0.4545 - val_loss: 14.2873 - val_acc: 0.4361\n",
      "Epoch 22/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1961 - acc: 0.4594 - val_loss: 14.2811 - val_acc: 0.4038\n",
      "Epoch 23/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1764 - acc: 0.4603 - val_loss: 14.2643 - val_acc: 0.4158\n",
      "Epoch 24/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1602 - acc: 0.4709 - val_loss: 14.2240 - val_acc: 0.4492\n",
      "Epoch 25/150\n",
      "7052/7052 [==============================] - 2s - loss: 14.1323 - acc: 0.4702 - val_loss: 14.2617 - val_acc: 0.3811\n",
      "Epoch 26/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1259 - acc: 0.4728 - val_loss: 14.2251 - val_acc: 0.4313\n",
      "Epoch 27/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0940 - acc: 0.4864 - val_loss: 14.2078 - val_acc: 0.4217\n",
      "Epoch 28/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0698 - acc: 0.5026 - val_loss: 14.1820 - val_acc: 0.4205\n",
      "Epoch 29/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0518 - acc: 0.4942 - val_loss: 14.2000 - val_acc: 0.3955\n",
      "Epoch 30/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0377 - acc: 0.5035 - val_loss: 14.1613 - val_acc: 0.4086\n",
      "Epoch 31/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0150 - acc: 0.4979 - val_loss: 14.1627 - val_acc: 0.4421\n",
      "Epoch 32/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0123 - acc: 0.5099 - val_loss: 14.1399 - val_acc: 0.3978\n",
      "Epoch 33/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9842 - acc: 0.5176 - val_loss: 14.1265 - val_acc: 0.4540\n",
      "Epoch 34/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9582 - acc: 0.5244 - val_loss: 14.1242 - val_acc: 0.4050\n",
      "Epoch 35/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9640 - acc: 0.5213 - val_loss: 14.1139 - val_acc: 0.4600\n",
      "Epoch 36/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9418 - acc: 0.5208 - val_loss: 14.1265 - val_acc: 0.4648\n",
      "Epoch 37/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9330 - acc: 0.5247 - val_loss: 14.1196 - val_acc: 0.4480\n",
      "Epoch 38/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9190 - acc: 0.5319 - val_loss: 14.1397 - val_acc: 0.4229\n",
      "Epoch 39/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9108 - acc: 0.5262 - val_loss: 14.1050 - val_acc: 0.4205\n",
      "Epoch 40/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8896 - acc: 0.5286 - val_loss: 14.0828 - val_acc: 0.4743\n",
      "Epoch 41/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8738 - acc: 0.5390 - val_loss: 14.0799 - val_acc: 0.4540\n",
      "Epoch 42/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8600 - acc: 0.5493 - val_loss: 14.0657 - val_acc: 0.4516\n",
      "Epoch 43/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8489 - acc: 0.5435 - val_loss: 14.0511 - val_acc: 0.4624\n",
      "Epoch 44/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8297 - acc: 0.5512 - val_loss: 14.1002 - val_acc: 0.4241\n",
      "Epoch 45/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8199 - acc: 0.5559 - val_loss: 14.0910 - val_acc: 0.4170\n",
      "Epoch 46/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8098 - acc: 0.5584 - val_loss: 14.0668 - val_acc: 0.4659\n",
      "Epoch 47/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7924 - acc: 0.5716 - val_loss: 14.0578 - val_acc: 0.4755\n",
      "Epoch 48/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7815 - acc: 0.5764 - val_loss: 14.0287 - val_acc: 0.4922\n",
      "Epoch 49/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7719 - acc: 0.5740 - val_loss: 14.0292 - val_acc: 0.4886\n",
      "Epoch 50/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7526 - acc: 0.5743 - val_loss: 14.0787 - val_acc: 0.4444\n",
      "Epoch 51/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7455 - acc: 0.5803 - val_loss: 14.0390 - val_acc: 0.4803\n",
      "Epoch 52/150\n",
      "7052/7052 [==============================] - 4s - loss: 13.7437 - acc: 0.5862 - val_loss: 13.9960 - val_acc: 0.4934\n",
      "Epoch 53/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7248 - acc: 0.5832 - val_loss: 14.0422 - val_acc: 0.4755\n",
      "Epoch 54/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7177 - acc: 0.5889 - val_loss: 14.0942 - val_acc: 0.4385\n",
      "Epoch 55/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7074 - acc: 0.5876 - val_loss: 13.9983 - val_acc: 0.4528\n",
      "Epoch 56/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6951 - acc: 0.5879 - val_loss: 13.9965 - val_acc: 0.4946\n",
      "Epoch 57/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6843 - acc: 0.5990 - val_loss: 14.0058 - val_acc: 0.4982\n",
      "Epoch 58/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6596 - acc: 0.6130 - val_loss: 13.9864 - val_acc: 0.4385\n",
      "Epoch 59/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6605 - acc: 0.6027 - val_loss: 13.9775 - val_acc: 0.4898\n",
      "Epoch 60/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6402 - acc: 0.6137 - val_loss: 13.9823 - val_acc: 0.4719\n",
      "Epoch 61/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6368 - acc: 0.6069 - val_loss: 13.9551 - val_acc: 0.4827\n",
      "Epoch 62/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6232 - acc: 0.6133 - val_loss: 14.0155 - val_acc: 0.5054\n",
      "Epoch 63/150\n",
      "7052/7052 [==============================] - 4s - loss: 13.6210 - acc: 0.6157 - val_loss: 13.9946 - val_acc: 0.4540\n",
      "Epoch 64/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6041 - acc: 0.6229 - val_loss: 14.0038 - val_acc: 0.4910\n",
      "Epoch 65/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5898 - acc: 0.6224 - val_loss: 13.9444 - val_acc: 0.4875\n",
      "Epoch 66/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5799 - acc: 0.6288 - val_loss: 13.9442 - val_acc: 0.4922\n",
      "Epoch 67/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5731 - acc: 0.6271 - val_loss: 14.0118 - val_acc: 0.4791\n",
      "Epoch 68/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5759 - acc: 0.6271 - val_loss: 13.9883 - val_acc: 0.4827\n",
      "Epoch 69/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5551 - acc: 0.6310 - val_loss: 13.9307 - val_acc: 0.4875\n",
      "Epoch 70/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5413 - acc: 0.6363 - val_loss: 13.9019 - val_acc: 0.5269\n",
      "Epoch 71/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5280 - acc: 0.6408 - val_loss: 13.9113 - val_acc: 0.5018\n",
      "Epoch 72/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5184 - acc: 0.6424 - val_loss: 13.9253 - val_acc: 0.4958\n",
      "Epoch 73/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5122 - acc: 0.6458 - val_loss: 13.9166 - val_acc: 0.4934\n",
      "Epoch 74/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4991 - acc: 0.6488 - val_loss: 13.8885 - val_acc: 0.5149\n",
      "Epoch 75/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4915 - acc: 0.6505 - val_loss: 13.8995 - val_acc: 0.4922\n",
      "Epoch 76/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4815 - acc: 0.6554 - val_loss: 13.8803 - val_acc: 0.4970\n",
      "Epoch 77/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4683 - acc: 0.6558 - val_loss: 13.8759 - val_acc: 0.4719\n",
      "Epoch 78/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4614 - acc: 0.6554 - val_loss: 13.8802 - val_acc: 0.5197\n",
      "Epoch 79/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4508 - acc: 0.6594 - val_loss: 13.9799 - val_acc: 0.5269\n",
      "Epoch 80/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4702 - acc: 0.6492 - val_loss: 13.8594 - val_acc: 0.5125\n",
      "Epoch 81/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4405 - acc: 0.6653 - val_loss: 13.8666 - val_acc: 0.4898\n",
      "Epoch 82/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4201 - acc: 0.6690 - val_loss: 13.8635 - val_acc: 0.4970\n",
      "Epoch 83/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4071 - acc: 0.6712 - val_loss: 13.8973 - val_acc: 0.5281\n",
      "Epoch 84/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4141 - acc: 0.6748 - val_loss: 13.8995 - val_acc: 0.4755\n",
      "Epoch 85/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3977 - acc: 0.6733 - val_loss: 13.8592 - val_acc: 0.5054\n",
      "Epoch 86/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3886 - acc: 0.6741 - val_loss: 13.8511 - val_acc: 0.5090\n",
      "Epoch 87/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3751 - acc: 0.6838 - val_loss: 13.8473 - val_acc: 0.4994\n",
      "Epoch 88/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3732 - acc: 0.6815 - val_loss: 13.8669 - val_acc: 0.5639\n",
      "Epoch 89/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3665 - acc: 0.6873 - val_loss: 13.8783 - val_acc: 0.5317\n",
      "Epoch 90/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3687 - acc: 0.6792 - val_loss: 13.8984 - val_acc: 0.4934\n",
      "Epoch 91/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3611 - acc: 0.6768 - val_loss: 13.8057 - val_acc: 0.5615\n",
      "Epoch 92/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3395 - acc: 0.6883 - val_loss: 13.8942 - val_acc: 0.4934\n",
      "Epoch 93/150\n",
      "7052/7052 [==============================] - 4s - loss: 13.3407 - acc: 0.6843 - val_loss: 13.8101 - val_acc: 0.5568\n",
      "Epoch 94/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3238 - acc: 0.6868 - val_loss: 13.8560 - val_acc: 0.5030\n",
      "Epoch 95/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3114 - acc: 0.6916 - val_loss: 13.8138 - val_acc: 0.5926\n",
      "Epoch 96/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2987 - acc: 0.6987 - val_loss: 13.8137 - val_acc: 0.5520\n",
      "Epoch 97/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2855 - acc: 0.7050 - val_loss: 13.8610 - val_acc: 0.5042\n",
      "Epoch 98/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2883 - acc: 0.7005 - val_loss: 13.8459 - val_acc: 0.5771\n",
      "Epoch 99/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2773 - acc: 0.6991 - val_loss: 13.8355 - val_acc: 0.5245\n",
      "Epoch 100/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2760 - acc: 0.7035 - val_loss: 13.8180 - val_acc: 0.4683\n",
      "Epoch 101/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2655 - acc: 0.7035 - val_loss: 13.7838 - val_acc: 0.5388\n",
      "Epoch 102/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2485 - acc: 0.7130 - val_loss: 13.7761 - val_acc: 0.5448\n",
      "Epoch 103/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2447 - acc: 0.7092 - val_loss: 13.7852 - val_acc: 0.5687\n",
      "Epoch 104/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2354 - acc: 0.7117 - val_loss: 13.8091 - val_acc: 0.5221\n",
      "Epoch 105/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2180 - acc: 0.7163 - val_loss: 13.7702 - val_acc: 0.5352\n",
      "Epoch 106/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2211 - acc: 0.7083 - val_loss: 13.7667 - val_acc: 0.5412\n",
      "Epoch 107/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2122 - acc: 0.7155 - val_loss: 13.7508 - val_acc: 0.5627\n",
      "Epoch 108/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2045 - acc: 0.7192 - val_loss: 13.7581 - val_acc: 0.5269\n",
      "Epoch 109/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1997 - acc: 0.7192 - val_loss: 13.7759 - val_acc: 0.5030\n",
      "Epoch 110/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1863 - acc: 0.7232 - val_loss: 13.8198 - val_acc: 0.5496\n",
      "Epoch 111/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1851 - acc: 0.7198 - val_loss: 13.7270 - val_acc: 0.6165\n",
      "Epoch 112/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1699 - acc: 0.7206 - val_loss: 13.7423 - val_acc: 0.5484\n",
      "Epoch 113/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1569 - acc: 0.7306 - val_loss: 13.7904 - val_acc: 0.5245\n",
      "Epoch 114/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1520 - acc: 0.7337 - val_loss: 13.7514 - val_acc: 0.5520\n",
      "Epoch 115/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1490 - acc: 0.7294 - val_loss: 13.7330 - val_acc: 0.5699\n",
      "Epoch 116/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1420 - acc: 0.7293 - val_loss: 13.6961 - val_acc: 0.5986\n",
      "Epoch 117/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1434 - acc: 0.7208 - val_loss: 13.7733 - val_acc: 0.5376\n",
      "Epoch 118/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1320 - acc: 0.7338 - val_loss: 13.7901 - val_acc: 0.5890\n",
      "Epoch 119/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1316 - acc: 0.7323 - val_loss: 13.7129 - val_acc: 0.5603\n",
      "Epoch 120/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1084 - acc: 0.7364 - val_loss: 13.7152 - val_acc: 0.5699\n",
      "Epoch 121/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0964 - acc: 0.7385 - val_loss: 13.7622 - val_acc: 0.6105\n",
      "Epoch 122/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0929 - acc: 0.7399 - val_loss: 13.7663 - val_acc: 0.5771\n",
      "Epoch 123/150\n",
      "7052/7052 [==============================] - 4s - loss: 13.0888 - acc: 0.7351 - val_loss: 13.7243 - val_acc: 0.6141\n",
      "Epoch 124/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0758 - acc: 0.7483 - val_loss: 13.7225 - val_acc: 0.5460\n",
      "Epoch 125/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0655 - acc: 0.7419 - val_loss: 13.7079 - val_acc: 0.6045\n",
      "Epoch 126/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0646 - acc: 0.7491 - val_loss: 13.7419 - val_acc: 0.5711\n",
      "Epoch 127/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0517 - acc: 0.7480 - val_loss: 13.7916 - val_acc: 0.5448\n",
      "Epoch 128/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0674 - acc: 0.7431 - val_loss: 13.6992 - val_acc: 0.5568\n",
      "Epoch 129/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0456 - acc: 0.7466 - val_loss: 13.7023 - val_acc: 0.6284\n",
      "Epoch 130/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0338 - acc: 0.7499 - val_loss: 13.7248 - val_acc: 0.5197\n",
      "Epoch 131/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0263 - acc: 0.7537 - val_loss: 13.6700 - val_acc: 0.5890\n",
      "Epoch 132/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0171 - acc: 0.7526 - val_loss: 13.7069 - val_acc: 0.6022\n",
      "Epoch 133/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0072 - acc: 0.7578 - val_loss: 13.7155 - val_acc: 0.6069\n",
      "Epoch 134/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0033 - acc: 0.7534 - val_loss: 13.6473 - val_acc: 0.6201\n",
      "Epoch 135/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9938 - acc: 0.7606 - val_loss: 13.6545 - val_acc: 0.5902\n",
      "Epoch 136/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9932 - acc: 0.7554 - val_loss: 13.6922 - val_acc: 0.5806\n",
      "Epoch 137/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9832 - acc: 0.7569 - val_loss: 13.7464 - val_acc: 0.6213\n",
      "Epoch 138/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9934 - acc: 0.7579 - val_loss: 13.6706 - val_acc: 0.5830\n",
      "Epoch 139/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9741 - acc: 0.7596 - val_loss: 13.6543 - val_acc: 0.5974\n",
      "Epoch 140/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9535 - acc: 0.7673 - val_loss: 13.6458 - val_acc: 0.5950\n",
      "Epoch 141/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9431 - acc: 0.7667 - val_loss: 13.6397 - val_acc: 0.6260\n",
      "Epoch 142/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9301 - acc: 0.7716 - val_loss: 13.6359 - val_acc: 0.6033\n",
      "Epoch 143/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9257 - acc: 0.7700 - val_loss: 14.1207 - val_acc: 0.4456\n",
      "Epoch 144/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0255 - acc: 0.7395 - val_loss: 13.6415 - val_acc: 0.6153\n",
      "Epoch 145/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9233 - acc: 0.7694 - val_loss: 13.6068 - val_acc: 0.6416\n",
      "Epoch 146/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9156 - acc: 0.7646 - val_loss: 13.6095 - val_acc: 0.6153\n",
      "Epoch 147/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9236 - acc: 0.7642 - val_loss: 13.6632 - val_acc: 0.6105\n",
      "Epoch 148/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.9092 - acc: 0.7689 - val_loss: 13.6081 - val_acc: 0.6057\n",
      "Epoch 149/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.8936 - acc: 0.7781 - val_loss: 13.5833 - val_acc: 0.6392\n",
      "Epoch 150/150\n",
      "7052/7052 [==============================] - 3s - loss: 12.8794 - acc: 0.7812 - val_loss: 13.5817 - val_acc: 0.6201\n",
      "training time: 484.4681656360626\n",
      "800/838 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.6718\n",
      "\n",
      "Error Rate = 0.3282\n",
      "training time: 0.6893494129180908\n",
      "opening fold: 8\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8476030826568604\n",
      "Scaling time: 0.2231004238128662\n",
      "Scaling time: 0.2149677276611328\n",
      "training model...hold tight\n",
      "Train on 7084 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7084/7084 [==============================] - 9s - loss: 15.1196 - acc: 0.1110 - val_loss: 15.0388 - val_acc: 0.1732\n",
      "Epoch 2/150\n",
      "7084/7084 [==============================] - 3s - loss: 15.0400 - acc: 0.1661 - val_loss: 14.9672 - val_acc: 0.2079\n",
      "Epoch 3/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.9755 - acc: 0.2067 - val_loss: 14.8963 - val_acc: 0.2210\n",
      "Epoch 4/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.8888 - acc: 0.2336 - val_loss: 14.8268 - val_acc: 0.2640\n",
      "Epoch 5/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.8303 - acc: 0.2483 - val_loss: 14.7542 - val_acc: 0.2915\n",
      "Epoch 6/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.7712 - acc: 0.2623 - val_loss: 14.6883 - val_acc: 0.3047\n",
      "Epoch 7/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.7099 - acc: 0.2837 - val_loss: 14.6344 - val_acc: 0.2939\n",
      "Epoch 8/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.6587 - acc: 0.2925 - val_loss: 14.5890 - val_acc: 0.2772\n",
      "Epoch 9/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.6020 - acc: 0.3103 - val_loss: 14.5478 - val_acc: 0.3393\n",
      "Epoch 10/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.5646 - acc: 0.3178 - val_loss: 14.5148 - val_acc: 0.3262\n",
      "Epoch 11/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.5275 - acc: 0.3309 - val_loss: 14.4867 - val_acc: 0.3309\n",
      "Epoch 12/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4840 - acc: 0.3556 - val_loss: 14.4610 - val_acc: 0.4146\n",
      "Epoch 13/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4507 - acc: 0.3722 - val_loss: 14.4364 - val_acc: 0.3429\n",
      "Epoch 14/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4175 - acc: 0.3871 - val_loss: 14.4092 - val_acc: 0.3716\n",
      "Epoch 15/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3854 - acc: 0.3913 - val_loss: 14.3801 - val_acc: 0.3967\n",
      "Epoch 16/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3527 - acc: 0.4125 - val_loss: 14.3603 - val_acc: 0.3955\n",
      "Epoch 17/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3231 - acc: 0.4249 - val_loss: 14.3479 - val_acc: 0.3584\n",
      "Epoch 18/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2859 - acc: 0.4413 - val_loss: 14.3203 - val_acc: 0.3883\n",
      "Epoch 19/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2744 - acc: 0.4377 - val_loss: 14.3011 - val_acc: 0.3644\n",
      "Epoch 20/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2382 - acc: 0.4468 - val_loss: 14.3001 - val_acc: 0.3859\n",
      "Epoch 21/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2221 - acc: 0.4489 - val_loss: 14.2799 - val_acc: 0.3656\n",
      "Epoch 22/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1929 - acc: 0.4554 - val_loss: 14.2624 - val_acc: 0.3740\n",
      "Epoch 23/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1798 - acc: 0.4568 - val_loss: 14.2512 - val_acc: 0.3895\n",
      "Epoch 24/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1512 - acc: 0.4716 - val_loss: 14.2492 - val_acc: 0.3978\n",
      "Epoch 25/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1301 - acc: 0.4773 - val_loss: 14.2340 - val_acc: 0.3596\n",
      "Epoch 26/150\n",
      "7084/7084 [==============================] - 4s - loss: 14.1050 - acc: 0.4862 - val_loss: 14.2311 - val_acc: 0.3978\n",
      "Epoch 27/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0957 - acc: 0.4855 - val_loss: 14.2118 - val_acc: 0.3823\n",
      "Epoch 28/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0765 - acc: 0.4944 - val_loss: 14.2268 - val_acc: 0.3668\n",
      "Epoch 29/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0617 - acc: 0.4845 - val_loss: 14.1857 - val_acc: 0.4074\n",
      "Epoch 30/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0341 - acc: 0.4992 - val_loss: 14.1933 - val_acc: 0.3704\n",
      "Epoch 31/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0286 - acc: 0.5016 - val_loss: 14.1683 - val_acc: 0.3787\n",
      "Epoch 32/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0114 - acc: 0.5037 - val_loss: 14.1758 - val_acc: 0.4026\n",
      "Epoch 33/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9878 - acc: 0.5089 - val_loss: 14.1892 - val_acc: 0.3751\n",
      "Epoch 34/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9774 - acc: 0.5109 - val_loss: 14.1439 - val_acc: 0.3823\n",
      "Epoch 35/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9633 - acc: 0.5246 - val_loss: 14.1488 - val_acc: 0.3919\n",
      "Epoch 36/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9460 - acc: 0.5244 - val_loss: 14.1355 - val_acc: 0.3907\n",
      "Epoch 37/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9254 - acc: 0.5336 - val_loss: 14.1318 - val_acc: 0.3955\n",
      "Epoch 38/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9101 - acc: 0.5356 - val_loss: 14.1166 - val_acc: 0.4373\n",
      "Epoch 39/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9092 - acc: 0.5337 - val_loss: 14.1075 - val_acc: 0.4194\n",
      "Epoch 40/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8913 - acc: 0.5368 - val_loss: 14.0951 - val_acc: 0.4241\n",
      "Epoch 41/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8696 - acc: 0.5399 - val_loss: 14.0939 - val_acc: 0.4253\n",
      "Epoch 42/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8604 - acc: 0.5480 - val_loss: 14.0852 - val_acc: 0.4205\n",
      "Epoch 43/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8461 - acc: 0.5433 - val_loss: 14.0741 - val_acc: 0.4205\n",
      "Epoch 44/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8378 - acc: 0.5565 - val_loss: 14.0708 - val_acc: 0.4337\n",
      "Epoch 45/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8227 - acc: 0.5553 - val_loss: 14.0574 - val_acc: 0.4241\n",
      "Epoch 46/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8172 - acc: 0.5541 - val_loss: 14.0732 - val_acc: 0.4301\n",
      "Epoch 47/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7956 - acc: 0.5685 - val_loss: 14.0912 - val_acc: 0.4205\n",
      "Epoch 48/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7979 - acc: 0.5567 - val_loss: 14.0381 - val_acc: 0.4480\n",
      "Epoch 49/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7730 - acc: 0.5755 - val_loss: 14.0405 - val_acc: 0.4337\n",
      "Epoch 50/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7666 - acc: 0.5651 - val_loss: 14.0365 - val_acc: 0.4444\n",
      "Epoch 51/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7575 - acc: 0.5762 - val_loss: 14.0467 - val_acc: 0.4552\n",
      "Epoch 52/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7331 - acc: 0.5833 - val_loss: 14.0109 - val_acc: 0.4576\n",
      "Epoch 53/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.7312 - acc: 0.5798 - val_loss: 14.0027 - val_acc: 0.4636\n",
      "Epoch 54/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7190 - acc: 0.5846 - val_loss: 14.0098 - val_acc: 0.4492\n",
      "Epoch 55/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7000 - acc: 0.5902 - val_loss: 14.0088 - val_acc: 0.4683\n",
      "Epoch 56/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6917 - acc: 0.5991 - val_loss: 14.0003 - val_acc: 0.4803\n",
      "Epoch 57/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6783 - acc: 0.6025 - val_loss: 13.9718 - val_acc: 0.4803\n",
      "Epoch 58/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6677 - acc: 0.6030 - val_loss: 13.9960 - val_acc: 0.4612\n",
      "Epoch 59/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6631 - acc: 0.5940 - val_loss: 13.9894 - val_acc: 0.4707\n",
      "Epoch 60/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6489 - acc: 0.6069 - val_loss: 13.9733 - val_acc: 0.4659\n",
      "Epoch 61/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6343 - acc: 0.6118 - val_loss: 13.9890 - val_acc: 0.4827\n",
      "Epoch 62/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6205 - acc: 0.6139 - val_loss: 13.9580 - val_acc: 0.4863\n",
      "Epoch 63/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6131 - acc: 0.6221 - val_loss: 14.0129 - val_acc: 0.5018\n",
      "Epoch 64/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6183 - acc: 0.6059 - val_loss: 13.9484 - val_acc: 0.4731\n",
      "Epoch 65/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5828 - acc: 0.6262 - val_loss: 13.9191 - val_acc: 0.4934\n",
      "Epoch 66/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5821 - acc: 0.6302 - val_loss: 13.9188 - val_acc: 0.4958\n",
      "Epoch 67/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.5685 - acc: 0.6321 - val_loss: 13.9082 - val_acc: 0.4898\n",
      "Epoch 68/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5562 - acc: 0.6359 - val_loss: 13.9306 - val_acc: 0.4934\n",
      "Epoch 69/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5435 - acc: 0.6475 - val_loss: 13.9150 - val_acc: 0.5173\n",
      "Epoch 70/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5315 - acc: 0.6471 - val_loss: 13.9345 - val_acc: 0.5352\n",
      "Epoch 71/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5248 - acc: 0.6446 - val_loss: 13.9077 - val_acc: 0.4934\n",
      "Epoch 72/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5126 - acc: 0.6484 - val_loss: 13.9338 - val_acc: 0.4922\n",
      "Epoch 73/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5037 - acc: 0.6499 - val_loss: 13.9283 - val_acc: 0.4612\n",
      "Epoch 74/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.5015 - acc: 0.6501 - val_loss: 13.8911 - val_acc: 0.4827\n",
      "Epoch 75/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4804 - acc: 0.6635 - val_loss: 13.8732 - val_acc: 0.4922\n",
      "Epoch 76/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4669 - acc: 0.6599 - val_loss: 13.9180 - val_acc: 0.5125\n",
      "Epoch 77/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4715 - acc: 0.6564 - val_loss: 13.8604 - val_acc: 0.5233\n",
      "Epoch 78/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4586 - acc: 0.6625 - val_loss: 13.8450 - val_acc: 0.5675\n",
      "Epoch 79/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4454 - acc: 0.6656 - val_loss: 13.8620 - val_acc: 0.5424\n",
      "Epoch 80/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4341 - acc: 0.6701 - val_loss: 13.8721 - val_acc: 0.5364\n",
      "Epoch 81/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4285 - acc: 0.6628 - val_loss: 13.8695 - val_acc: 0.4958\n",
      "Epoch 82/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4144 - acc: 0.6731 - val_loss: 13.8984 - val_acc: 0.5544\n",
      "Epoch 83/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4132 - acc: 0.6789 - val_loss: 13.8233 - val_acc: 0.5603\n",
      "Epoch 84/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3986 - acc: 0.6815 - val_loss: 13.8227 - val_acc: 0.5448\n",
      "Epoch 85/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3888 - acc: 0.6743 - val_loss: 13.8040 - val_acc: 0.5317\n",
      "Epoch 86/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3797 - acc: 0.6748 - val_loss: 13.8079 - val_acc: 0.5329\n",
      "Epoch 87/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3696 - acc: 0.6863 - val_loss: 13.8223 - val_acc: 0.5257\n",
      "Epoch 88/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3629 - acc: 0.6814 - val_loss: 13.8054 - val_acc: 0.5341\n",
      "Epoch 89/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3466 - acc: 0.6885 - val_loss: 13.8114 - val_acc: 0.5460\n",
      "Epoch 90/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3389 - acc: 0.6959 - val_loss: 13.8038 - val_acc: 0.5305\n",
      "Epoch 91/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3327 - acc: 0.6966 - val_loss: 13.7674 - val_acc: 0.5460\n",
      "Epoch 92/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3292 - acc: 0.6981 - val_loss: 13.8264 - val_acc: 0.5448\n",
      "Epoch 93/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3262 - acc: 0.6938 - val_loss: 13.7987 - val_acc: 0.5424\n",
      "Epoch 94/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3030 - acc: 0.7053 - val_loss: 13.8135 - val_acc: 0.5125\n",
      "Epoch 95/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3049 - acc: 0.7019 - val_loss: 13.7955 - val_acc: 0.5197\n",
      "Epoch 96/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2963 - acc: 0.7005 - val_loss: 13.7801 - val_acc: 0.5818\n",
      "Epoch 97/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2830 - acc: 0.7036 - val_loss: 13.8289 - val_acc: 0.5830\n",
      "Epoch 98/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2725 - acc: 0.7020 - val_loss: 13.7527 - val_acc: 0.5436\n",
      "Epoch 99/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2598 - acc: 0.7141 - val_loss: 13.8133 - val_acc: 0.5376\n",
      "Epoch 100/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2628 - acc: 0.7016 - val_loss: 13.7845 - val_acc: 0.5818\n",
      "Epoch 101/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.2482 - acc: 0.7116 - val_loss: 13.7505 - val_acc: 0.5520\n",
      "Epoch 102/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2288 - acc: 0.7230 - val_loss: 13.7315 - val_acc: 0.5376\n",
      "Epoch 103/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2357 - acc: 0.7123 - val_loss: 13.7533 - val_acc: 0.5305\n",
      "Epoch 104/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2204 - acc: 0.7143 - val_loss: 13.7125 - val_acc: 0.5818\n",
      "Epoch 105/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2152 - acc: 0.7168 - val_loss: 13.7285 - val_acc: 0.6105\n",
      "Epoch 106/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2028 - acc: 0.7175 - val_loss: 13.7066 - val_acc: 0.6010\n",
      "Epoch 107/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1914 - acc: 0.7250 - val_loss: 13.7430 - val_acc: 0.5962\n",
      "Epoch 108/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1865 - acc: 0.7256 - val_loss: 13.7346 - val_acc: 0.5783\n",
      "Epoch 109/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1764 - acc: 0.7270 - val_loss: 13.6903 - val_acc: 0.6057\n",
      "Epoch 110/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1672 - acc: 0.7244 - val_loss: 13.6931 - val_acc: 0.5448\n",
      "Epoch 111/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1640 - acc: 0.7277 - val_loss: 13.6799 - val_acc: 0.5866\n",
      "Epoch 112/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1512 - acc: 0.7281 - val_loss: 13.7091 - val_acc: 0.5818\n",
      "Epoch 113/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1427 - acc: 0.7292 - val_loss: 13.7216 - val_acc: 0.5376\n",
      "Epoch 114/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1546 - acc: 0.7281 - val_loss: 13.6929 - val_acc: 0.6153\n",
      "Epoch 115/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1262 - acc: 0.7415 - val_loss: 13.7070 - val_acc: 0.5436\n",
      "Epoch 116/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1213 - acc: 0.7420 - val_loss: 13.6588 - val_acc: 0.6141\n",
      "Epoch 117/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1212 - acc: 0.7329 - val_loss: 13.7070 - val_acc: 0.5496\n",
      "Epoch 118/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1162 - acc: 0.7331 - val_loss: 13.6583 - val_acc: 0.6165\n",
      "Epoch 119/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1073 - acc: 0.7342 - val_loss: 13.6874 - val_acc: 0.5998\n",
      "Epoch 120/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1037 - acc: 0.7356 - val_loss: 13.7268 - val_acc: 0.5257\n",
      "Epoch 121/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0858 - acc: 0.7415 - val_loss: 13.6896 - val_acc: 0.5651\n",
      "Epoch 122/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0762 - acc: 0.7460 - val_loss: 13.6853 - val_acc: 0.5472\n",
      "Epoch 123/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0864 - acc: 0.7362 - val_loss: 13.6371 - val_acc: 0.5711\n",
      "Epoch 124/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0576 - acc: 0.7524 - val_loss: 13.6494 - val_acc: 0.6057\n",
      "Epoch 125/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0547 - acc: 0.7470 - val_loss: 13.6248 - val_acc: 0.5639\n",
      "Epoch 126/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0484 - acc: 0.7499 - val_loss: 13.6677 - val_acc: 0.6081\n",
      "Epoch 127/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0313 - acc: 0.7585 - val_loss: 13.6153 - val_acc: 0.6260\n",
      "Epoch 128/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0209 - acc: 0.7566 - val_loss: 13.6646 - val_acc: 0.5269\n",
      "Epoch 129/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0384 - acc: 0.7489 - val_loss: 13.6420 - val_acc: 0.6189\n",
      "Epoch 130/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0135 - acc: 0.7583 - val_loss: 13.6568 - val_acc: 0.6057\n",
      "Epoch 131/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0119 - acc: 0.7588 - val_loss: 13.6516 - val_acc: 0.5938\n",
      "Epoch 132/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0012 - acc: 0.7633 - val_loss: 13.6239 - val_acc: 0.5639\n",
      "Epoch 133/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9980 - acc: 0.7607 - val_loss: 13.6016 - val_acc: 0.6141\n",
      "Epoch 134/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9866 - acc: 0.7616 - val_loss: 13.7412 - val_acc: 0.5735\n",
      "Epoch 135/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0027 - acc: 0.7545 - val_loss: 13.6219 - val_acc: 0.5269\n",
      "Epoch 136/150\n",
      "7084/7084 [==============================] - 4s - loss: 12.9885 - acc: 0.7568 - val_loss: 13.5760 - val_acc: 0.6284\n",
      "Epoch 137/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9693 - acc: 0.7627 - val_loss: 13.5684 - val_acc: 0.5735\n",
      "Epoch 138/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9585 - acc: 0.7634 - val_loss: 13.6092 - val_acc: 0.5711\n",
      "Epoch 139/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9599 - acc: 0.7595 - val_loss: 13.6132 - val_acc: 0.5854\n",
      "Epoch 140/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9542 - acc: 0.7620 - val_loss: 13.5397 - val_acc: 0.6272\n",
      "Epoch 141/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9404 - acc: 0.7684 - val_loss: 13.5466 - val_acc: 0.6069\n",
      "Epoch 142/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9276 - acc: 0.7698 - val_loss: 13.5415 - val_acc: 0.5854\n",
      "Epoch 143/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9250 - acc: 0.7768 - val_loss: 13.5793 - val_acc: 0.6010\n",
      "Epoch 144/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9255 - acc: 0.7778 - val_loss: 13.6276 - val_acc: 0.6272\n",
      "Epoch 145/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.9311 - acc: 0.7678 - val_loss: 13.5500 - val_acc: 0.6165\n",
      "Epoch 146/150\n",
      "7084/7084 [==============================] - 4s - loss: 12.8925 - acc: 0.7792 - val_loss: 13.5233 - val_acc: 0.6308\n",
      "Epoch 147/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.8921 - acc: 0.7804 - val_loss: 13.5289 - val_acc: 0.6141\n",
      "Epoch 148/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.8933 - acc: 0.7753 - val_loss: 13.5496 - val_acc: 0.5986\n",
      "Epoch 149/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.8775 - acc: 0.7832 - val_loss: 13.5472 - val_acc: 0.5818\n",
      "Epoch 150/150\n",
      "7084/7084 [==============================] - 3s - loss: 12.8675 - acc: 0.7842 - val_loss: 13.5363 - val_acc: 0.6416\n",
      "training time: 483.77074337005615\n",
      "800/806 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.5931\n",
      "\n",
      "Error Rate = 0.4069\n",
      "training time: 0.6194310188293457\n",
      "opening fold: 9\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Scaling time: 1.8411602973937988\n",
      "Scaling time: 0.2238936424255371\n",
      "Scaling time: 0.2191176414489746\n",
      "training model...hold tight\n",
      "Train on 7074 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7074/7074 [==============================] - 9s - loss: 15.1171 - acc: 0.1110 - val_loss: 15.0364 - val_acc: 0.1195\n",
      "Epoch 2/150\n",
      "7074/7074 [==============================] - 3s - loss: 15.0497 - acc: 0.1407 - val_loss: 14.9741 - val_acc: 0.1995\n",
      "Epoch 3/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9919 - acc: 0.1756 - val_loss: 14.9087 - val_acc: 0.2270\n",
      "Epoch 4/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9260 - acc: 0.2088 - val_loss: 14.8427 - val_acc: 0.2772\n",
      "Epoch 5/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8669 - acc: 0.2300 - val_loss: 14.7753 - val_acc: 0.3035\n",
      "Epoch 6/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8035 - acc: 0.2494 - val_loss: 14.7092 - val_acc: 0.2593\n",
      "Epoch 7/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7482 - acc: 0.2696 - val_loss: 14.6548 - val_acc: 0.2712\n",
      "Epoch 8/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6911 - acc: 0.2802 - val_loss: 14.6099 - val_acc: 0.3082\n",
      "Epoch 9/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6440 - acc: 0.2933 - val_loss: 14.5615 - val_acc: 0.3070\n",
      "Epoch 10/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6033 - acc: 0.3049 - val_loss: 14.5316 - val_acc: 0.3082\n",
      "Epoch 11/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5618 - acc: 0.3230 - val_loss: 14.4951 - val_acc: 0.3202\n",
      "Epoch 12/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5190 - acc: 0.3384 - val_loss: 14.4790 - val_acc: 0.3226\n",
      "Epoch 13/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4758 - acc: 0.3678 - val_loss: 14.4477 - val_acc: 0.3751\n",
      "Epoch 14/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4501 - acc: 0.3670 - val_loss: 14.4196 - val_acc: 0.3596\n",
      "Epoch 15/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4184 - acc: 0.3781 - val_loss: 14.3847 - val_acc: 0.3644\n",
      "Epoch 16/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3777 - acc: 0.3948 - val_loss: 14.3616 - val_acc: 0.3668\n",
      "Epoch 17/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3390 - acc: 0.4266 - val_loss: 14.3407 - val_acc: 0.3668\n",
      "Epoch 18/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3152 - acc: 0.4207 - val_loss: 14.3098 - val_acc: 0.3799\n",
      "Epoch 19/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2865 - acc: 0.4347 - val_loss: 14.2877 - val_acc: 0.3835\n",
      "Epoch 20/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2554 - acc: 0.4444 - val_loss: 14.2740 - val_acc: 0.3955\n",
      "Epoch 21/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2294 - acc: 0.4631 - val_loss: 14.2412 - val_acc: 0.4301\n",
      "Epoch 22/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2013 - acc: 0.4599 - val_loss: 14.2243 - val_acc: 0.3931\n",
      "Epoch 23/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1760 - acc: 0.4666 - val_loss: 14.2163 - val_acc: 0.4170\n",
      "Epoch 24/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1611 - acc: 0.4747 - val_loss: 14.2103 - val_acc: 0.4086\n",
      "Epoch 25/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1361 - acc: 0.4785 - val_loss: 14.1911 - val_acc: 0.4361\n",
      "Epoch 26/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1161 - acc: 0.4809 - val_loss: 14.1926 - val_acc: 0.4146\n",
      "Epoch 27/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1027 - acc: 0.4804 - val_loss: 14.1610 - val_acc: 0.4397\n",
      "Epoch 28/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0706 - acc: 0.4936 - val_loss: 14.1515 - val_acc: 0.4540\n",
      "Epoch 29/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0585 - acc: 0.4926 - val_loss: 14.1455 - val_acc: 0.4432\n",
      "Epoch 30/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0450 - acc: 0.5016 - val_loss: 14.1236 - val_acc: 0.4528\n",
      "Epoch 31/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0251 - acc: 0.5072 - val_loss: 14.1410 - val_acc: 0.4253\n",
      "Epoch 32/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0158 - acc: 0.4979 - val_loss: 14.1213 - val_acc: 0.4612\n",
      "Epoch 33/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9955 - acc: 0.5062 - val_loss: 14.1096 - val_acc: 0.4170\n",
      "Epoch 34/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9835 - acc: 0.5158 - val_loss: 14.1066 - val_acc: 0.4349\n",
      "Epoch 35/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9658 - acc: 0.5205 - val_loss: 14.0863 - val_acc: 0.4600\n",
      "Epoch 36/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9464 - acc: 0.5287 - val_loss: 14.0819 - val_acc: 0.4480\n",
      "Epoch 37/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9449 - acc: 0.5228 - val_loss: 14.0637 - val_acc: 0.4600\n",
      "Epoch 38/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9200 - acc: 0.5385 - val_loss: 14.0568 - val_acc: 0.4886\n",
      "Epoch 39/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9146 - acc: 0.5259 - val_loss: 14.0753 - val_acc: 0.4552\n",
      "Epoch 40/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8979 - acc: 0.5427 - val_loss: 14.0716 - val_acc: 0.4444\n",
      "Epoch 41/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8906 - acc: 0.5380 - val_loss: 14.0596 - val_acc: 0.4122\n",
      "Epoch 42/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8724 - acc: 0.5409 - val_loss: 14.0431 - val_acc: 0.4743\n",
      "Epoch 43/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8602 - acc: 0.5479 - val_loss: 14.0364 - val_acc: 0.4397\n",
      "Epoch 44/150\n",
      "7074/7074 [==============================] - 2s - loss: 13.8502 - acc: 0.5522 - val_loss: 14.0423 - val_acc: 0.4540\n",
      "Epoch 45/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8405 - acc: 0.5553 - val_loss: 14.0349 - val_acc: 0.4671\n",
      "Epoch 46/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8300 - acc: 0.5546 - val_loss: 14.0065 - val_acc: 0.4707\n",
      "Epoch 47/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8005 - acc: 0.5687 - val_loss: 14.0874 - val_acc: 0.4062\n",
      "Epoch 48/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8114 - acc: 0.5687 - val_loss: 14.0027 - val_acc: 0.4779\n",
      "Epoch 49/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7919 - acc: 0.5674 - val_loss: 13.9802 - val_acc: 0.4875\n",
      "Epoch 50/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7764 - acc: 0.5732 - val_loss: 13.9659 - val_acc: 0.4755\n",
      "Epoch 51/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7621 - acc: 0.5830 - val_loss: 13.9743 - val_acc: 0.4875\n",
      "Epoch 52/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7479 - acc: 0.5794 - val_loss: 13.9817 - val_acc: 0.4695\n",
      "Epoch 53/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7387 - acc: 0.5850 - val_loss: 13.9684 - val_acc: 0.5137\n",
      "Epoch 54/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7266 - acc: 0.5865 - val_loss: 13.9845 - val_acc: 0.4695\n",
      "Epoch 55/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7139 - acc: 0.5916 - val_loss: 13.9446 - val_acc: 0.5018\n",
      "Epoch 56/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7088 - acc: 0.5885 - val_loss: 13.9628 - val_acc: 0.4803\n",
      "Epoch 57/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6928 - acc: 0.5956 - val_loss: 13.9472 - val_acc: 0.5317\n",
      "Epoch 58/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6724 - acc: 0.6108 - val_loss: 13.9230 - val_acc: 0.5532\n",
      "Epoch 59/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6660 - acc: 0.6004 - val_loss: 13.9210 - val_acc: 0.4707\n",
      "Epoch 60/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6593 - acc: 0.6011 - val_loss: 13.9329 - val_acc: 0.4731\n",
      "Epoch 61/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6465 - acc: 0.6031 - val_loss: 13.9301 - val_acc: 0.4779\n",
      "Epoch 62/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6363 - acc: 0.6182 - val_loss: 13.9000 - val_acc: 0.5364\n",
      "Epoch 63/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6340 - acc: 0.6115 - val_loss: 13.8981 - val_acc: 0.5197\n",
      "Epoch 64/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6211 - acc: 0.6211 - val_loss: 13.8607 - val_acc: 0.5591\n",
      "Epoch 65/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6060 - acc: 0.6152 - val_loss: 13.9280 - val_acc: 0.4791\n",
      "Epoch 66/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6108 - acc: 0.6190 - val_loss: 13.8849 - val_acc: 0.4946\n",
      "Epoch 67/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5828 - acc: 0.6224 - val_loss: 13.9559 - val_acc: 0.4444\n",
      "Epoch 68/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5897 - acc: 0.6243 - val_loss: 13.8667 - val_acc: 0.5197\n",
      "Epoch 69/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5631 - acc: 0.6367 - val_loss: 13.8612 - val_acc: 0.5603\n",
      "Epoch 70/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5526 - acc: 0.6346 - val_loss: 13.8447 - val_acc: 0.6201\n",
      "Epoch 71/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5496 - acc: 0.6337 - val_loss: 13.8823 - val_acc: 0.4839\n",
      "Epoch 72/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5364 - acc: 0.6426 - val_loss: 13.8667 - val_acc: 0.5484\n",
      "Epoch 73/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5294 - acc: 0.6422 - val_loss: 13.8510 - val_acc: 0.4958\n",
      "Epoch 74/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5136 - acc: 0.6414 - val_loss: 13.8356 - val_acc: 0.6117\n",
      "Epoch 75/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5076 - acc: 0.6467 - val_loss: 13.8384 - val_acc: 0.5233\n",
      "Epoch 76/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5015 - acc: 0.6455 - val_loss: 13.8467 - val_acc: 0.5185\n",
      "Epoch 77/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4828 - acc: 0.6511 - val_loss: 13.8125 - val_acc: 0.6129\n",
      "Epoch 78/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4750 - acc: 0.6677 - val_loss: 13.8073 - val_acc: 0.5711\n",
      "Epoch 79/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4664 - acc: 0.6544 - val_loss: 13.8178 - val_acc: 0.6057\n",
      "Epoch 80/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4575 - acc: 0.6612 - val_loss: 13.8091 - val_acc: 0.5556\n",
      "Epoch 81/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4496 - acc: 0.6638 - val_loss: 13.8756 - val_acc: 0.4970\n",
      "Epoch 82/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4422 - acc: 0.6589 - val_loss: 13.8005 - val_acc: 0.5460\n",
      "Epoch 83/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4188 - acc: 0.6725 - val_loss: 13.8015 - val_acc: 0.5197\n",
      "Epoch 84/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4134 - acc: 0.6692 - val_loss: 13.7945 - val_acc: 0.5615\n",
      "Epoch 85/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4107 - acc: 0.6729 - val_loss: 13.8375 - val_acc: 0.5747\n",
      "Epoch 86/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4054 - acc: 0.6740 - val_loss: 13.8473 - val_acc: 0.5388\n",
      "Epoch 87/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3980 - acc: 0.6726 - val_loss: 13.8309 - val_acc: 0.5544\n",
      "Epoch 88/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3850 - acc: 0.6791 - val_loss: 13.7458 - val_acc: 0.5795\n",
      "Epoch 89/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3715 - acc: 0.6812 - val_loss: 13.7687 - val_acc: 0.5974\n",
      "Epoch 90/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3574 - acc: 0.6913 - val_loss: 13.7526 - val_acc: 0.5723\n",
      "Epoch 91/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3504 - acc: 0.6894 - val_loss: 13.7523 - val_acc: 0.6093\n",
      "Epoch 92/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3341 - acc: 0.6944 - val_loss: 13.7180 - val_acc: 0.6153\n",
      "Epoch 93/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3369 - acc: 0.6862 - val_loss: 13.7579 - val_acc: 0.5281\n",
      "Epoch 94/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3237 - acc: 0.6934 - val_loss: 13.7477 - val_acc: 0.5663\n",
      "Epoch 95/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3277 - acc: 0.6966 - val_loss: 13.7229 - val_acc: 0.6105\n",
      "Epoch 96/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3055 - acc: 0.6932 - val_loss: 13.7504 - val_acc: 0.5484\n",
      "Epoch 97/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2898 - acc: 0.6995 - val_loss: 13.7420 - val_acc: 0.6057\n",
      "Epoch 98/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2775 - acc: 0.7071 - val_loss: 13.7134 - val_acc: 0.6153\n",
      "Epoch 99/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2845 - acc: 0.6979 - val_loss: 13.7266 - val_acc: 0.5986\n",
      "Epoch 100/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2834 - acc: 0.6999 - val_loss: 13.7146 - val_acc: 0.5866\n",
      "Epoch 101/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2537 - acc: 0.7144 - val_loss: 13.7250 - val_acc: 0.5639\n",
      "Epoch 102/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.2662 - acc: 0.7040 - val_loss: 13.7332 - val_acc: 0.5723\n",
      "Epoch 103/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2536 - acc: 0.7067 - val_loss: 13.7102 - val_acc: 0.6093\n",
      "Epoch 104/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2318 - acc: 0.7207 - val_loss: 13.6557 - val_acc: 0.6189\n",
      "Epoch 105/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2238 - acc: 0.7169 - val_loss: 13.6944 - val_acc: 0.5974\n",
      "Epoch 106/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2225 - acc: 0.7198 - val_loss: 13.6482 - val_acc: 0.6272\n",
      "Epoch 107/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2152 - acc: 0.7084 - val_loss: 13.6495 - val_acc: 0.6189\n",
      "Epoch 108/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2111 - acc: 0.7193 - val_loss: 13.7405 - val_acc: 0.5448\n",
      "Epoch 109/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2020 - acc: 0.7170 - val_loss: 13.6560 - val_acc: 0.6141\n",
      "Epoch 110/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1891 - acc: 0.7231 - val_loss: 13.6473 - val_acc: 0.6272\n",
      "Epoch 111/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1773 - acc: 0.7273 - val_loss: 13.7272 - val_acc: 0.5329\n",
      "Epoch 112/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1779 - acc: 0.7204 - val_loss: 13.6860 - val_acc: 0.5830\n",
      "Epoch 113/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1646 - acc: 0.7311 - val_loss: 13.6481 - val_acc: 0.5878\n",
      "Epoch 114/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1509 - acc: 0.7351 - val_loss: 13.6438 - val_acc: 0.5950\n",
      "Epoch 115/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1430 - acc: 0.7325 - val_loss: 13.6688 - val_acc: 0.5472\n",
      "Epoch 116/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1266 - acc: 0.7348 - val_loss: 13.6249 - val_acc: 0.6129\n",
      "Epoch 117/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1245 - acc: 0.7328 - val_loss: 13.6206 - val_acc: 0.6165\n",
      "Epoch 118/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1223 - acc: 0.7341 - val_loss: 13.6106 - val_acc: 0.6249\n",
      "Epoch 119/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1157 - acc: 0.7412 - val_loss: 13.6354 - val_acc: 0.5699\n",
      "Epoch 120/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1167 - acc: 0.7349 - val_loss: 13.6262 - val_acc: 0.6189\n",
      "Epoch 121/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0924 - acc: 0.7433 - val_loss: 13.6334 - val_acc: 0.6105\n",
      "Epoch 122/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0927 - acc: 0.7419 - val_loss: 13.6023 - val_acc: 0.6177\n",
      "Epoch 123/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0823 - acc: 0.7443 - val_loss: 13.6311 - val_acc: 0.6177\n",
      "Epoch 124/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0776 - acc: 0.7419 - val_loss: 13.5819 - val_acc: 0.6284\n",
      "Epoch 125/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0754 - acc: 0.7494 - val_loss: 13.6078 - val_acc: 0.5986\n",
      "Epoch 126/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0607 - acc: 0.7420 - val_loss: 13.5762 - val_acc: 0.6356\n",
      "Epoch 127/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0628 - acc: 0.7410 - val_loss: 13.6034 - val_acc: 0.6272\n",
      "Epoch 128/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0501 - acc: 0.7474 - val_loss: 13.5512 - val_acc: 0.6177\n",
      "Epoch 129/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0384 - acc: 0.7523 - val_loss: 13.5801 - val_acc: 0.6213\n",
      "Epoch 130/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0363 - acc: 0.7484 - val_loss: 13.5644 - val_acc: 0.6440\n",
      "Epoch 131/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0225 - acc: 0.7537 - val_loss: 13.5407 - val_acc: 0.6320\n",
      "Epoch 132/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0187 - acc: 0.7563 - val_loss: 13.5716 - val_acc: 0.5926\n",
      "Epoch 133/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0006 - acc: 0.7567 - val_loss: 13.5735 - val_acc: 0.6105\n",
      "Epoch 134/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9944 - acc: 0.7662 - val_loss: 13.6120 - val_acc: 0.5866\n",
      "Epoch 135/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0065 - acc: 0.7494 - val_loss: 13.5683 - val_acc: 0.5974\n",
      "Epoch 136/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9845 - acc: 0.7602 - val_loss: 13.5061 - val_acc: 0.6392\n",
      "Epoch 137/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9768 - acc: 0.7634 - val_loss: 13.5408 - val_acc: 0.6201\n",
      "Epoch 138/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9578 - acc: 0.7693 - val_loss: 13.5448 - val_acc: 0.6272\n",
      "Epoch 139/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9439 - acc: 0.7697 - val_loss: 13.5031 - val_acc: 0.6464\n",
      "Epoch 140/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9443 - acc: 0.7706 - val_loss: 13.4920 - val_acc: 0.6631\n",
      "Epoch 141/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9375 - acc: 0.7762 - val_loss: 13.5510 - val_acc: 0.6332\n",
      "Epoch 142/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9252 - acc: 0.7762 - val_loss: 13.5164 - val_acc: 0.6368\n",
      "Epoch 143/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9273 - acc: 0.7707 - val_loss: 13.5585 - val_acc: 0.6284\n",
      "Epoch 144/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9174 - acc: 0.7771 - val_loss: 13.5774 - val_acc: 0.6093\n",
      "Epoch 145/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9180 - acc: 0.7745 - val_loss: 13.4908 - val_acc: 0.6392\n",
      "Epoch 146/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9093 - acc: 0.7819 - val_loss: 13.5429 - val_acc: 0.6081\n",
      "Epoch 147/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.8975 - acc: 0.7798 - val_loss: 13.4964 - val_acc: 0.6249\n",
      "Epoch 148/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.8883 - acc: 0.7798 - val_loss: 13.5045 - val_acc: 0.6356\n",
      "Epoch 149/150\n",
      "7074/7074 [==============================] - 4s - loss: 12.8826 - acc: 0.7778 - val_loss: 13.4753 - val_acc: 0.6487\n",
      "Epoch 150/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.8832 - acc: 0.7788 - val_loss: 13.4993 - val_acc: 0.6452\n",
      "training time: 481.16710352897644\n",
      "800/816 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.6752\n",
      "\n",
      "Error Rate = 0.3248\n",
      "training time: 0.63260817527771\n",
      "opening fold: 10\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Scaling time: 1.849740743637085\n",
      "Scaling time: 0.22032999992370605\n",
      "Scaling time: 0.22438764572143555\n",
      "training model...hold tight\n",
      "Train on 7074 samples, validate on 816 samples\n",
      "Epoch 1/150\n",
      "7074/7074 [==============================] - 9s - loss: 15.1433 - acc: 0.1161 - val_loss: 15.0475 - val_acc: 0.1127\n",
      "Epoch 2/150\n",
      "7074/7074 [==============================] - 3s - loss: 15.0445 - acc: 0.1541 - val_loss: 14.9698 - val_acc: 0.1998\n",
      "Epoch 3/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9746 - acc: 0.1818 - val_loss: 14.8883 - val_acc: 0.1924\n",
      "Epoch 4/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9123 - acc: 0.2088 - val_loss: 14.7980 - val_acc: 0.3027\n",
      "Epoch 5/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8553 - acc: 0.2294 - val_loss: 14.7142 - val_acc: 0.3272\n",
      "Epoch 6/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7908 - acc: 0.2560 - val_loss: 14.6398 - val_acc: 0.3824\n",
      "Epoch 7/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7241 - acc: 0.2889 - val_loss: 14.5689 - val_acc: 0.3750\n",
      "Epoch 8/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6771 - acc: 0.2887 - val_loss: 14.5011 - val_acc: 0.3811\n",
      "Epoch 9/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6305 - acc: 0.3111 - val_loss: 14.4482 - val_acc: 0.3787\n",
      "Epoch 10/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5746 - acc: 0.3274 - val_loss: 14.4066 - val_acc: 0.4203\n",
      "Epoch 11/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5267 - acc: 0.3461 - val_loss: 14.3718 - val_acc: 0.4044\n",
      "Epoch 12/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4979 - acc: 0.3517 - val_loss: 14.3360 - val_acc: 0.4093\n",
      "Epoch 13/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4531 - acc: 0.3767 - val_loss: 14.3154 - val_acc: 0.4400\n",
      "Epoch 14/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4165 - acc: 0.3944 - val_loss: 14.2842 - val_acc: 0.4191\n",
      "Epoch 15/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3798 - acc: 0.4067 - val_loss: 14.2734 - val_acc: 0.4485\n",
      "Epoch 16/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3450 - acc: 0.4196 - val_loss: 14.2480 - val_acc: 0.4375\n",
      "Epoch 17/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3134 - acc: 0.4258 - val_loss: 14.2298 - val_acc: 0.4252\n",
      "Epoch 18/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2899 - acc: 0.4313 - val_loss: 14.2313 - val_acc: 0.4571\n",
      "Epoch 19/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2505 - acc: 0.4484 - val_loss: 14.2214 - val_acc: 0.4350\n",
      "Epoch 20/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2361 - acc: 0.4558 - val_loss: 14.1976 - val_acc: 0.4436\n",
      "Epoch 21/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1978 - acc: 0.4723 - val_loss: 14.1605 - val_acc: 0.4350\n",
      "Epoch 22/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1766 - acc: 0.4683 - val_loss: 14.1509 - val_acc: 0.4424\n",
      "Epoch 23/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1523 - acc: 0.4767 - val_loss: 14.1423 - val_acc: 0.4449\n",
      "Epoch 24/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1322 - acc: 0.4781 - val_loss: 14.1438 - val_acc: 0.4167\n",
      "Epoch 25/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1090 - acc: 0.4805 - val_loss: 14.1266 - val_acc: 0.4081\n",
      "Epoch 26/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0960 - acc: 0.4901 - val_loss: 14.1107 - val_acc: 0.4228\n",
      "Epoch 27/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0772 - acc: 0.4948 - val_loss: 14.1296 - val_acc: 0.4326\n",
      "Epoch 28/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0584 - acc: 0.4939 - val_loss: 14.1010 - val_acc: 0.3983\n",
      "Epoch 29/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0369 - acc: 0.5055 - val_loss: 14.1368 - val_acc: 0.4203\n",
      "Epoch 30/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0117 - acc: 0.5090 - val_loss: 14.1117 - val_acc: 0.4252\n",
      "Epoch 31/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0157 - acc: 0.5055 - val_loss: 14.1015 - val_acc: 0.4069\n",
      "Epoch 32/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9955 - acc: 0.5144 - val_loss: 14.0946 - val_acc: 0.4142\n",
      "Epoch 33/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9842 - acc: 0.5113 - val_loss: 14.0658 - val_acc: 0.4179\n",
      "Epoch 34/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9632 - acc: 0.5232 - val_loss: 14.1308 - val_acc: 0.4534\n",
      "Epoch 35/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9559 - acc: 0.5236 - val_loss: 14.1329 - val_acc: 0.4130\n",
      "Epoch 36/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9395 - acc: 0.5287 - val_loss: 14.0524 - val_acc: 0.4326\n",
      "Epoch 37/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9275 - acc: 0.5281 - val_loss: 14.0675 - val_acc: 0.4167\n",
      "Epoch 38/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9130 - acc: 0.5259 - val_loss: 14.0539 - val_acc: 0.4301\n",
      "Epoch 39/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9024 - acc: 0.5332 - val_loss: 14.0394 - val_acc: 0.4314\n",
      "Epoch 40/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8828 - acc: 0.5444 - val_loss: 14.0306 - val_acc: 0.4301\n",
      "Epoch 41/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8714 - acc: 0.5427 - val_loss: 14.0877 - val_acc: 0.4314\n",
      "Epoch 42/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8640 - acc: 0.5500 - val_loss: 14.0359 - val_acc: 0.4363\n",
      "Epoch 43/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8521 - acc: 0.5503 - val_loss: 14.0582 - val_acc: 0.4363\n",
      "Epoch 44/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8302 - acc: 0.5575 - val_loss: 14.0922 - val_acc: 0.4265\n",
      "Epoch 45/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8160 - acc: 0.5671 - val_loss: 14.0659 - val_acc: 0.4363\n",
      "Epoch 46/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8101 - acc: 0.5640 - val_loss: 14.1149 - val_acc: 0.4375\n",
      "Epoch 47/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8047 - acc: 0.5612 - val_loss: 14.0503 - val_acc: 0.4387\n",
      "Epoch 48/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7748 - acc: 0.5769 - val_loss: 14.0172 - val_acc: 0.4510\n",
      "Epoch 49/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7735 - acc: 0.5736 - val_loss: 14.0448 - val_acc: 0.4473\n",
      "Epoch 50/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7675 - acc: 0.5703 - val_loss: 13.9918 - val_acc: 0.4547\n",
      "Epoch 51/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7537 - acc: 0.5772 - val_loss: 13.9837 - val_acc: 0.4583\n",
      "Epoch 52/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7420 - acc: 0.5840 - val_loss: 14.0020 - val_acc: 0.4743\n",
      "Epoch 53/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7278 - acc: 0.5845 - val_loss: 14.1487 - val_acc: 0.4718\n",
      "Epoch 54/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7239 - acc: 0.5867 - val_loss: 13.9889 - val_acc: 0.4841\n",
      "Epoch 55/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7041 - acc: 0.5947 - val_loss: 14.0320 - val_acc: 0.4583\n",
      "Epoch 56/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7042 - acc: 0.5902 - val_loss: 13.9645 - val_acc: 0.4926\n",
      "Epoch 57/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6941 - acc: 0.5936 - val_loss: 13.9455 - val_acc: 0.4779\n",
      "Epoch 58/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6742 - acc: 0.6023 - val_loss: 14.0264 - val_acc: 0.4816\n",
      "Epoch 59/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6661 - acc: 0.5967 - val_loss: 14.0025 - val_acc: 0.4816\n",
      "Epoch 60/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.6529 - acc: 0.6073 - val_loss: 13.9787 - val_acc: 0.4890\n",
      "Epoch 61/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6464 - acc: 0.6107 - val_loss: 13.9871 - val_acc: 0.4804\n",
      "Epoch 62/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6319 - acc: 0.6193 - val_loss: 14.2645 - val_acc: 0.4583\n",
      "Epoch 63/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6622 - acc: 0.6042 - val_loss: 14.0127 - val_acc: 0.4841\n",
      "Epoch 64/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6133 - acc: 0.6227 - val_loss: 13.9905 - val_acc: 0.5123\n",
      "Epoch 65/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6038 - acc: 0.6223 - val_loss: 14.0018 - val_acc: 0.5000\n",
      "Epoch 66/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5907 - acc: 0.6337 - val_loss: 13.9479 - val_acc: 0.5061\n",
      "Epoch 67/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5830 - acc: 0.6258 - val_loss: 13.9523 - val_acc: 0.5074\n",
      "Epoch 68/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5724 - acc: 0.6309 - val_loss: 13.9485 - val_acc: 0.4963\n",
      "Epoch 69/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5680 - acc: 0.6293 - val_loss: 14.0100 - val_acc: 0.5086\n",
      "Epoch 70/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5554 - acc: 0.6411 - val_loss: 13.9195 - val_acc: 0.5147\n",
      "Epoch 71/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5446 - acc: 0.6363 - val_loss: 13.9639 - val_acc: 0.5086\n",
      "Epoch 72/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5286 - acc: 0.6373 - val_loss: 13.9274 - val_acc: 0.5478\n",
      "Epoch 73/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5208 - acc: 0.6438 - val_loss: 13.9007 - val_acc: 0.5674\n",
      "Epoch 74/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5249 - acc: 0.6452 - val_loss: 13.9475 - val_acc: 0.5172\n",
      "Epoch 75/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5064 - acc: 0.6416 - val_loss: 13.8912 - val_acc: 0.5625\n",
      "Epoch 76/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4909 - acc: 0.6511 - val_loss: 13.9429 - val_acc: 0.5123\n",
      "Epoch 77/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4851 - acc: 0.6500 - val_loss: 13.9531 - val_acc: 0.5257\n",
      "Epoch 78/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4797 - acc: 0.6498 - val_loss: 13.9684 - val_acc: 0.5098\n",
      "Epoch 79/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4682 - acc: 0.6558 - val_loss: 13.9028 - val_acc: 0.5931\n",
      "Epoch 80/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4597 - acc: 0.6518 - val_loss: 13.8590 - val_acc: 0.5502\n",
      "Epoch 81/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4440 - acc: 0.6674 - val_loss: 13.8443 - val_acc: 0.5748\n",
      "Epoch 82/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4427 - acc: 0.6616 - val_loss: 13.8634 - val_acc: 0.5919\n",
      "Epoch 83/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4269 - acc: 0.6677 - val_loss: 13.9062 - val_acc: 0.5466\n",
      "Epoch 84/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4229 - acc: 0.6701 - val_loss: 13.8710 - val_acc: 0.5686\n",
      "Epoch 85/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4174 - acc: 0.6631 - val_loss: 13.8366 - val_acc: 0.5846\n",
      "Epoch 86/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4014 - acc: 0.6709 - val_loss: 13.8995 - val_acc: 0.5429\n",
      "Epoch 87/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3956 - acc: 0.6729 - val_loss: 13.8651 - val_acc: 0.5858\n",
      "Epoch 88/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3855 - acc: 0.6773 - val_loss: 13.9085 - val_acc: 0.5551\n",
      "Epoch 89/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3687 - acc: 0.6800 - val_loss: 13.8586 - val_acc: 0.5576\n",
      "Epoch 90/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3618 - acc: 0.6832 - val_loss: 13.8900 - val_acc: 0.5600\n",
      "Epoch 91/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3579 - acc: 0.6822 - val_loss: 13.8685 - val_acc: 0.5846\n",
      "Epoch 92/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3537 - acc: 0.6872 - val_loss: 13.8695 - val_acc: 0.6078\n",
      "Epoch 93/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3378 - acc: 0.6913 - val_loss: 13.8645 - val_acc: 0.5797\n",
      "Epoch 94/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3264 - acc: 0.6941 - val_loss: 13.8424 - val_acc: 0.6005\n",
      "Epoch 95/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3206 - acc: 0.6944 - val_loss: 13.8171 - val_acc: 0.5809\n",
      "Epoch 96/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3217 - acc: 0.6858 - val_loss: 13.8235 - val_acc: 0.6017\n",
      "Epoch 97/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3156 - acc: 0.6930 - val_loss: 13.8373 - val_acc: 0.6054\n",
      "Epoch 98/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2910 - acc: 0.7030 - val_loss: 13.8270 - val_acc: 0.5625\n",
      "Epoch 99/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2895 - acc: 0.6996 - val_loss: 13.7970 - val_acc: 0.5882\n",
      "Epoch 100/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2840 - acc: 0.7006 - val_loss: 13.7634 - val_acc: 0.6078\n",
      "Epoch 101/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2754 - acc: 0.6990 - val_loss: 13.9629 - val_acc: 0.5551\n",
      "Epoch 102/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2738 - acc: 0.7019 - val_loss: 13.7722 - val_acc: 0.6140\n",
      "Epoch 103/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2562 - acc: 0.7034 - val_loss: 13.8065 - val_acc: 0.5993\n",
      "Epoch 104/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2403 - acc: 0.7084 - val_loss: 13.8241 - val_acc: 0.5784\n",
      "Epoch 105/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2413 - acc: 0.7091 - val_loss: 13.8526 - val_acc: 0.5833\n",
      "Epoch 106/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2368 - acc: 0.7088 - val_loss: 13.8732 - val_acc: 0.5674\n",
      "Epoch 107/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2379 - acc: 0.7055 - val_loss: 13.8316 - val_acc: 0.5870\n",
      "Epoch 108/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2210 - acc: 0.7113 - val_loss: 13.8452 - val_acc: 0.5576\n",
      "Epoch 109/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2063 - acc: 0.7241 - val_loss: 13.8340 - val_acc: 0.5968\n",
      "Epoch 110/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1946 - acc: 0.7181 - val_loss: 13.8120 - val_acc: 0.5980\n",
      "Epoch 111/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1913 - acc: 0.7120 - val_loss: 13.8839 - val_acc: 0.5858\n",
      "Epoch 112/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1884 - acc: 0.7201 - val_loss: 13.7520 - val_acc: 0.6152\n",
      "Epoch 113/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1732 - acc: 0.7293 - val_loss: 14.0621 - val_acc: 0.5539\n",
      "Epoch 114/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2353 - acc: 0.6965 - val_loss: 13.7489 - val_acc: 0.6189\n",
      "Epoch 115/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1618 - acc: 0.7256 - val_loss: 13.7284 - val_acc: 0.6336\n",
      "Epoch 116/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1523 - acc: 0.7311 - val_loss: 13.7518 - val_acc: 0.6201\n",
      "Epoch 117/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1462 - acc: 0.7289 - val_loss: 13.7742 - val_acc: 0.6054\n",
      "Epoch 118/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1344 - acc: 0.7301 - val_loss: 13.7916 - val_acc: 0.5968\n",
      "Epoch 119/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1213 - acc: 0.7335 - val_loss: 13.7684 - val_acc: 0.6066\n",
      "Epoch 120/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1246 - acc: 0.7323 - val_loss: 13.6881 - val_acc: 0.6397\n",
      "Epoch 121/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1200 - acc: 0.7342 - val_loss: 13.8019 - val_acc: 0.6115\n",
      "Epoch 122/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1112 - acc: 0.7361 - val_loss: 13.6942 - val_acc: 0.6422\n",
      "Epoch 123/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.0835 - acc: 0.7419 - val_loss: 13.6916 - val_acc: 0.6397\n",
      "Epoch 124/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0856 - acc: 0.7426 - val_loss: 13.7128 - val_acc: 0.6275\n",
      "Epoch 125/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0796 - acc: 0.7424 - val_loss: 13.7027 - val_acc: 0.6299\n",
      "Epoch 126/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0672 - acc: 0.7444 - val_loss: 13.7653 - val_acc: 0.6029\n",
      "Epoch 127/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0668 - acc: 0.7431 - val_loss: 13.7609 - val_acc: 0.6262\n",
      "Epoch 128/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0475 - acc: 0.7468 - val_loss: 13.7254 - val_acc: 0.6324\n",
      "Epoch 129/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0484 - acc: 0.7458 - val_loss: 13.7210 - val_acc: 0.6213\n",
      "Epoch 130/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0587 - acc: 0.7342 - val_loss: 13.6859 - val_acc: 0.6471\n",
      "Epoch 131/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0373 - acc: 0.7420 - val_loss: 13.6674 - val_acc: 0.6262\n",
      "Epoch 132/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.0210 - acc: 0.7518 - val_loss: 13.6951 - val_acc: 0.6360\n",
      "Epoch 133/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0158 - acc: 0.7525 - val_loss: 13.7251 - val_acc: 0.6213\n",
      "Epoch 134/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0069 - acc: 0.7564 - val_loss: 13.6847 - val_acc: 0.6483\n",
      "Epoch 135/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9974 - acc: 0.7543 - val_loss: 13.6564 - val_acc: 0.6458\n",
      "Epoch 136/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9891 - acc: 0.7581 - val_loss: 13.6937 - val_acc: 0.6275\n",
      "Epoch 137/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9783 - acc: 0.7651 - val_loss: 13.6793 - val_acc: 0.6397\n",
      "Epoch 138/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9852 - acc: 0.7619 - val_loss: 13.7158 - val_acc: 0.6140\n",
      "Epoch 139/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9781 - acc: 0.7561 - val_loss: 13.6891 - val_acc: 0.6360\n",
      "Epoch 140/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9756 - acc: 0.7546 - val_loss: 13.6808 - val_acc: 0.6446\n",
      "Epoch 141/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9616 - acc: 0.7632 - val_loss: 13.6655 - val_acc: 0.6569\n",
      "Epoch 142/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9473 - acc: 0.7684 - val_loss: 13.8077 - val_acc: 0.5809\n",
      "Epoch 143/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9811 - acc: 0.7485 - val_loss: 13.6529 - val_acc: 0.6422\n",
      "Epoch 144/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9329 - acc: 0.7682 - val_loss: 13.7052 - val_acc: 0.6250\n",
      "Epoch 145/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9179 - acc: 0.7765 - val_loss: 13.7254 - val_acc: 0.6066\n",
      "Epoch 146/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9365 - acc: 0.7643 - val_loss: 13.6503 - val_acc: 0.6569\n",
      "Epoch 147/150\n",
      "7074/7074 [==============================] - 4s - loss: 12.9134 - acc: 0.7700 - val_loss: 13.6408 - val_acc: 0.6471\n",
      "Epoch 148/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9030 - acc: 0.7754 - val_loss: 13.6818 - val_acc: 0.6422\n",
      "Epoch 149/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.9019 - acc: 0.7710 - val_loss: 13.6538 - val_acc: 0.6409\n",
      "Epoch 150/150\n",
      "7074/7074 [==============================] - 3s - loss: 12.8907 - acc: 0.7744 - val_loss: 13.6306 - val_acc: 0.6458\n",
      "training time: 479.33487606048584\n",
      "800/837 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.6428\n",
      "\n",
      "Error Rate = 0.3572\n",
      "training time: 0.632312536239624\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "for test_fold in range(1, 11):\n",
    "    print('opening fold:', str(test_fold))\n",
    "    keras.backend.clear_session()\n",
    "    model = build_model()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True), metrics=['accuracy'])\n",
    "    train_x, train_y, valid_x, valid_y, test_x, test_y = load_all_folds(test_fold)\n",
    "\n",
    "    # for each channel, compute scaling factor\n",
    "    scaler_list = []\n",
    "    (n_clips, n_time, n_freq, n_channel) = train_x.shape\n",
    "\n",
    "    for channel in range(n_channel):\n",
    "        t1 = time.time()\n",
    "        xtrain_2d = train_x[:, :, :, channel].reshape((n_clips * n_time, n_freq))\n",
    "        scaler = sklearn.preprocessing.StandardScaler().fit(xtrain_2d)\n",
    "        # print(\"Channel %d Mean: %s\" % (channel, scaler.mean_,))\n",
    "        # print(\"Channel %d Std: %s\" % (channel, scaler.scale_,))\n",
    "        # print(\"Calculating scaler time: %s\" % (time.time() - t1,))\n",
    "        scaler_list += [scaler]\n",
    "\n",
    "    train_x = do_scale(train_x)\n",
    "    valid_x = do_scale(valid_x)\n",
    "    test_x = do_scale(test_x)\n",
    "\n",
    "    # use a batch size to fully utilize GPU power\n",
    "    t1 = time.time()\n",
    "    print(\"training model...hold tight\")\n",
    "    history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=callbacks,\n",
    "                        batch_size=1000,\n",
    "                        epochs=150)\n",
    "    print(\"training time: %s\" % (time.time() - t1,))\n",
    "    \n",
    "    t2 = time.time()\n",
    "    acc = evaluate(model, test_x, test_y)\n",
    "    print(\"training time: %s\" % (time.time() - t2,))\n",
    "\n",
    "    acc_list += [acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.6039 acc std 0.0909\n"
     ]
    }
   ],
   "source": [
    "acc_array = np.array(acc_list)\n",
    "print(\"acc mean %.4f acc std %.4f\" % (acc_array.mean(), acc_array.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History keys: dict_keys(['acc', 'val_acc', 'loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAHzCAYAAADy2UoqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERERHROP8CcPQBmTbKejcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8967502fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "print(\"History keys:\", (history.history.keys()))\n",
    "# summarise history for training and validation set accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarise history for training and validation set loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss', fontsize = 'large')\n",
    "plt.xlabel('epoch', fontsize = 'large' )\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py:913: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/837 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.6428\n",
      "\n",
      "Error Rate = 0.3572\n",
      "Showing Confusion Matrix\n",
      "                    air conditioner            horn        children             dog           drill          engine             gun          hammer           siren           music \n",
      "    air conditioner              84               0               0               0               0               1               0              15               0               0 \n",
      "               horn               1              18               6               3               0               0               1               0               2               2 \n",
      "           children               0               6              69              12               1               1               0               0               7               4 \n",
      "                dog               2               8               8              67               8               1               0               0               3               3 \n",
      "              drill               0               3               9               4              47              23               0              10               4               0 \n",
      "             engine              13               1               1               0               6              67               0               3               0               2 \n",
      "                gun               0               4               0               2               0               0              26               0               0               0 \n",
      "             hammer               0               6               0               0              25               7               0              58               0               0 \n",
      "              siren              11               2              17              10               1               4               0               0              34               4 \n",
      "              music               1               0              19               0               5               0               0               0               7              68 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f896769e048>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAHRCAYAAADAAuC2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XdcU1f/B/BPGAkggixRVESogAvcq4p7t9Y6QcWq1dZR\nV50VJ+6KC3GP6uOotWp3bWutq7W1WkVAUFSGIMpWNgmQ3x/8msojQesjOTfm8+4rr8pJcv3w9SQ3\nJ+fce2VqtVoNIiIiIiIi0itGogMQERERERHRv8fBHBERERERkR7iYI6IiIiIiEgPcTBHRERERESk\nhziYIyIiIiIi0kMczBEREREREekhE9EBiIiIiIiIRPGq26lSthsWf65StvskDuZeUGX9o+u7vzut\nMitdcBJpklvZsTZayK3sALDvaMO+o53cyg6FmcmiY0iSwsYRAF9X2sit7JDy23nRMSSp+us+ANh3\ntOF7snZ/789JNziYIyIiIiIigyWTyURHeGE8Zo6IiIiIiEgPcWaOiIiIiIgMlkymv/Nb+puciIiI\niIjIgHEwR0REREREpIe4zJKIiIiIiAyWEXgCFCIiIiIiItIhzswREREREZHB4qUJiIiIiIiISKc4\nM0dERERERAbLSI8vTcDBHBERERERGSwusyQiIiIiIiKd4mCOiIiIiIhID3Ewp0eqWlli5cYAXLj+\nDU5dOoZpc9+DkdHT/4TbDwRhWdA8AQmlQ6lUYsmK1WjftRc693oDe/9zUHQkSWF9tGNtKsb6PJtS\nqcTbw9/BH39eER1FUth3nqZUqTBq4WJcuRGpaTvw3ffoOHZ8mVvw4SMCU4rFflMx1od4zJweWbD8\nQ9hXt8WYIVNhY1cNq4MX4vGjLOzb8c+b/IChfdHepxW++vykwKTirQsOwfXwCOzasgnJKSmYvzgQ\nNWs4ok/PHqKjSQLrox1rUzHWp2KFhYWYtygQd2NiRUeRHPadsgpVKgTu2IXY+0ll2mPvJ2Fw924Y\n2a+Pps1crtB1PMlgv6kY6/NyyHjRcNKFDl3a4ODeY7gTHYvLv1/D91/9jNbtm2vut69ui6mzxyE8\nNEpgSvHy8vNx/MuvMWfGNDRq4ImunXwwxn8EPj16XHQ0SWB9tGNtKsb6VOxubBxGjpuIhP/6cE7s\nO/8t9n4SJixfifspqU/dF5f0APWd68DO2lpzszA3E5BSPPabirE+L4+RzKhSbjrJ/iJPWrFiBZKS\ndLezGjp0KBITE3HixAmcPn0aAHDwYOk08vnz5/HZZ5/pLItIjx9lod+AHjAzU8Chuh1e79QakeG3\nNPcvWP4hjhz4EvGxCQJTihcdfQdKpQrNm3pp2po39UZEZBSKi4sFJpMG1kc71qZirE/FrlwNRasW\nzXBg9zbRUSSHfaes0OhoNPP0xPaAsodElJSUIOHhQzjXqCEombSw31SM9SHgBZdZBgQEvOwcz2Xg\nwIGaP2/btg0jR46Ej4+PkCwirFiwASs2BOD3yJMwNjbGpd/+wrYN+wAAvd7ogjp1a2HWpMUINPDj\n5VLT02BtZQWF4p9lKXa2tlCpVMjIzISDvb3AdOKxPtqxNhVjfSo2bNAA0REki32nrLe7dC63/WFa\nOgqUSnxz/gKW7NgJM7kcfTt0gG+vHuUeI/+qY7+pGOvz8ujzpQkqHMzl5OQgICAA2dnZSElJwfDh\nwzF8+HD4+/tjyZIl+P7773Ht2jXk5eVhxYoVcHNzAwAUFBTgo48+QlJSElQqFRYuXIjGjRvjo48+\nQmJiIoqLizFmzBj07dsX/v7+8PT0xO3bt5GTk4NNmzahVq1a2LBhAy5cuIAaNWogMzMTALB582bY\n29vj0aNHePz4MZYsWQIvLy/ExMRg1qxZ2Lt3L7777juYmJigZcuWmD17NjZv3ozExESkp6cjKSkJ\nH330ETp27Ig///wTGzZsgLGxMerUqYPAwEB88803OH78OEpKSjB16lS0a9eu8v8F/oU6LrVw88Zt\nbN+0D5aWVfBR4DTMDJiInZsPYM7iKZg+PgBFRfwmpqCgAHK5aZk2U9PSn5VKlYhIksL6aMfaVIz1\noRfFvvN84h48AAA4VKuGNdOmIDr+nubkJ8P79BIZTQj2m4qxPgQ8YzAXHx+Pfv36oWfPnkhOToa/\nvz+GDx9e5jGurq5YsGBBmbYjR45oBmRxcXE4e/Ysbty4AVtbWwQFBSEnJwcDBw5E27ZtAQBeXl4I\nCAjAhg0b8N1336Fdu3a4fPkyjh07hry8PPTs2bPM9idOnIiDBw9iyZIlOHHiBADg1q1bOHnyJI4c\nOQITExNMmTIFZ86cAQDI5XLs3r0bv/32G/bu3YsOHTpg4cKFOHz4MOzs7LBx40Z88cUXMDExgZWV\nFbZtk94SmdrOTpiz6AP0ed0XyQ9L19gvmbsWOw4GwcXNGT99e8bgj5X7m1yueOpNTKUq/dnMzHAP\nIv8b66Mda1Mx1odeFPvO82nv7YVvgzfA2tISAOBWuzYeZ+fgxC9nDHIwx35TMdbn5TF6VWfm7O3t\nsX//fvz000+wtLREUVHRU4+pV6/eU20xMTGa5Y8uLi4YPXo0li5divbt2wMALC0t4ebmhoSE0mO7\nGjZsCACoUaMG0tLSEBcXh8aNG8PIyAiWlpZwd3d/5i8SExMDb29vzTcSLVu2xO3btwEADRo00Gxf\nqVQiIyMDKSkpmD59OoDSbzbat2+PunXrlvv7SEHDJh7IzsrRDOQAIDL8FkxMTNChcxu0aOONt4f1\nBQCYyuUAgEbenhjYY7SIuEI5OjggKzsbKpVK0x/S0tMhl8thbWUlOJ14rI92rE3FWB96Uew7z+/v\ngdzf6jrVRPqjR4LSiMV+UzHWh4BnnABl7969aNq0KYKCgtC7d2+o1eqnN1DOGm43NzeEh4cDABIS\nEjBz5ky4ubnhypXSa+7k5OQgOjoatWvXLvfvfe211xAWFoaSkhLk5eXhzp07Tz3mv7O4uroiLCwM\nRUVFUKvVuHz5smZg9t/rYG1sbFCjRg1s3boVBw4cwIQJEzSzhFJdk56anAYr66qwr26raXN9rS4A\nwPeN9zC411gM6TMOQ/qMw4Vffse5n3/D5NFzRcUVysOjPkxNTRAaFq5puxoahoaeHjAx4dU4WB/t\nWJuKsT70oth3ns/np37GO4uWlGm7HX8PdQz0hCjsNxVjfQh4xmCuS5cuOHz4MEaOHIn9+/fD2NgY\nSqXymRv19fVFYmIiRo4ciTlz5mD06NEYOnQoHj16BD8/P4waNQoffPAB7Ozsyn1+gwYN4OPjg8GD\nB+PDDz8s93Fubm6YNWuW5mcPDw/06dMHfn5+GDx4MGrVqoXu3buX/0sbGSEgIADvvfcefH19cfjw\n4eea/RMp7Fokbt+MwcoNAajv6QqvZg2xaNUsfHP8R0SG30JC/H3NLS8vH7k5eXhwP1l0bCHMzczQ\nv19fLF8ThPAbkThz7gL2HzyMEb5DRUeTBNZHO9amYqwPvSj2nefTpnFjJCanYPuxE0hMTsGpPy7h\n0MkfMKJvb9HRhGC/qRjr8/LIYFQpN51kV5c33UbP5FW3k87/TofqdpizeApat28GlaoIp74/h42r\ntqOwsOwAe+XGABQXFWPhrNU6zxgWfw4AoMxK1/nf/aT8ggIsX70Wp345C8sqVfDOCF+8M3L4s59Y\nyeRWdsJrA0izPnKr0i9tRNdHirUB2HcqIreyQ2GmtL688mrrg53B69G2dUuhORQ2jgDEv64A6fad\nlN/OC83Qcex4bJg5Ay0blR5yciUyCjuOHUds0gPYWlnBr08vrWe/rEzVXy89XEZ035FivwH4nlyR\nv/fn+qSjR/9K2e6FW19XynafxMHcCxIxmNMHUhnMSZVU3vylSCqDOali39FOioM5qZDSYE6KpDCY\nkyqpDOakiu/J2unjYM7H861K2e75m19VynafJM0DxIiIiIiIiKhCPDqSiIiIiIgM1it7aQIiIiIi\nIqJXmQz6O5jjMksiIiIiIiI9xMEcERERERGRHuJgjoiIiIiISA/xmDkiIiIiIjJYRjL9nd/iYI6I\niIiIiAyWTI/PZqm/w1AiIiIiIiIDxpk5IiIiIiIyWPp8nTnOzBEREREREekhzswREREREZHB4kXD\niYiIiIiISKc4mCMiIiIiItJDXGZJREREREQGS5+vM6e/yYmIiIiIiAyYTK1Wq0WHICIiIiIiEqGv\nl1+lbPf7sE8rvP/EiRP44osvAACFhYWIiorC+vXrsWbNGtSsWRMAMGXKFLRu3VrrNjiYe0GFmcmi\nI0iSwsYRAJB06pTgJNLk1KMHsuNuiY4hSVVdPAAAecn3BCeRJgtHZyiz0kXHkCS5lR1ro4Xcyg4A\n91naKGwc2Xe0+LvvFKQlCU4iTWb2TqyNFmb2TqIj/GuiBnNPWrp0KTw9PZGUlISGDRuiV69ez/U8\nLrMkIiIiIiKDZSSTVcrteYWHh+POnTsYNmwYbty4gePHj2P48OFYvXo1ioqKKs7+v/7yRERERERE\n+kpWSf89rx07dmDy5MkAgNdffx0LFy7EoUOHkJeXhyNHjlT4XA7miIiIiIiIBMjKykJsbCzatm0L\nABg0aBDq1KkDmUyGbt26ITIyssLnczBHREREREQkwOXLl9GuXTsAgFqtRv/+/fHw4UMAwO+//45G\njRpV+HxeZ46IiIiIiEiA2NhY1K5dGwAgk8mwfPlyfPDBBzAzM4ObmxuGDh1a4fM5mCMiIiIiIoMl\n+xcnK3nZxo0bV+bnDh06oEOHDs/9fA7miIiIiIjIYP2bM09KDY+ZIyIiIiIi0kOcmSMiIiIiIoP1\nby4jIDWcmSMiIiIiItJDnJkjIiIiIiKDZSTT3/kt/U1ORERERERkwDiYIyIiIiIi0kMczL0ClEol\n3h7+Dv7484roKMIpVSqMWbECf928qWlLyczE/O3b8casWfBdtAhHT58WmFAaioqKsH7HHnQbMgLd\nBo/AquCtUCpVomNJQmz8Pbw/Yw7a93oTfYaMwP5Pj4qOJClKpRJLVqxG+6690LnXG9j7n4OiI0kG\na/Ns3F+Vj31Hu4TE+5gyZz469H4TPQYMQdDmrSgsVIqOJRmsz8shk8kq5aYLPGZOzxUWFmLeokDc\njYkVHUU4pUqF5fv2Ie7BgzLtS/fsgYONDbbNno345GSs2LcP1W1s0Ll5c0FJxdu06xOc/f0S1i0J\ngAwyLFizDtaHP8Ok0SNFRxNKVVSED2YHoFVzbwTMnIa4ewmYH7gKDnZ26Nuzm+h4krAuOATXwyOw\na8smJKekYP7iQNSs4Yg+PXuIjiYca1Mx7q+0Y98pn0qlwtS5AXB1qYv/bA9BRmYmFq9cCwCYNWWS\n4HTisT4EcGZOr92NjcPIcRORcD9JdBTh4h48wKSgINxPSyvTnp2Xh8i4OIzs1Qt1HB3RwcsLrRo0\nwLXoaEFJxcvOycGx704iYNpkNG3UEN6NGuC9kX64efuO6GjCpaamoXEDD8ybMQXOtWvBp31btGnR\nDH9dDxMdTRLy8vNx/MuvMWfGNDRq4ImunXwwxn8EPj16XHQ04VibinF/pR37jnbhkTdxL/E+lgXM\ng6tLXbRs1hSTx4/B9z/9LDqaJLA+L4+RTFYpN51k18nfQpXiytVQtGrRDAd2bxMdRbjrd+6gmbs7\ntsycWaZdYWoKM7kcP/zxB4qKi3EvORkRMTFwd3YWlFS80IgomCkUaNO8qabtzZ7dELxiibhQEuFU\nswbWLF0AM4UCarUaoeERuBoWjtbNm4mOJgnR0XegVKrQvKmXpq15U29EREahuLhYYDLxWJuKcX+l\nHfuOdi7OdbAlaDUsLMw1bTKZDNk5OQJTSQfrQ8ArtszyxIkTiImJwaxZs0RH0YlhgwaIjiAZb3Xs\nWG673NQU04YORfDnn+OL8+dRUlKCHq1bo1/79jpOKB2JDx6gZvXq+PHMeez99CjyCgrQvePrmDzG\nH6ampqLjSUavQX5ITUuHT/u26N65/P5laFLT02BtZQWFQqFps7O1hUqlQkZmJhzs7QWmE4u1qRj3\nV9qx72hna1MNbVu10PxcUlKCI8e/QJuWLSp4luFgfV4efb5o+Cs1mCMqT0JKClo3bAjf7t3xID0d\nm44exbEzZzC4SxfR0YTIzc/H/YfJ+OzrbzF/2mTk5udj9eZtKC4uxsyJ40XHk4wNK5ciNS0dK9cH\nIyhkO+ZOmyw6knAFBQWQy8sO+P/+AsDQT6DD2tCLYt95fkHBW3Ez+g4OcYa3XKzPi9PVksjK8MoN\n5q5fv46xY8ciIyMDfn5+qF27NjZu3AiFQoFq1aph5cqViIqKQlBQEExNTTF06FDs2bMHrVu3xq1b\ntyCTybB161ZUrVpV9K9CL8G16Gh8deECPl++HOYKBTzr1kVBYSG2nDiBtzt1grGR4a00NjE2Rm5e\nHpbN+RC1nWoCAKaNH4PFH2/AjPffhZEB1qQ8jTw9AAAFhYVYtHItPpz0nsHPXMrliqc+XKpUpT+b\nmSnKe4rBYG3oRbHvPJtarcbHm0Jw9MRXCFqxBK+51hMdSVJYH8P2yn1qMzExwZ49exASEoJ9+/Zh\n4cKFCAkJwcGDB9GqVSts21b6bUVhYSEOHz6MAQMGIDc3F/369cPBgwdRvXp1nD9/XvBvQS/Lzfh4\n1LK3h/kTy1fcnZ2Rm5+PrNxcgcnEsbe1hbGxsWYgBwAutWuhUKlE5uPHApOJl5KahrO/XizT5upS\nFyqVCjm5eYJSSYejgwOysrM1HzQBIC09HXK5HNZWVgKTicfa0Iti36lYSUkJFq38GEe/+BprAheh\nS8cOoiNJCutDr9xgrmHDhpDJZHBwcMCDBw9gaWkJR0dHAECrVq1w+/ZtAEC9evWeeh4A1KxZE4WF\nhboNTZXG3toaD9LToXxiJxn/8CEszMxQzdJSYDJxvBp6ori4GHdi4zRtMfEJqGJhbvAfHGLi72HW\nwqXIyMzUtEXdioZNtWqwqWYtMJk0eHjUh6mpCULDwjVtV0PD0NDTAyYmr9xCj3+FtaEXxb5TsXWb\nt+HkqdNYvzIQ3Tv7iI4jOawPvXKDuScv0GdjY4OcnBykpKQAAP7880+4uLgAwFNLyXR1YT/SrXZN\nmkBhaoo1Bw/iXnIy/rp5Ezu//BKDOnc22H9z51pO6NSuDZauC0bU7Tu4Fn4DIXv3Y0DvnjAxNhYd\nT6gWTb3gWrcuFq1ci5i4eJy/+AeCd+zBOH8/0dEkwdzMDP379cXyNUEIvxGJM+cuYP/BwxjhO1R0\nNOFYG3pR7DvahUVE4uDRY5j47mg08vRAWnqG5kasz8vEi4ZLlEwmw/LlyzFlyhTIZDJYW1tj1apV\nmtk5evVZmptj3dSp2HL8OCYFBcHS3Bx92rXDyN69RUcTKnDODARt24UJcxbAxNgY/Xp0xQdjR4mO\nJZypiQmC1yzHqg2bMWrCVFhYmGP4kIHwG/y26GiSMXvGVCxfvRbvTpwCyypVMGHcGPTuwQuqA6wN\nvTj2nfKdOnsOABC8fReCt+8qc99f536GiYlhfwHJ+rw8+nwCFJlarVaLDqGPCjOTRUeQJIVN6ZLW\npFOnBCeRJqcePZAdd0t0DEmq6lJ6wpG85HuCk0iThaMzlFnpomNIktzKjrXRQm5lB4D7LG0UNo7s\nO1r83XcK0nih9/KY2TuxNlqY2TuJjvCvjWzzXqVs9+ClnZWy3Se90jNzREREREREFdHn68y9csfM\nERERERERGQLOzBERERERkcHS52PmODNHRERERESkhziYIyIiIiIi0kNcZklERERERAZLn689zJk5\nIiIiIiIiPcSZOSIiIiIiMlg8AQoRERERERHpFGfmiIiIiIjIYOnzRcM5mCMiIiIiIoPFZZZERERE\nRESkUxzMERERERER6SEO5oiIiIiIiPQQj5kjIiIiIiKDpc8XDedgjoiIiIiIDJY+nwBFplar1aJD\nEBERERERiTCh49RK2e72C8GVst0ncWaOiIiIiIgMFpdZGiBlVrroCJIkt7IDAGTH3RKcRJqqunhg\nbPtJomNI0t6LWwEA6VcvCU4iTXbN26AwM1l0DElS2DiyNloobBwBcJ+ljdzKjrXR4u/9edbdKMFJ\npMnKrQHykmJFx5AkC6d6oiMYFA7miIiIiIjIYMmgvzNzvDQBERERERGRHuJgjoiIiIiISA9xmSUR\nERERERksI/1dZcmZOSIiIiIiIn3EmTkiIiIiIjJY+nxpAs7MERERERER6SHOzBERERERkcEy0uOZ\nOQ7miIiIiIjIYHGZJREREREREekUB3NERERERER6iIM5IiIiIiIiPcRj5oiIiIiIyGAZQX+PmeNg\nTo8plUqsXLseP50+A7mpKUaN8MXYUSNFx5KEoqIiBO/Zj+9+/gVQA919XsfMCeMhl5uKjiaEsbER\nBk9+G+17t4FMBlw+fRWfbjqGIlUR6tSvjREzhsK5fm0k30/FsW1f4salKNGRdU6pUmHM/EWYPmoE\nWjVpDAC4FRuH4AOHcSs2DtZVLfFW1y4Y2b8fjIy4qEGpVGLY6PGYO30K2rZuKTqOpLA25eM+SzvW\npnzfnDqNwA2by79v3y7UqO6g40TSFRi0EfcS72P3xrWio+glfT4BCgdzemxdcAiuh0dg15ZNSE5J\nwfzFgahZwxF9evYQHU24Tbs+wdnfL2HdkgDIIMOCNetgffgzTBptmDvHoR8MRDMfb2yeux1qNfD+\n0jHIycrFz0fPYPbmabj+azj2rzkMt8Yu+GDle1gzeQPibt4THVtnCpVKLAnZhtjE+5q2rJwcfLg6\nCN3atsbc8WOQ8OAhlm/bBXMzBYb07ikwrXiFhYWYtygQd2NiRUeRHNZGO+6ztGNtytfDpwPatWiu\n+VmtVmPGkuWoVcORA7knXPrrGr747ge08G4iOgoJwK+X9VRefj6Of/k15syYhkYNPNG1kw/G+I/A\np0ePi44mXHZODo59dxIB0yajaaOG8G7UAO+N9MPN23dERxPC3NIcnd/uiH2rD+FOeAzuRsTgqz3f\nwcXDGe37tEFBXgH2rTqIB/EP8et3f+DiD3+il1830bF1JjbxPt5bFIj7ySll2i9euw4TE2NMf2ck\nnGvWxOvNm8G3X2/89NvvgpJKw93YOIwcNxEJ95NER5Ec1kY77rO0Y220M1MoYG9ro7mdufg7klPT\nEDB1suhokpGfX4Dl64PRtHFD0VH0mpFMVik3nWTXyd/yPzhx4gSCgoKeap8xYwaUSiXmzZuH8+fP\nl7mvsLAQXbt21VVEIaKj70CpVKF5Uy9NW/Om3oiIjEJxcbHAZOKFRkTBTKFAm+ZNNW1v9uyG4BVL\nxIUSyN3LDcoCFSIv39S0/fb9H9gwcwscnOwRfzMBxcUlmvsS7iTCrbGriKhCXIu6ieYNG2Bn4KIy\n7c0aeiJwyqQySyplkCE7L0/XESXlytVQtGrRDAd2bxMdRXJYG+24z9KOtXk+uXn52HXoM7zv7wer\nqpai40hGyJ59aOHdBC2f6D9kWPR2meWGDRtERxAqNT0N1lZWUCgUmjY7W1uoVCpkZGbCwd5eYDqx\nEh88QM3q1fHjmfPY++lR5BUUoHvH1zF5jD9MTQ3vmDmH2g5If5iONj1a4o13ekNhocCVX67h+Pav\n8DgjCy4N6pZ5vH0NW1haVxGUVvcG9ih/FtLRzg6OdnaanwuVSnx95izaNfXWVTRJGjZogOgIksXa\naMd9lnaszfM5cfJHyE1NMaCXYS89fdL1G5E4de4Cju3djgOcyf2f6PEhc9IbzBUUFOCjjz5CUlIS\nVCoVevXqhevXr2Ps2LHIyMiAn58fhg0bhq5du+LkyZOa5+Xm5mLWrFnIysqCs7Ozpt3f3x+2trZ4\n/Pgxdu7ciSVLliA+Ph4lJSWYPn062rRpgzfffBOtW7fGrVu3IJPJsHXrVlStWlXEr//cCgoKnjqZ\nx98DFaVSJSKSZOTm5+P+w2R89vW3mD9tMnLz87F68zYUFxdj5sTxouPpnJmFAvZO9ug2pDP+8/Gn\nMLNQwH+2H4yNjXDuq1/Rf0xfdB3UCee+vIC6ns7o8EZ7mJhK7q1BqOKSEizdsh35BYUY/XZ/0XGI\n9A73WdqxNs+mVqvxxckfMbR/P5iYcP8ElJ40Z+najZg9+X1YSfwzK1UuyS2zPHLkCGrVqoXPPvsM\n69evh0KhgImJCfbs2YOQkBDs379f6/Pc3d1x6NAh+Pr6lrnvjTfewL59+3Ds2DHY2Njg0KFD2Lp1\nKwIDAwGUDgT79euHgwcPonr16k8t25QiuVzx1Ju8SlX6s5mZorynGAwTY2Pk5uVh2ZwP0bRxQ7ze\nqgWmjR+DE9//iJKSkmdv4BVTUlwCC0tz7Fq6D7fD7iL8j0h8FnICnQZ0wIP4ZOxZcQAD33sTO84G\nY9zCd/Dz0TPIzy0QHVsyVEVFWLhpC/4Mi8DHs2fArlo10ZGI9A73WdqxNs92885dJD54iL5dO4uO\nIhk7/3MYzrWc0KOzj+goJJjkvt6IiYmBj09px3RxcYGVlRUaNmwImUwGBwcHFBSU/yEzLi4OnTp1\nAgB4e3uX+eamXr16AIDo6Gj89ddfCAsLA1B6+vqMjAwAQMOGpQeO1qxZE4WFhZXzy71Ejg4OyMrO\nhkql0nyDl5aeDrlcDmsrK8HpxLK3tYWxsTFqO9XUtLnUroVCpRKZjx/DzsZGYDrde5T6GEVFxUi9\nn6ZpexifDLlCjqrVLPHHj3/i0k+XYWVbFY/Ts9BloA/SH6QLTCwdhUol5q3bhIjbd7B+3iw0es1N\ndCQivcR9lnaszbNdvHIVjT3c4WBnKzqKZJw8fQZp6Rlo36d0ebeqqAglJSVo32cALp78UnA6/aOr\nk5VUBsnNzLm5uSE8PBwAkJCQgPXr1z/XtR/c3NwQGhoKAIiMjERRUZHmvr+f7+rqin79+uHAgQPY\ntWsXevfujWr//y27vl1fwsOjPkxNTRAaFq5puxoahoaeHga/BMGroSeKi4txJzZO0xYTn4AqFuYG\nuWO8ExEDExNj1HJ10rQ51auJ/Nx81HZzwqQV46BWq/E4PQsA0LRDE0RdjRYVV1KWhGxD5N272BQw\nF14e7qLDJ/axAAAgAElEQVTjEOkt7rO0Y22eLeJmNJo1aSQ6hqTs2vAxPv9kB47s3ooju7diYL/e\naOheH0d2bxUdjXRMcoM5X19fJCYmYuTIkZgzZw7GjBnzXM/z8/NDQkIC/Pz8cOjQoXJPdOHr64uY\nmBiMHDkSvr6+qFWrlt5e/NfczAz9+/XF8jVBCL8RiTPnLmD/wcMY4TtUdDThnGs5oVO7Nli6LhhR\nt+/gWvgNhOzdjwG9e8LE2Fh0PJ1LSUzF1fPX8W6AP+p61EF9bzcMnvgWzn/9G+7HPkDjNg3RfWgX\n2Ne0w4Bxb8CtUT38fPSM6NjC/fz7Hzh3+S98OHoUHO1skf7oEdIfPUJmVpboaER6h/ss7VibZ7sb\nHw835zqiY0iKUw1HONdy0tysqlpCoZDDuZbTs59MT5FV0n+6ILmvfBQKBdatW6f1vl9++QUANP9f\nvXq15v5NmzY99ZwDBw5o/iyXy/Hxxx8/9Zi/twUAs2bNerHgAsyeMRXLV6/FuxOnwLJKFUwYNwa9\ntZyZz9AEzpmBoG27MGHOApgYG6Nfj674YOwo0bGE2R24D37Th2D25ukoKS7Gbycv4di2r1BcVIyt\nAbsxbMpADHq/P+5FJyBoWjAyUx+JjizcL39cBgAs3bK9TLuDrQ2+2vL0ew0RVYz7LO1Ym4plPHrM\nk3wQaSFTq9Vq0SH0kTKLxxSVR25Veir37LhbgpNIU1UXD4xtP0l0DEnae7F0aUj61UuCk0iTXfM2\nKMxMFh1DkhQ2jqyNFgobRwDcZ2kjt7JjbbT4e3+edTdKcBJpsnJrgLykWNExJMnCqZ7oCP/a/F4f\nVcp2V/64qlK2+yTJzcwRERERERHpCk+AQkRERERERDrFmTkiIiIiIjJYejwxx5k5IiIiIiIifcTB\nHBERERERkR7iMksiIiIiIjJYPAEKERERERER6RRn5oiIiIiIyGDJIG5mbseOHfjll1+gUqng5+eH\n1q1bY968eZDJZKhfvz4WL14MIyPt82+cmSMiIiIiItKxS5cu4dq1a/j0009x4MABPHz4EKtWrcL0\n6dNx+PBhqNVqnD59usJtcDBHREREREQGy0gmq5Tbs/z6669wd3fH5MmTMWHCBHTu3Bk3btxA69at\nAQA+Pj64ePFihdvgMksiIiIiIjJYos5/kpmZiaSkJGzfvh2JiYmYOHEi1Go1ZP8fqEqVKsjOzq5w\nGxzMERERERER6Vi1atXg6uoKuVwOV1dXKBQKPHz4UHN/bm4urKysKtwGl1kSERERERHpWIsWLXDh\nwgWo1WokJycjPz8f7dq1w6VLlwAA58+fR8uWLSvcBmfmiIiIiIiIdKxLly64fPkyBg8eDLVajUWL\nFqF27dpYuHAh1q9fD1dXV/Tq1avCbXAwR0REREREBksm8KLhc+bMeart4MGDz/18LrMkIiIiIiLS\nQzK1Wq0WHYKIiIiIiEiElf0XV8p253+9tFK2+yQus3xBBWlJoiNIkpm9EwDgcXS44CTSZO3ehLXR\nwtq9CQBgos80wUmkadv5Tew7Wli7N0FhZrLoGJKksHEEACiz0gUnkSa5lR1ro4Xcyg4AkJd8T3AS\nabJwdGZttLBwdBYd4V8TuMryf8ZllkRERERERHqIM3NERERERGSwjPR4ao4zc0RERERERHqIgzki\nIiIiIiI9xGWWRERERERksGTgMksiIiIiIiLSIc7MERERERGRwZLxBChERERERESkS5yZIyIiIiIi\ng2WkvxNzHMwREREREZHh4jJLIiIiIiIi0ikO5oiIiIiIiPQQB3NERERERER6iMfM6bGExPv4OHgL\nroWFw9zMDL26dcGU98ZBoZCLjiZcVk4OgnbswcUr16CQy9Gniw8m+vvB2NhYdDRJYH3+YWRshLcn\n9EfbXq0AmQxXz1zD55tPYPisYWjXp81Tj09LSsNC32UCkkoD+86zKZVKDBs9HnOnT0Hb1i1Fx5EM\npVKJlWvX46fTZyA3NcWoEb4YO2qk6FiSwNpoFxt/D6s3hiA8MgrWVlbwHfgW3vEbKjqWZLA+L4c+\nHzPHwZyeUqlUmDo3AK4udfGf7SHIyMzE4pVrAQCzpkwSnE68j7ftQlpGJnasDkTm4ywsDNoIa6uq\n8B/4luhoksD6/GPQpLfg3aEJts3fDUCNsQtHITerF44Gn8CXO77RPK6qTVXMDJmGn4+eFZZVCth3\nKlZYWIh5iwJxNyZWdBTJWRccguvhEdi1ZROSU1Iwf3EgatZwRJ+ePURHE461KZ+qqAgfzA5Aq+be\nCJg5DXH3EjA/cBUc7OzQt2c30fGEY30I4DJLvRUeeRP3Eu9jWcA8uLrURctmTTF5/Bh8/9PPoqNJ\nwm9XrsG3/xtwq+uMll6N0atTR1y5Hi46lmSwPqXMLc3R8a0OOLj2M8RExCImIg7ffvIDnN3roCC3\nAFkZ2Zpb33d6IS4yHudOXBAdWyj2He3uxsZh5LiJSLifJDqK5OTl5+P4l19jzoxpaNTAE107+WCM\n/wh8evS46GjCsTbapaamoXEDD8ybMQXOtWvBp31btGnRDH9dDxMdTRJYn5fHSFY5N51k181fQy+b\ni3MdbAlaDQsLc02bTCZDdk6OwFTSYV3VEj+cO4+CgkKkpmfg97+uwfM1N9GxJIP1KeXWxBWqQiVu\nXrmlafvjhz8RMmdHmcfVa+QC7w5NcCzkC11HlBz2He2uXA1FqxbNcGD3NtFRJCc6+g6UShWaN/XS\ntDVv6o2IyCgUFxcLTCYea6OdU80aWLN0AcwUCqjVaoSGR+BqWDhaN28mOpoksD4vj0wmq5SbLhjE\nMsvCwkL06dMHv/zyi+goL42tTTW0bdVC83NJSQmOHP8CbVq2qOBZhmPuxPFYvH4zOg/zR0lJCVp6\nNcb44VxD/jfWp5RDLXukP8xAq+4t0Nu/BxTmClw9G4qvdn6L4qJ/PkT18e+Ja+evIyn2gcC00sC+\no92wQQNER5Cs1PQ0WFtZQaFQaNrsbG2hUqmQkZkJB3t7genEYm2eT69BfkhNS4dP+7bo3rmj6DiS\nw/oYLs7MvSKCgrfiZvQdTJ/4nugokpDw4CE8XF2wY1UgNi6ejwcpqQje+x/RsSSD9SllZqGAfU07\ndB7YEYeDjuLTdUfRvJM3Bk7sr3mMraMNGrVpgNOfnRUXVELYd+hFFBQUQC43LdNmalr6s1KpEhFJ\nMlib57Nh5VJsWLkUUdG3ERSyXXQcyWF9/jcyWeXcdOGVnZnLzc3FrFmzkJWVBWdnZwBAZGQkli1b\nBmNjYygUCixbtgxOTk7YsmULfv75Z9ja2iI/Px/Tpk1DmzZPn8VOitRqNT7eFIKjJ75C0IoleM21\nnuhIwiU+eIgNuz7Bl3u2wdHeDgAQIJdjysJAvDP4bdjZVBOcUCzW5x/FxSUwtzTHJ8sPIC0pHQBw\nfOtXGL1gJI6FfAm1Wo1mnZsi9X4q4qLiBacVj32HXpRcrnhqYKJSlf5sZqYo7ykGg7V5Po08PQAA\nBYWFWLRyLT6c9J5m0EusjyF7ZWfmjhw5And3dxw6dAi+vr4AgAULFmDRokU4ePAg/Pz8sHr1aty8\neRMXLlzAsWPHsGXLFqSmpgpO/vxKSkqwaOXHOPrF11gTuAhdOnYQHUkSou7EwLJKFc2HTQDwfM0V\nxSUleKhH/76VhfX5x+O0xyguKtYM5AAgOSEFcoUcltUsAQCN2zTAtfM8mBxg36EX5+jggKzsbM0g\nBQDS0tMhl8thbWUlMJl4rI12KalpOPvrxTJtri51oVKpkJObJyiVdLA+BLzCg7m4uDg0adIEAODt\n7Q0TExOkpKSgQYMGAIBWrVrh9u3buHv3Lpo0aQJjY2OYmZmhcePGImP/K+s2b8PJU6exfmUgunf2\nER1HMhxsbZCdm4u0jExNW1xCIgCglqOjqFiSwfr8I+ZGHIxNjOHkWlPTVtOlBvJzC5CblQsAqNug\nLm6H3hEVUVLYd+hFeXjUh6mpCULD/jnz6dXQMDT09ICJySu7SOi5sDbaxcTfw6yFS5GR+c97TtSt\naNhUqwabatYCk0kD6/PyGMlklXLTSXad/C0CuLm5ITQ0FEDp8sqioiJUr14dN2/eBABcvnwZLi4u\neO211xAeHo6SkhIolUpERkaKjP3cwiIicfDoMUx8dzQaeXogLT1DczN0jT3d4VbXGYvXB+N2bBzC\nb0ZjZcgO9Onig2rWhv0tJ8D6PCk1MRWhF8Iwat5wOLvXxmterhjw/pv47dvfUVJcAtsatjCvYoYH\ncQ9FR5UE9h16UeZmZujfry+WrwlC+I1InDl3AfsPHsYIX548h7XRrkVTL7jWrYtFK9ciJi4e5y/+\ngeAdezDO3090NElgfQh4hY+Z8/Pzw5w5c+Dn5wdXV1eYmppi+fLlWLZsGdRqNYyNjbFy5UrUqVMH\nnTp1wtChQ2FjYwNTU1O9+Cbs1NlzAIDg7bsQvH1Xmfv+OvczTEyMRcSSBBNjY2xcPB/rd32CSQFL\nYWpqgq7t2+KD0SNFR5ME1qesfcsPYujUgZi+8QMUF5fgjx/+1Fws3MqmKgAgN4vLVQD2HfrfzJ4x\nFctXr8W7E6fAskoVTBg3Br178MLGAGujjamJCYLXLMeqDZsxasJUWFiYY/iQgfAb/LboaJLA+rw8\nMujobCWVQKZWq9WiQ4iUnp6OH374ASNGjIBSqUS/fv2wf/9+ODk5Vfi8gjReFLY8ZvaldXsczYsI\nl8favQlro4W1e+my6Ik+0wQnkaZt5zex72hh7d4EhZnJomNIksKmdPmrMiv9GY80THIrO9ZGC7lV\n6bGxecn3BCeRJgtHZ9ZGCwtHZ9ER/rWtvqsqZbuTjnxUKdt9kvSnoCqZjY0NIiIiMGjQIMhkMgwZ\nMuSZAzkiIiIiIno16OoyApXB4AdzRkZGWLWqckbjREREREQkbbo6WUlleGVPgEJERERERPQq42CO\niIiIiIhID3EwR0REREREpIcM/pg5IiIiIiIyXDI9PmaOgzkiIiIiIjJYejyW4zJLIiIiIiIifcSZ\nOSIiIiIiMlj6vMySM3NERERERER6iDNzRERERERksIz0d2KOM3NERERERET6iIM5IiIiIiIiPcRl\nlkREREREZLB4AhQiIiIiIiLSKc7MERERERGRwdLjiTnI1Gq1WnQIIiIiIiIiEfaNXlsp2x29b3al\nbPdJnJkjIiIiIiKDZaTHU3MczL0gZVa66AiSJLeyAwDkJd8TnESaLByd8SjquugYklStgTcAIC8p\nVnASabJwqofPJ24UHUOShmybjpjPvxIdQ5Jch7wFgPssbeRWdsi8cVV0DEmyadQcAN+TtbFwqsfX\nlRZ/fxbUJzwBChEREREREekUB3NERERERER6iIM5IiIiIiIiPcRj5oiIiIiIyGDp8SFzHMwRERER\nEZHh4glQiIiIiIiISKc4M0dERERERAZLjyfmODNHRERERESkjzgzR0REREREBstIj6fmODNHRERE\nRESkhziYIyIiIiIi0kNcZklERERERAZLj1dZcmaOiIiIiIhIH3FmTo8plUqsXLseP50+A7mpKUaN\n8MXYUSNFx5KE2Ph7WL0xBOGRUbC2soLvwLfwjt9Q0bEk41FWFtbu3Is/Q6/Dwtwcvm/2hV//N0TH\nkpzAoI24l3gfuzeuFR1FuC+iziI9/zHGNX8Lu69+hbhHSU89pl41J7zb/C0B6cRISk/Hju+/RmR8\nHBRyOTo18cI73XtDbmqKSzcjse/UD0hKT0NteweM7tkHrdw9RUcWivuspylVKoyeNR/Tx45Ca+8m\nAIDH2TlYs303/ggNg5VlFYz3HYx+XToJTioNfE9+Gl9XL4c+XzScgzk9ti44BNfDI7BryyYkp6Rg\n/uJA1KzhiD49e4iOJpSqqAgfzA5Aq+beCJg5DXH3EjA/cBUc7OzQt2c30fEkYc6qIBQUFiJ4yQLk\n5ucjcNMWyGRG8H2zr+hoknHpr2v44rsf0OL/P2AZsrsZifjrQRRcqjkBAIY36YXikhLN/Sm5Gdh/\n/Tu87uwtKqLOqYqKsOTgJ3Cu7oh1703Co9wcbDjxOQCgZ4vWWHHkIMb17odW7p74LTICgYf2Y+e0\nWahpayc4uTjcZ5VVqFRi0YYQxCQklmlftnkb8gsKsHPlEkTduYs12/egTs2a8PJ0F5RUGvieXD6+\nrojLLPVUXn4+jn/5NebMmIZGDTzRtZMPxviPwKdHj4uOJlxqahoaN/DAvBlT4Fy7Fnzat0WbFs3w\n1/Uw0dEkIepODK5H3cSymdPQ4DU3tGzSGB+8MxIHTnwlOppk5OcXYPn6YDRt3FB0FOGUxSp8efMc\nnK1raNosTM1QVWGBqgoLWMrN8dPdS2hWwx2e9i7igurYrcQEPMhIx8yBQ+Fc3RFe9dwwqnsvnLl+\nDWmPH6F/2/bo3/Z11LS1w+AOnWAml+Nmwj3RsYXhPqus2IREjJu3CPcfJpdpT3yYjF+vXMW8iePx\nWl1nvNmtC3r5dMDxH34SlFQa+J5cPr6uXh6ZrHJuumAwg7nCwkJ07dq1TNv58+fx2WefITExEUOH\nli7B69q1KwoLC0VE/Feio+9AqVSheVMvTVvzpt6IiIxCcXGxwGTiOdWsgTVLF8BMoYBarUZoeASu\nhoWjdfNmoqNJQlJyMqwsq6BuLSdNW32XukjLzERScorAZNIRsmcfWng3QcsnXl+G6tTdS6hn44R6\n1ZzKvT8s+Q7S8jLRw62NjpOJVdvBAYH+Y2GuUGjaZAByCgrQor4HxvUuXbZcVFyMH6/8CVVRERrU\nqSsorXjcZ5V19UYUWjRuiN2rA8u034i+A3ubaqhT858vT7wbeCDi1m1dR5QUvieXj6+rl0cmk1XK\nTRcMepmlj48PACAxMfEZj5Se1PQ0WFtZQfHEBwk7W1uoVCpkZGbCwd5eYDrp6DXID6lp6fBp3xbd\nO3cUHUcSbKtZIzcvH7n5+ahibg4AeJiaBgB4nJ0NJ8fqIuMJd/1GJE6du4Bje7fjgIF/u3nv8UNE\npMRgapth+PVeaLmPOR9/Fa1rNYKl3ELH6cSqVsUSzV6rr/m5pKQE31y6iGZur2naElJTMGHzepSU\nlGBMzz6oYWsrIqokcJ9V1qDe5S+BS8vMhL2tTZk222rWSEnP0EUsSeJ7snZ8XRHwig/mcnNzMWvW\nLGRlZcHZ2RkA4O/vD1tbWzx+/Bj9+vVDfHw8fH19BSf99woKCiCXm5ZpMzUt/VmpVImIJEkbVi5F\nalo6Vq4PRlDIdsydNll0JOEauddHdXs7fLx9F+ZMGI/cvHzsOlJ6rI+qqEhwOrGUSiWWrt2I2ZPf\nh1XVqqLjCFVUUowvos6in/vrMDdVlPuYuEcPkJr3CKO8++k4nfTsPPkt7j5IwqYJUzRtNpZVsWnC\nFETei8Ouk9/Cyc4eHRoZ5vE+3Gc9n8JCJUxNytZJbmoCVVER1Gq1Xp+k4UXwPblifF0R8Iovszxy\n5Ajc3d1x6NChMgO2N954A/v27YOxsbHAdP8buVzx1AtVpSr92cys/A9ehqiRpwc6d2iPDye/j+Nf\nf6epkSGTm5pi9dyZuHH7LrqPGI0R02bizW5dAEAzU2eodv7nMJxrOaFHZx/RUYQ7E3sFdhbWaFzd\nTetjIlLuwNWmFqzNLHWYTFrUajW2f/cVvr10EXOHDkddx3+Wx1mam+M1p1ro3/Z19GzeEl///pvA\npGJxn/V85HJTqIrK1kmpKoJCLje4gRzA9+Rn4euKgFd8Zi4uLg6dOpWeztfb2xsmJqW/br169UTG\neikcHRyQlZ0NlUql+RYmLT0dcrkc1lZWgtOJlZKahshb0ejcob2mzdWlLlQqFXJy82BTzVpgOmnw\ndHPFsa2bkP7oEayqWCLh4UMYGcng6GDYSzJOnj6DtPQMtO8zAEDpTGVJSQna9xmAiye/FJxOt64n\n30aOMg+B53YBAIpLSlCiViPw3C4s6jQeABCdfg8dnJuKjClUSUkJNn5xDGfCruGjYSPQrkEjAEDs\nwwfIVxaiobOL5rHO1R1xIz5OTFAJ4D7r+TjY2iI983GZtozMR7C3qSYokVh8T64YX1cvjz5/V/JK\nD+bc3NwQGhqK7t27IzIyEkX/v4TsVfh2y8OjPkxNTRAaFo5WLZoDAK6GhqGhp4dm0GqoYuLvYdbC\npfjpxBHY2pQeexB1Kxo21apxIAcgKycHM1eswZq5s2BXrfQDwoU/r8DD1RWWFoZ13NN/27XhYxQ9\ncdD4oc9PIPLWbaxYMFdgKjHebfYWStT/XH7gYsJ13M9OxZCG3QEAucp8ZORnaT0xiiHY9cO3OBN2\nDQv8/NHG85+z7J0Pv45Lt6Kw9YMZmrbb9++jjoPhHo/Kfdbzaez+GlIzMpCUkgqn6g4AgOs3b6GR\ne/1nPPPVxPfkivF19fIY6fHY4JVeZunn54eEhAT4+fnh0KFDmm8tXgXmZmbo368vlq8JQviNSJw5\ndwH7Dx7GCF9eGLtFUy+41q2LRSvXIiYuHucv/oHgHXswzt9PdDRJsLK0RGGhEps++Q8SHzzE6d9+\nx57PjmHs0EGiownnVMMRzrWcNDerqpZQKORwrmV4AxYb86qws7DW3MxMFDAxMoGdRekXIsm5GTCW\nGcHOwjBnDKIS4vHlxV/h37Un6teqg4zsbM2tZ4tWSEpPw75TP+B+Wiq++v1XnAsPxbBOXUTHFob7\nrOdTq4Yj2jb1QmDwVtyOi8e3p8/ix/O/YUjfnqKjCcH35IrxdUXAKz4zp1AosGnTJq33Dxw4UPPn\no0ePAgB++eWXSs/1ssyeMRXLV6/FuxOnwLJKFUwYNwa9e/Ci2KYmJghesxyrNmzGqAlTYWFhjuFD\nBsJv8Nuio0nG8lnTsXrbToyYPhvV7Wwxf/L78GndUnQs0iO5ynwoTOR6/W3m/+LXiHAAwCenTuKT\nUyfL3Pft0lVY/s447Dz5Db747Txq2NohwM8frznVFhFVMrjPej6Lpk7Cyq07MW7eQthWq4aPJo1H\nEw/DvmA4acfX1cshcleWnp6OgQMHYu/evSgsLMT7778PFxcXAKUTU3379q3w+TK1Wq3WQc5XjjIr\nXXQESZJb2QEA8pIN9+K4FbFwdMajqOuiY0hStQbeAIC8pFjBSaTJwqkePp+4UXQMSRqybTpiPudF\n78vjOuQtANxnaSO3skPmjauiY0iSTaPSZXt8Ty6fhVM9vq60+PuzoD75ckpwpWx3wOapFd6vUqkw\nffp03LlzB1u3bsXVq1eRnZ2NsWPHPvff8UovsyQiIiIiIqqIqIuGr1mzBr6+vqhevfSY6oiICJw9\nexYjRozA/PnzkZOT88xtcDBHRERERESkQydOnICtrS06duyoafPy8sKcOXNw6NAh1KlTB1u2bHnm\ndjiYIyIiIiIi0qHjx4/j4sWL8Pf3R1RUFObOnQsfHx80btwYANCjRw9ERkY+czuv9AlQiIiIiIiI\nKiLiBCiHDh3S/Nnf3x9LlizBpEmTsHDhQnh5eeH3339Ho0aNnrkdDuaIiIiIiIgEW7JkCZYtWwZT\nU1PY29tj2bJlz3wOB3NERERERGSwnudkJZXpwIEDmj8fOXLkXz2Xx8wRERERERHpIc7MERERERGR\nwRI8Mfc/4WCOiIiIiIgMluhllv8LLrMkIiIiIiLSQxzMERERERER6SEO5oiIiIiIiPQQj5kjIiIi\nIiKDpceHzHEwR0REREREhosnQCEiIiIiIiKd4swcEREREREZLD2emINMrVarRYcgIiIiIiIS4YfZ\nWytlu73XTqqU7T6JM3MvKO3yRdERJMm+VXsAQGFmsuAk0qSwcWRttFDYOAIAlFnpgpNIk9zKDtlx\nt0THkKSqLh6Y6DNNdAxJ2nZ+EwC+rrSRW9khL/me6BiSZOHoDIB9Rxu5lR0K0pJEx5AkM3sn0RH+\nNSM9nprjMXNERERERER6iDNzRERERERksPR4Yo4zc0RERERERPqIgzkiIiIiIiI9xGWWRERERERk\nsHjRcCIiIiIiItIpzswREREREZHB0uOJOQ7miIiIiIjIcMmM9Hc0x2WWREREREREeogzc0RERERE\nZLD0eZklZ+aIiIiIiIj0EAdzREREREREeojLLImIiIiIyGDp83XmOJjTQ0qVCmMXLsW0kX5o1bgR\nACDi9h1sOvgp7iYkorqtLd556w306fi64KTiKZVKDBs9HnOnT0Hb1i1Fx5Ec1udpSqUSK9eux0+n\nz0BuaopRI3wxdtRI0bEko6ioCMF79uO7n38B1EB3n9cxc8J4yOWmoqPpnJGxEd6e0B9te7UCZDJc\nPXMNn28+geGzhqFdnzZPPT4tKQ0LfZcJSCoNfG1pFxt/D6s3hiA8MgrWVlbwHfgW3vEbKjqWJLDf\nVCwh8T4+Dt6Ca2HhMDczQ69uXTDlvXFQKOSio5GOcDCnZwqVKizZuh2xifc1bZlZWZi1dgPe7t4V\nSya/j7Bbt7F69ydwqu4Abw93gWnFKiwsxLxFgbgbEys6iiSxPuVbFxyC6+ER2LVlE5JTUjB/cSBq\n1nBEn549REeThE27PsHZ3y9h3ZIAyCDDgjXrYH34M0wabXgfrgZNegveHZpg2/zdANQYu3AUcrN6\n4WjwCXy54xvN46raVMXMkGn4+ehZYVmlgK+t8qmKivDB7AC0au6NgJnTEHcvAfMDV8HBzg59e3YT\nHU849hvtVCoVps4NgKtLXfxnewgyMjOxeOVaAMCsKZMEp9Mvejwxx2Pm9Ens/ft4b8kyJKWklmlP\nTs9AxxbN8f7QQahVvTr6dHwdrrVrIfRmtKCk4t2NjcPIcRORcD9JdBRJYn3Kl5efj+Nffo05M6ah\nUQNPdO3kgzH+I/Dp0eOio0lCdk4Ojn13EgHTJqNpo4bwbtQA7430w83bd0RH0zlzS3N0fKsDDq79\nDDERsYiJiMO3n/wAZ/c6KMgtQFZGtubW951eiIuMx7kTF0THFoavLe1SU9PQuIEH5s2YAufateDT\nvmg66NUAACAASURBVC3atGiGv66HiY4mHPtNxcIjb+Je4n0sC5gHV5e6aNmsKSaPH4Pvf/pZdDTS\nIQ7m9Eho1C00b9gAOxYHlGn3rOeCgPffBQCUlJTg16uhuPfwIZo38BCQUhquXA1FqxbNcGD3NtFR\nJIn1KV909B0olSo0b+qlaWve1BsRkVEoLi4WmEwaQiOiYKZQoE3zppq2N3t2Q/CKJeJCCeLWxBWq\nQiVuXrmlafvjhz8RMmdHmcfVa+QC7w5NcCzkC11HlBS+trRzqlkDa5YugJlCAbVajdDwCFwNC0fr\n5s1ERxOO/aZiLs51sCVoNSwszDVtMpkM2Tk5AlPpJ5lMVik3XTCIZZY7d+5E27Zt4eXl9ewHS9jb\n3btWeH+hUoke4yehuLgYA7p1QRP3+jpKJj3DBg0QHUHSWJ/ypaanwdrKCgqFQtNmZ2sLlUqFjMxM\nONjbC0wnXuKDB6hZvTp+PHMeez89iryCAnTv+Domj/GHqalhHTPnUMse6Q8z0Or/2Lvz+BjP/f/j\nr5FkEmSRzS5I7HvRVhdrba2231YdtcVBaXXTqq22ClKnWlvRaoWeKmor7VGqC0dRSql9J8Qa2REh\nmUkyvz/8DDkk9BzJPZN5Px+PeTzMPTN33vfHdd8z11zX3HfrRrQPb4NnUU92/rqbf81eRVbmzQ+Z\nT4a3ZdfGPZw/GWtgWuNp37o37V7oSkJiEs0ebULrFk2NjmM4tZu8BfiXoMmDjez3s7OzWbz8Wx5u\n3CiPV0lh4xKduZdfftnoCAXERFTEKGLOxzL5y/lUKFWKLk+1MzqUiNNIT0+/7UQeNzopFovViEgO\nJe3aNc5diGPJylWMeOt10q5d44MZs8jKymLQq/2MjlegvIp5ElQmkBYdm/L1pKV4FfOk6zt/w82t\nCMtmXB+FCyjlT+2Ha/LRa9MMTms87Vv3ZuqEsSQkJjFhynQmzfyMYW+9bnQkQ6nd/DWTpn/K4aPH\nWahZN3+ZM/9mzik6c1arlTFjxnDq1Cmys7N5++23iYyM5KGHHuLIkSOYTCY+/fRTvL29GTt2LPv3\n7ycoKIhz584xa9YsZs6cyVNPPUViYiIbNmwgPT2d06dP069fPzp27MiRI0eIjIwEoESJEkyYMAEf\nHx+Dt/qv8zR7UL1yJapXrkR8UjLLfv5FnTmRv8Bs9rztA4LVev2+l5fnnV7iUtzd3Ei7epXxQ9+h\nfNkyALzVrzdjPpzKwFdeokgR15m5n5WVTVHvovwzcj6J55MAWP7pv+g1qgffzPwOm83GAy0akHAu\ngZhDpwxOazztW/emdo3rP49Iz8jgvQkf8c5rL7vcqPet1G7ujc1m48OPZ7J0xb+Y9H4EVUIrGx1J\nCpBTvPMuW7YMf39/Fi5cyKeffsq4ceNIS0ujQ4cOLFiwgJIlS7Jx40bWrVvHxYsX+eabb5gwYQKx\nsbdPa7ly5Qqff/45s2bNYvbs2QCMHj2aMWPGMH/+fJo1a8acOXMKehP/J2cvxLF9/4EcyyqVK8ul\nVM2ZFvkrSgUHczk11f5hASAxKQmz2Yyfr6+ByRxDUEAAbm5u9o4cQKXy5ciwWEi5dMnAZAXvUuIl\nsjKz7B05gLgz8Zg9zXiX8AagzsM12bVRJ7EA7Vt5iU9I5NfftuRYFlqpIlarlStpVw1K5RjUbu4u\nOzub9yZ8yNJvVzJx3Hu0bPq40ZGkgDlFZ+7o0aNs3LiR8PBwBgwYQGZmJikpKdSqVQuAMmXKkJGR\nwYkTJ2jQ4PoP8wMCAggNDb1tXTVq1LC/xmKxABAdHc3YsWMJDw9n+fLlxMXFFdCW3R87Dx0m4pPP\nsNxysDsSE0PFWz5wicjdVa9eFQ8Pd3bv3WdftnP3XmrVqI67u1NMZMhX9WrVICsri+MnY+zLTpw6\nQ/FiRV3ug9WJAzG4ubtRNvTmcbZMpdJcS0sn7XIaABVrVuTYbtc70+edaN/K3YlTpxk8eizJKSn2\nZYeOHMW/RAn8S/gZmMx4ajd3N3nGLNb8so4pE8bRukUzo+M4L5Mpf24FwCk6c6GhoXTo0IH58+cT\nFRVF+/bt8fPzu+0sMVWrVmX37t0AXLp0iZiYmNvWdaczy1SuXJmJEycyf/58hgwZQosWLfJjM/JN\ni4ca4+bmzqR/fsXp2Av89NsWFv/wE72ee8boaCJOpaiXF892eIrIiZPYd+Ag6zdsYt6Cr+neRRfv\nBQgpV5bmjzzM2MnTOXTsOLv2HWDmF/N4rn1b3N3cjI5XoBLOJrB70156vtuNkGrlqVIvlOdeeYbN\nq34nOyubgNIBFC3uRWzMBaOjOgTtW7lr1KAeoRUr8t6EjzgRc4qNW7Yy/fO59A3vanQ0w6nd5G3v\n/oMsWPoNr77Ui9o1qpOYlGy/ietwiq81unTpwqhRo+jRowdXrlyhW7dud/xtRosWLdi4cSNdunQh\nKCgILy+ve5prHhERwbBhw8jMzMRkMvH+++/nx2bkG9/ixZk2bBBTvlpI71FjCPD1463wbjRt1NDo\naCJOZ8jAAUR+8BEvvfom3sWL079vb9q30YV7bxg3dCCTZkXRf+go3N3c6NCmFW/06Wl0LEN8GbmA\nzgM68va0N8jKymbrj3/YLxbu63/9d9dpl117mtyttG/dmYe7O9MnRvKPqTPo2X8AxYoVpdvfOtK1\n0/NGR3MIaje5++XXDQBM/yyK6Z9F5Xjszw1rcXd3rS/Z/hcFdRmB/GCy2Ww2o0PcL9HR0Rw+fJgO\nHTqQkpLC008/zfr16zGbzff9byVu33L3J7mgoAcfBSAjxbmmqhYUT/9Sqk0uPP1LAWC5nHSXZ7om\ns28gqTFH7v5EF+RTqTqvNnvL6BgOadbGjwHtV7kx+wZyNe600TEcUrFSIYDaTm7MvoGkJ543OoZD\n8goqa3SEv2zz+Ln5st7HRr+UL+u9lVOMzN2rMmXKMGnSJObNm0dWVhaDBw/Ol46ciIiIiIiI0QpV\nZ65YsWLMmqVra4iIiIiIyL0xFXHeaZZOcQIUERERERERyUmdORERERERESdUqKZZioiIiIiI/BVO\nfDJLjcyJiIiIiIg4I43MiYiIiIiIy3Lm68xpZE5ERERERMQJaWRORERERERclhMPzGlkTkRERERE\nxBlpZE5ERERERFyWfjMnIiIiIiIiBUqdORERERERESekaZYiIiIiIuKynHiWpUbmREREREREnJFG\n5kRERERExGU58wlQTDabzWZ0CBERERERESPsmDwvX9bbeNDf82W9t9I0SxERERERESekaZb/Jcvl\nJKMjOCSzbyAAV8+fNDiJYypWtrLaTi5utJ30xPMGJ3FMXkFl1XZyYfYNVG1ycWO/OvrVNwYncUzV\nenZS28nFjbaj+tyZjju5u9F2nIkzT7PUyJyIiIiIiIgTUmdORERERETECWmapYiIiIiIuCwnnmWp\nkTkRERERERFnpJE5ERERERFxWToBioiIiIiIiBQojcyJiIiIiIjLcuKBOY3MiYiIiIiIOCONzImI\niIiIiOty4qE5jcyJiIiIiIg4IXXmREREREREnJCmWYqIiIiIiMsyFdE0SxERERERESlAGplzYhaL\nhQkfTeHndesxe3jQs3sX+vTsYXQshzNu0jROnz3HnGkfGR3FYajt5O7M2XN8OP0Tdu3dR1EvL9o9\n0ZI3X+6Lp6fZ6GgOQW0nd6rNTbEpSUT9vJqDZ0/h5WGmaa26hLdog9ndg6TUy8z6cSW7Tx7Hp2gx\nOj3SjA6Nmxgd2VBqO7lTbfKm+twfRp3/JCsri1GjRnHy5ElMJhNjx47F09OTd999F5PJRNWqVRkz\nZgxFiuQ+/qbOnBObPH0me/btJ+qTj4mLj2fEmHGUKV2KJ9u2MTqaw9j25y6+Xf0jjerXNTqKQ1Hb\nuTOr1cqAYSMJrVSRrz6bSXJKCmMmXP8SYPCbrxmczjGo7eROtbnOmpXJ+KXzqRBUko/+/goX09KY\nvmoFAL2faM/4pfPxLVaMqX1e40RcLNO+X07ZgCAeCK1icHLjqO3kTrXJm+pzf5gM6s2tX78egMWL\nF7Nt2zamTp2KzWbj7bff5uGHH+a9995j3bp1tGmT+/+nplk6qavXrrH8u5UMHfgWtWvWoFXzZvQO\n786ipcuNjuYwrl1LJ3LKdBrUqWV0FIeitpO7fQcPc/rsOcaPfJfQShVp/EADXu/Xmx9+Xmt0NIeg\ntpM71eamo+fPEpuczNvPvECFoJLUrViZ7s1b8+v+PeyMPsb55CSGPPciFYJK0rx2fVrXa8jhc6eN\njm0YtZ3cqTZ5U32cX+vWrRk/fjwA58+fx9fXlwMHDvDQQw8B0KxZM7Zs2ZLnOtSZc1JHjx7HYrHS\nsEE9+7KGDeqz/+AhsrKyDEzmOGbO/ZJG9evS+JYaidpOXiqFVOCTSR9QrFhR+zKTyUTqlSsGpnIc\naju5U21uKh8QzJguPSlq9rQvM5kgLT2dPTEnqFexMj5Fi9kfe/2p5+jatJURUR2C2k7uVJu8qT73\nj8mUP7d74e7uzrBhwxg/fjzPPPMMNpvNPlJYvHhxUlNT83y9OnNOKiEpET9fXzw9b75ZBgYEYLVa\nSU5JMTCZY9hz4CC/bNjEO6/2MzqKw1HbyV2AfwmaPNjIfj87O5vFy7/l4caN8niV61DbyZ1qc5Nf\n8eI0qHxzymS2LZvVO7ZSv3IYF1KSCPYrwfxff6H39A957fOP+Xn3DgPTGk9tJ3eqTd5Un8Jj4sSJ\n/PTTT4wePZqMjAz78rS0NHx9ffN8baH9zVx6ejpDhw4lPj6eMmXKsH37dipXrkxERARhYWEsWrSI\nxMREnn/+eQYNGkTp0qU5c+YMdevWZezYsUbHv6v09HTMZo8cyzw8rt+3WKxGRHIYFouFsR9NY8jr\nr+Dr42N0HIejtnPvJk3/lMNHj7NwziyjozgEtZ3cqTa5m/vLGqIvxDKlz6tE/bya9ft282iN2oz8\nW3eiL5znsx+/x6doMR6p7ppT4tV2cqfa5E31cX7fffcdcXFxvPLKKxQtWhSTyUSdOnXYtm0bDz/8\nMBs3bqRJk7xPEFVoO3NLliyhfPnyTJ8+nejoaJ5++mkqV658x+fGxMQwd+5cihYtSuvWrUlISCA4\nOLiAE/81ZrPnbTuq1Xr9vpeX551e4jJmf/U1IeXK0qZFM6OjOCS1nbuz2Wx8+PFMlq74F5Pej6BK\n6J2PHa5GbSd3qs3tbDYbUb+s5oc/t/Fux65UDC6FW5EiFPfy4vWnnsOtSBGqlCnHybhY1uzc5rKd\nObWd3Kk2eVN97iODToDStm1bhg8fTvfu3cnMzGTEiBGEhYUxevRopkyZQmhoKO3atctzHYW2Mxcd\nHU2zZtc/zIeFhREQEJDjcZvNZv93SEgI3t7eAAQHB+cY3nRUpYKDuZyaitVqtX8Lk5iUhNlsxu8u\nw7GF3Zp160lMSubRJ58DwJqZSXZ2No8++Rxb1nxncDrjqe3kLTs7mzH/+Igffl7LxHHv0bLp40ZH\nchhqO7lTbXLKtmUzfdW3bNi/h6HPd6HJ/++oBXj7kG3Lxu2W02yXCwxmT8wJo6IaTm0nd6pN3lQf\n51esWDE+/vjj25YvWLDgntdRaH8zV61aNXbt2gXA6dOnSUlJwWw2k5CQAMDBgwftzzXqdKT/i+rV\nq+Lh4c7uvfvsy3bu3kutGtVxdy+0ffR7EjX1Q5b983MWz/mUxXM+pWOH9tSqVpXFcz41OppDUNvJ\n2+QZs1jzyzqmTBhHa43u5qC2kzvVJqe5a9ew4cAehnfqxqM1atuX1ygfQkx8HJm3nJzhTGI8Jf1K\nGBHTIajt5E61yZvqc/+Yipjy5VYQCm1nrlOnTpw7d47u3bszY8YMPD096dmzJ2PHjuWll15y+rP8\nFPXy4tkOTxE5cRL7Dhxk/YZNzFvwNd27dDY6muHKli5FSLmy9puvjzeenmZCypU1OppDUNvJ3d79\nB1mw9BtefakXtWtUJzEp2X4TtZ28qDY3HT53mpV/bKFbsyeoWqYcKVdS7bemterhXsSNGau/5VxS\nIuv37Wbtnp10aPSw0bENo7aTO9Umb6qPAJhst843LER27tzJ1atXefzxx4mJiaFv376sXXv/rhVl\nuZx039b137qWnk7kBx/xy79/xbt4cf7evQt/79HN0Exm30AArp4/aWiOW30y90t27TvAnGkfGR2F\nYmUrq+3k4kbbSU88b1iGyTNn8dWipXd87M8Na3F3dyvgRDd5BZVV28mF2TdQtcnFjf3q6FffFNjf\nnLt2Dd9t++2Oj303fByxKcl89uP3HDxzCn9vH158vAVtGzQusHy3qtazk9pOLm60HaPr44i1AR13\n8nKj7TiTg1GL82W9tfp1yZf13qrQduYSEhJ45513sFqtZGZmMmDAAPtv6O4HR9iBHZEjduYciaN0\n5hyRI3TmHJmjdOYckaN8qHJERnTmnImjdOYckaN05hyVjju5U2fupoLozBXaCbXBwcHMnz/f6Bgi\nIiIiIuLInPD8GTcU2t/MiYiIiIiIFGbqzImIiIiIiDihQjvNUkRERERE5G6ceJalRuZERERERESc\nkUbmRERERETEZRXUBb7zgzpzIiIiIiLiskxOPM9S0yxFRERERESckEbmRERERETEdTnvwJxG5kRE\nRERERJyROnMiIiIiIiJOSNMsRURERETEZekEKCIiIiIiIlKgNDInIiIiIiIuSyNzIiIiIiIiUqA0\nMiciIiIiIq7LiYe3TDabzWZ0CBERERERESMc/3pFvqy3SreO+bLeW2lk7r9kuZxkdASHZPYNBCA1\n5ojBSRyTT6Xqaju5uNF2VJ87M/sG5tubjbOr0q0jl6MPGR3DIfmG1QS0X+XG7BvIxOcijI7hkIZ9\nFwGo7eTG7Buo2uTixvu5FAwnHlQUERERERFxXerMiYiIiIiIOCFNsxQREREREZelSxOIiIiIiIhI\ngdLInIiIiIiIuC7nHZhTZ05ERERERFyXqYjz9uY0zVJERERERMQJaWRORERERERcl06AIiIiIiIi\nIgVJnTkREREREREnpGmWIiIiIiLispx4lqVG5kRERERERJyRRuZERERERMRlmZx4aE6dOSdmsViY\n8NEUfl63HrOHBz27d6FPzx5Gx3IImZmZTJ87j9Vr/w02aN3sMQb174fZ7GF0NIegtpM71San2OQk\nZv+0igOnY/DyMNOsdj16PtEWs7sHM77/lh93/pHj+f3adeC5Jo8blNY43/+yjnFTZ9z5sS+jKF0y\nuIATOR7tWzfVbFqHZwd1yrHs6LbDfPuPxQSFlKTNy09ROqwsqcmX2bJkAwc37jMoqfHUbvKm+og6\nc05s8vSZ7Nm3n6hPPiYuPp4RY8ZRpnQpnmzbxuhohvs46p/8+vs2JkeMxISJURMn4/f1El7rpQMc\nqO3kRbW5yZqVydhFXxESXJJJfV7lUtoVpq1cDkDfdh04nRBHnzZP0rLeA/bXFPP0NCquodo0e5xH\nGjW037fZbAyMiKRc6VLqyP1/2rduCqpQkiO/H+KXz1fbl2VaM3Fzd+OFkV05vv0oa2b+iwq1K/HU\ngOdIiU0m9tg5AxMbR+0mb6rPfaKLhktBu3rtGsu/W8nQgW9Ru2YNWjVvRu/w7ixautzoaIZLvXKF\nb1avYeRbr9Ogdi3q167Jyz26cvjYcaOjOQS1ndypNjkdPXeW2OQkBj7XiZDgktStFEp4yzas37cb\ngDOJ8VQtW54Abx/7zcvDbHBqY3h5ehIU4G+/rd/yO3EJiYwc8LrR0RyC9q2cAisEk3AqjrSLV+y3\njLR0AisEU6KUP78tWs/FCynsW7eLhFNxhNSpZHRkQ6jd5E31uX9MJlO+3AqCOnNO6ujR41gsVho2\nqGdf1rBBffYfPERWVpaByYy3e/8hvDw9ebhhA/uyZ9o+wfT3I4wL5UDUdnKn2uRUPjCIiO69KGrO\nOdqWlp5O8pVUUq9do3xgkEHpHFfa1WtELVzCK+Fd8fXxNjqOQ9C+lVNQhWCSzyXetjz9yjUA6rV+\nAEwmylYvT0C5IOJOxBZ0RIegdpM31UfAgaZZrlixghMnTjB48GCjoziFhKRE/Hx98bxlSlNgQABW\nq5XklBSCg1z3A9bZ2FjKlCzJT+s38sWipVxNT6d108d4vXc4Hh76zZzaTu5Um5z8invzQGgV+/1s\nWzartm+lQWgYZxLicStShPnrf+HP40fxLVaM/2vyOG0aNDIwsWNYseYnzB4ePNdO05xu0L51UxF3\nN0qU9iescTWadmsFJjiy+SC/LVrP5YRLbJi/luY9WtOiZxuKuBVh85INxOw5YXRsQ6jd5E31EXCg\nzpz8Nenp6bedzONGR8VisRoRyWGkXbvGuQtxLFm5ihFvvU7atWt8MGMWWVlZDHq1n9HxDKe2kzvV\nJm9zflrNidjzTO33Ovtirn+4rFyqDM8+/Cj7Yk4wc9W3eHmYaVq7rsFJjWOz2fh2zU90frYD7u56\ni71B+9ZNAWUCcHN3w5ph5duJS/AvHcATfdtjLmpm7Zwf8S8TyN61O9mzdielQ8vQsk874k9e4OjW\nQ0ZHL3BqN3lTfQQcrDO3Z88e+vTpQ3JyMl27dsXPz4+FCxeSmZmJyWRi5syZHDt2jNmzZ+Ph4cGF\nCxfo0qULW7du5fDhw/Ts2ZNu3brxzDPP0LhxY44cOUJoaCiBgYHs2LEDs9nM7NmzSU9PZ+TIkaSk\npAAwatQoqlevTsuWLQkNDSUsLIwRI0YYXI28mc2et+2oVuv1+15ernkCghvc3dxIu3qV8UPfoXzZ\nMgC81a83Yz6cysBXXqJIEdeeXay2kzvV5s5sNhuzf1zF6h1bGf637lQsWYqQ4JI0r1sfn6LFgOud\nunNJSfywY6tLd+YOH4/mbOwFnmrVwugoDkX71k2JZxL4OHwi6anXp1QmxMSBCZ59pxPxJy9QrmYF\n5rzxCdhsxEXH4hPoy+NdW7pkZ07tJm+qz33kvOc/cazfzLm7uzN37lxmzpzJvHnziImJYfbs2Sxa\ntIgqVarw22+/AXDhwgVmzJhBREQEs2bN4sMPPyQqKoolS5YAkJaWxtNPP83XX3/Njh07aNiwIQsX\nLsRqtXL8+HE+++wzmjRpwvz58xk/fjwREREAxMbGMmnSJIfvyAGUCg7mcmqqfacFSExKwmw24+fr\na2Ay4wUFBODm5mbvyAFUKl+ODIuFlEuXDEzmGNR2cqfa3C7bls20lcv5Ycc2hnXqyiM1agHXfyx+\noyN3Q4XgYJJSLxsR02Fs2bGTOtWrERwYYHQUh6J9K6cbHbkbks4k4ubhRrkaFUg8FQ82m/2xC9Gx\nlCjtX9ARHYLaTd5UHwEH68zVqlULk8lEcHAw6enpBAYGMmzYMIYPH86RI0fIzMwEoGrVqnh4eODj\n40NISMj1RuvnR0ZGhn1dtWvXBsDX15ewsDD7vzMyMjh69CjLly8nPDyc0aNHc+n/f8D39/fH3985\nDpjVq1fFw8Od3XtvXntm5+691KpR3eWn9tSrVYOsrCyOn4yxLztx6gzFixXVwQ21nbyoNreb89MP\n/LpvNyNf7M5jNevcsnw1EV9/meO5J2JjKR/k2qfh33/4KA/UrW10DIejfeumak1q8saXgyni7mZf\nViq0NOlXrnExLoXA8jl/5xRYPoiLF5ILOqZDULvJm+pz/+hslvfJrRudmprK9OnTmTp1KpGRkXh6\nemL7/99U3Utx8npOaGgovXr1Yv78+UybNo1nn30WwKmm3xX18uLZDk8ROXES+w4cZP2GTcxb8DXd\nu3Q2OprhQsqVpfkjDzN28nQOHTvOrn0HmPnFPJ5r3xZ3N7e7r6CQU9vJnWqT0+Gzp/nXts10b9Ga\nKmXLk3wl1X57qHpN/jx+lJXbNhObnMT3f2xh3d6dvPBoM6NjGyr61CnCQioYHcPhaN+66fSBGMBE\n+9eewb9sIKGNqtKiV1u2fbeF/b/uxTe4BK36tKNEaX+qNalJkxceZ/vKrUbHNoTaTd5Un/vHVMSU\nL7eC4LDddm9vb+rVq8eLL76Iu7s7vr6+xMfHU758+f953f3792fkyJEsXbqUK1eu8MYbb9yHxAVv\nyMABRH7wES+9+ibexYvTv29v2rd5wuhYDmHc0IFMmhVF/6GjcHdzo0ObVrzRp6fRsRyG2k7uVJub\nfju4H4B5635i3rqfcjy2cnQkQ1/owqIN/+aLX36ktH8AQ1/oQu2QSgYkdRzJFy/h6+NjdAyHpH3r\nuvTUaywdO59WfdrRa/IrZFxNZ/ePO9j6zSYAFr83j5a929Jran/Skq+wYcE69q3bZXBq46jd5E31\nEZPNdsvEbLlnlstJRkdwSGbfQABSY44YnMQx+VSqrraTixttR/W5M7NvIMe/XmF0DIdUpVtHLke7\n3skh7oVvWE1A+1VuzL6BTHwuwugYDmnYdxGA2k5uzL6Bqk0ubryfO5Mzq9fky3ordHgyX9Z7K+eZ\nVygiIiIiIiJ2DjvNUkREREREJL8V1MlK8oNG5kRERERERJyQOnMiIiIiIiJOSNMsRURERETEdTnv\nLEuNzImIiIiIiDgjjcyJiIiIiIjLKqgLfOcHdeZERERERMR16WyWIiIiIiIiUpA0MiciIiIiIi5L\n15kTERERERGRAqXOnIiIiIiIiBNSZ05ERERERMQJ6TdzIiIiIiLiunRpAhEREREREeejE6CIiIiI\niIhIgTLZbDab0SFERERERESMELt+Xb6st0zLJ/JlvbfSyJyIiIiIiIgT0m/m/kvJe7YbHcEhBdR/\nEID0xPMGJ3FMXkFl8+3bH2d349urlAM7DU7imPxrNyQjJc7oGA7J078UV8+fNDqGQypWtjIAlstJ\nBidxTGbfQNUmF2bfQAB2fDTP4CSOqfGQv+u4k4sbxx1not/MiYiIiIiISIFSZ05ERERERMQJaZql\niIiIiIi4Lie+zpxG5kRERERERJyQOnMiIiIiIuKyTCZTvtzuxZ49ewgPDwfg4MGDNG3alPDwBlyG\n1gAAIABJREFUcMLDw/nhhx/u+npNsxQREREREddl0Nkso6KiWLlyJUWLFgXgwIED9O7dmz59+tzz\nOjQyJyIiIiIiUsBCQkKYMWOG/f7+/fv59ddf6d69OyNGjODKlSt3XYc6cyIiIiIi4rKMmmbZrl07\n3N1vTpSsV68eQ4cOZeHChVSoUIFPPvnkrutQZ05ERERERMRgbdq0oU6dOvZ/Hzx48K6vUWdORERE\nRETEYC+99BJ79+4F4Pfff6d27dp3fY1OgCIiIiIiImKwiIgIxo8fj4eHB0FBQYwfP/6ur1FnTkRE\nREREXJeBFw0vX748S5cuBaB27dosXrz4L71enTkREREREXFZ93pNOEek38w5IYvVSvdB7/LH3v23\nPXbxcipPvvQqsfEJBiRzHGfOnuPNoSN4vP0ztHnub0ya8SkZGRajYxnOYrXSa9x4dhw6DMA/v19F\ni/6v3XZr+errBicteBarlW5vDeGPPfvsyy6lXmHER9No1b0Pz73yJqvXbzAwoWOxWCw83+3vbP1j\nh9FRHNK4SdPo+/YQo2M4FIvFQsT7H/Boq3a0aPc0X3y1wOhIDkO1yen8xUQm/PA1fb78iAGLZ7Jq\n79bbnpOZlcWw5bNZ/udGAxI6Hh1zXJdG5pxMhsXCmOmfcuLM2dseu3TlCkMmTuZiaqoByRyH1Wpl\nwLCRhFaqyFefzSQ5JYUxEz4CYPCbrxmczjgZViuRc78g5nysfdmLbVrzbLOm9vsWq5UBk6fQslEj\nIyIaJsNi4b2pM2/br8bPmMW19HRmT4jg0PFoJn42lwplylCvRjWDkjqGjIwM3n1vHNEnThodxSFt\n+3MX367+kUb16xodxaFMnj6TPfv2E/XJx8TFxzNizDjKlC7Fk23bGB3NcKrNTZnZWXz44xJqla1I\nn8fac/5SEp+s/xf+xbx5rEod+/O+2/0bZ1MSeaiScVkdhY4594FG5qQgnDx7jn4jIzgXF3/bY7sO\nHqb3sNGkWzT6tO/gYU6fPcf4ke8SWqkijR9owOv9evPDz2uNjmaYmPOxvDbxI84nJOZYXszLi0A/\nP/vt2183UMzTi5eff86gpAXv5Jmz9H33Pc5diMux/OyFOH7bsZN3X+1HlYohPPNES9o1e5zlP/5s\nUFLHEH0yhh59X+XMufNGR3FI166lEzllOg3q1DI6ikO5eu0ay79bydCBb1G7Zg1aNW9G7/DuLFq6\n3OhohlNtckpJSyU0uCy9Hm1Hab8AGoZUpU7ZShyKPW1/zumkeNYf2UNZv0ADkzoGHXOkUHbmDh06\nxMyZM42Ocd/tOniIhrVrERU55rbHtu7ew/+1bknkwDcMSOZYKoVU4JNJH1CsWFH7MpPJROqVKwam\nMtaeY8d4oFo1PhmW+xSM2MQkvv11A691egF3N7cCTGesnQcO0ahOLeZ8MC7H8gNHjxPkX4IKZUrb\nl9WvWZ39R44VdESHsmPnbh5s9ADz58wyOopDmjn3SxrVr0vjBvWMjuJQjh49jsVipeEtdWnYoD77\nDx4iKyvLwGTGU21yCvYpwYAnnsfs7oHNZuPIhTMcvnCG2mUrAZCdnc3sTavo8mBLvL2K5r0yF6Bj\nzv1hKmLKl1tBKJTTLGvWrEnNmjWNjnHfdWzbOtfHXu32IgBnLlwoqDgOK8C/BE0evDlNMDs7m8XL\nv+Xhxq41dfBW/9e82V2fs+SXtVQpX56H69z9miaFyQvt7zyNKTElhaAA/xzLAkr4EZ+UXBCxHNaL\nL7jOqO1ftefAQX7ZsIlvvviM+S46qpKbhKRE/Hx98fT0tC8LDAjAarWSnJJCcFCQgemMpdrk7s1F\nM0i5eoUHKlTh4co1AFi9bxs+XsVoWrUu/z68y+CExtIxR6CQdOZOnjzJ8OHDcXd3Jzs7m86dO7Nh\nwwamTp1Ky5YtCQ0NJSwsjN69ezN69GgyMjLw9PRk/PjxZGVlMWjQIEqXLs2ZM2eoW7cuY8eONXqT\n5D6aNP1TDh89zkKNJOTqWkYGv2zbxqAe3YyO4jAyMix4uHvkWGb2cMeamYnNZnPqM1/J/WexWBj7\n0TSGvP4Kvj4+RsdxOOnp6ZjNOfcnD4/r9y0WqxGRHIZqk7t32vyNlKup/HPzj8zfupa2tRuxau9W\nIp/rbXQ0w+mYIzcUis7cli1bqFevHkOGDGHHjh1ER0fbH4uNjWXFihX4+/vz9ttvEx4eTvPmzfn9\n99+ZNGkSAwcOJCYmhrlz51K0aFFat25NQkICwcHBBm6R3A82m40PP57J0hX/YtL7EVQJrWx0JIf1\nx4GD2IDH69c3OorDMJs9sGbm/CBlsWbiaTarIye3mf3V14SUK0ubFncfBXdFZrPnbR0Tq/X6fS8v\nzzu9xGWoNrkLDS4DlMGSaeWzDas4kRjLcw0eI9inhNHRDKdjzn3mxO/rhaIz16lTJ6Kioujbty8+\nPj489thj9sf8/f3x978+Vero0aN8/vnnzJkzB5vNhrv79c0PCQnB29sbgODgYDIyMgp+I+S+ys7O\nZsw/PuKHn9cycdx7tGz6uNGRHNq2AwdoUqcOZg+Puz/ZRQQHBJCUcinHsuSUiwT560OE3G7NuvUk\nJiXz6JPXp6FaMzPJzs7m0SefY8ua7wxOZ7xSwcFcTk3FarXaR50Sk5Iwm834+foanM5Yqk1OyWmp\nnEyMpVHFm2cNLlcimMzsLI7Hn+NMcjzL/rx+mRhLVibRCec5nnCeYe27GBXZEDrmyA2FojO3bt06\nGjVqxBtvvMGqVauYMmUK9f//CEORIjfP8RIaGkqfPn1o2LAh0dHRbN++HXDuCwXKnU2eMYs1v6xj\nyoRxNH/sEaPjOLyDJ0/yfIvmRsdwKHWqVSEhOZnz8QmULXl9pH7P4SPUrlbV4GTiiKKmfkjmLSer\nWLhsBQePHOP9UcMMTOU4qlevioeHO7v37uPBRg0B2Ll7L7VqVLd/seqqVJuczl9MZNra5czsNgC/\nosUBOJkUS3FPL8Y92yvHc2eu/46qJcvzTH3Xe5/XMef+cua+QKE4StSpU4dhw4Yxa9YssrOzCQ8P\nZ+/evbc9b9iwYURERJCRkUF6ejojR440IK3kt737D7Jg6TcM6N+P2jWqk3jLCSuCAgMMTOaYMrOy\nOHMhjsplyhodxaGUK12KJg3qMW76pwzq24sj0Sf5aeNmPhk3yuho4oDKli6V476vjzeenmZCymm/\nAijq5cWzHZ4icuIkIseMIjExiXkLvmbMyHeNjmY41SanGmVCKFciiM83rKL7w08Ql5rC4j/W0/GB\nxyntl/M93MPNHW9PLwKKu95vxnTMuc/UmTNWSEgIixYtuuNjmzdvtv+7QoUKzJ0797bnLF269I7/\nFuf0y6/Xp19M/yyK6Z9F5Xjszw1rcXd3ndPu34vLaWlkZWfjU7yY0VEcznsDXmPCp7Pp++5oAkqU\nYPhr/ahb3bUvGC7y3xoycACRH3zES6++iXfx4vTv25v2bZ4wOpZDUG1uci/ixpB2L/Lllp94b+WX\nFPUw077OQ7Sr/aDR0UQckslms9mMDuGMkvdsNzqCQwqof/1gm56oCwrfiVdQWWLXrzM6hkMq0/L6\nB5eUAzsNTuKY/Gs3JCMl7u5PdEGe/qW4ev6k0TEcUrGy10/8ZLmcZHASx2T2DVRtcmH2vX5B7h0f\nzTM4iWNqPOTvOu7k4sZxx5kk7/4jX9Yb0OChfFnvrQrlRcNFREREREQKO3XmREREREREnJA6cyIi\nIiIiIk6oUJwARURERERE5L+is1mKiIiIiIg4ISfuzGmapYiIiIiIiBPSyJyIiIiIiLgsk0bmRERE\nREREpCBpZE5ERERERFxXEY3MiYiIiIiISAFSZ05ERERERMQJaZqliIiIiIi4LJPJece3nDe5iIiI\niIiIC9PInIiIiIiIuC4nvjSBOnMiIiIiIuKydJ05ERERERERKVAmm81mMzqEiIiIiIiIES4d3Zcv\n6/WrVjdf1nsrTbP8L2WkxBkdwSF5+pcCwHI5yeAkjsnsG8i5n34yOoZDKteuHaC2kxuzbyBpZ6ON\njuGQipcPU7vJhdk3ENB+lRuzb6Bqk4sbbedy9CGDkzgm37Ca9HvsDaNjOKSozTONjuBSNM1SRERE\nRETECakzJyIiIiIi4oQ0zVJERERERFyWM5/NUp05ERERERFxXU7cmdM0SxERERERESekkTkRERER\nEXFdJucd33Le5CIiIiIiIi5MI3MiIiIiIuKyTEX0mzkREREREREpQOrMiYiIiIiIOCFNsxQRERER\nEdelSxOIiIiIiIhIQdLInIiIiIiIuCyTE4/MqTNXCFgsFl7s1Y9hb79Jk4caGx3HIVgsFiZ8NIWf\n163H7OFBz+5d6NOzh9GxDGexWuk/aRKvd+xIo+rVAbiQlMS0pUvZf+IEAX5+9GzXjtYPPmhwUuOo\n7eTtx3//yoj3P8yxrMWjTZgy/j2DEjkOtZ28qT65U23u7Ptf1jFu6ow7P/ZlFKVLBhdwIuO5uRXh\nhdeeo0n7hzCZTOz4906WfLycTGsmZSuXodugzlSsHsLFxIus+ucatv28w+jIzsGJrzOnzpyTy8jI\n4N33xhF94qTRURzK5Okz2bNvP1GffExcfDwjxoyjTOlSPNm2jdHRDGOxWomcN4+Y2NgcywZ/8gll\ng4KYPnAg5xMT+XDhQrw8PXm8Xj0D0xpHbSdv0TGnaPn4owx/6zX7Mk+z2cBEjkNtJ2+qT+5Umztr\n0+xxHmnU0H7fZrMxMCKScqVLuWRHDqDTG8/ToGk9Pnl3Nths9I3oRdqlNFZ9+SNvfvgKezbvZ94/\nFlKtQRV6jQwn/mwCJw+eMjq25CPn7YYK0Sdj6NH3Vc6cO290FIdy9do1ln+3kqED36J2zRq0at6M\n3uHdWbR0udHRDBMTG8vrU6ZwPjExx/KtBw6QfPkyo/7+d0LLluXxevXo0ro1i9euNSipsdR27u7E\nqTNUDa1EUECA/ebj7W10LMOp7eRN9cmdapM7L09PggL87bf1W34nLiGRkQNeNzqaIYp6F6X5c4/z\n1cRFRO87QfT+k3z/xQ+EVK9AmUqlCSobxL/mrCbhXCKbV2/l3PFzVH+gqtGxnYKpiClfbgVBnTkn\ntmPnbh5s9ADz58wyOopDOXr0OBaLlYYNbo4sNWxQn/0HD5GVlWVgMuPsOX6cBlWrMvOdd3IsP5+U\nRPmSJfEtXty+LKxcOY6cPk2mC9ZKbefuTp46TaUK5Y2O4XDUdvKm+uROtbk3aVevEbVwCa+Ed8XX\nxzW/QKpaLwxLupVD2w/bl235YRvTB88i7XIaAI8//Qgmk4nQ2pUpXbEUp46eNSquFBCXnmZ56NAh\n1q1bxxtvvGF0lP/Kiy88Z3QEh5SQlIifry+enp72ZYEBAVitVpJTUggOCjIwnTH+r2nTOy4P8PEh\n+fJlsrKzcSty/buduORksrKzSbt2DT8XG3FR28mb1Wrl7PlYNm39g0//OR9sNlo3b0r/v/fAbPYw\nOp6h1HbypvrkTrW5NyvW/ITZw4Pn2rnu1NPgckEkxyXzUJvGdPh7OzyLerLj37v49vOVJMelsOKz\nlXTs/ywvvPp/uLm78f0/1+To+Enh5NKduZo1a1KzZk2jY8h9lp6eftsHSw+P6/ctFqsRkRzWQzVr\nMuObb5j7/ff0euopLiQn88369QBYXfAbYbWdvJ0+d57MrCy8vLyYFDGSM+djmfTJ56Rdvcrwt1xz\n2tMNajt5U31yp9rcnc1m49s1P9H52Q64u7vuR1evYp4ElgmkVafmzP9wEV7FvOg++EXc3IuwbOa3\nlCwfzG+rfmfT91uoWK0CnQd05Myxs+zasMfo6JKPnHKPWLFiBevXryc9PZ2EhAR69uzJunXrOHbs\nGEOHDmXMmDFs3rwZgIEDB9KlSxdKlizJ8OHDcXd3Jzs7m8mTJ3P69GkWL17M1KlTWbZsGYsWLSI7\nO5tWrVoxYMAAg7dS/ltms+dtb4BW6/X7Xl6ed3qJyyrh48OYPn2YuGABS//9b/x9fOjSujWfrFhB\ncS8vo+MVOLWdvIVVqsi/VyymhJ8vANXCQsFmY/j7HzLkjf64u7kZnNA4ajt5U31yp9rc3eHj0ZyN\nvcBTrVoYHcVQWVnZFPMuytxx80g4d/038MtmfstL7/XkXPR5qtQL5b1ukdhsNk4fOYN/yRL8X98O\n6szdC12aoOClpaXxxRdfsHr1ar788kuWLl3Ktm3b+Oqrr+74/C1btlCvXj2GDBnCjh07SE1NtT+W\nlJREVFQUK1euxNPTk8mTJ5OWlkbxW35HJM6jVHAwl1NTsVqt9m83E5OSMJvN+Pn6GpzO8TSuUYOl\n48eTfPkyJXx82H7oEH7Fi1PU0/U+RKjt3N2NjtwNlUNCyMzMJOXiJYIDAwxKZTy1nbypPrlTbe5u\ny46d1KlezaWPMQCXEi+RmZll78gBxJ2Ox+xppmKNEM5Fn8dms9kfO3XkDG27tTYiqtNx5uvMOe0J\nUG5Mj/Tx8SEsLAyTyYSfnx8ZGRk5nnejUXfq1AlfX1/69u3LwoULcbvlG+QzZ85QtWpVvLy8MJlM\nDB48WB05J1a9elU8PNzZvXeffdnO3XupVaO6S0/PuJPTcXG8M3062dnZBPr54VakCL/v30/9qq55\n9iu1nbyt27SZ1i90s48awPVvzH28vQkK8DcwmfHUdvKm+uROtbm7/YeP8kDd2kbHMFz0/pO4u7tR\nLrSsfVmZyqW5lnaNiwkXKVOpdI7nl6lYKkfHTwonp+3M5dWDzszMJC0tDYvFwvHjxwFYt24djRo1\nYt68ebRv3545c+bYnx8SEsKJEyewWCwADBgwgLi4uPzdAMk3Rb28eLbDU0ROnMS+AwdZv2ET8xZ8\nTfcunY2O5nBKBwRwJj6euatWEZuUxL82beKnP/6gW2vX/CZPbSdvjerVxYaNyCkzOHXmLJu2/sG0\n2XPp2fkFp/5W835Q28mb6pM71ebuok+dIiykgtExDBd/NoFdG/fQa2QPQqpXoGr9MF7o/yybVm5h\n60/bCSgVQOcBHQkuF8QDzevTvkdb1i75t9GxnYOpSP7cCkCh/MqnZ8+evPjii5QvX56yZa9/e1Gn\nTh2GDRvGrFmzyM7OZvjw4Vy5cgWAgIAA+vXrR48ePTCZTLRs2ZJSpUoZuQnyPxoycACRH3zES6++\niXfx4vTv25v2bZ4wOpbDMXt4MK5fP6YvW8Z3mzZRPjiY8X37Ui0kxOhohlHbyV0JP18++SCSKbOi\n6NZ/AN7Fi9Pp6afo000fOkFt525Un9ypNnlLvngJXx8fo2M4hLnjv6LLW50YNH0A2VnZ/L5mGys+\nW0lWZhZT3prO3954nve+fJdLiZf59vOVbF691ejIks9Mtlsn18o9y0jRyN2dePpf7wRbLicZnMQx\nmX0DOffTT0bHcEjl2rUD1HZyY/YNJO1stNExHFLx8mFqN7kw+wYC2q9yY/YNVG1ycaPtXI4+ZHAS\nx+QbVpN+jznnpa3yW9TmmUZH+Muuxp3Ol/UWK5X/X4477TRLERERERERV6bOnIiIiIiIiBMqlL+Z\nExERERERuRfOfBIvjcyJiIiIiIg4IY3MiYiIiIiI6yqgywjkB3XmRERERETEZWmapYiIiIiIiBQo\njcyJiIiIiIjrcuJpls6bXERERERExIWpMyciIiIiIuKE1JkTERERERFxQvrNnIiIiIiIuCxTEec9\nm6U6cyIiIiIi4rp0aQIREREREREpSBqZExERERERl2Uy6NIE2dnZREREcOTIEcxmM5GRkVSsWPEv\nrUMjcyIiIiIiIgVs7dq1WCwWlixZwqBBg/jggw/+8jpMNpvNlg/ZREREREREHJ7lclK+rNfsG5jn\n4//4xz+oV68eHTp0AKBp06Zs2rTpL/0NTbMUERERERGXdbdOV365cuUK3t7e9vtubm5kZmbi7n7v\nXTRNsxQRERERESlg3t7epKWl2e9nZ2f/pY4cqDMnIiIiIiJS4Bo2bMjGjRsB2L17N9WqVfvL69Bv\n5kRERERERArYjbNZHj16FJvNxoQJEwgLC/tL61BnTkRERERExAlpmqWIiIiIiIgTUmdORERERETE\nCakzl8/ef/99zp8/X2B/r3Pnzpw9e5YVK1awbt06ABYsWADAxo0bWbJkSYFlyW8rVqxg0qRJRsdw\nGLnVY+DAgVgsFt599137j2xvyMjIoFWrVgUV0WGpDnm7U31uHE/Onj1L586dAWjVqhUZGRlGRHRI\ns2fPZu/evUbHkAKi96T749ChQ8ycOdPoGIWG6ln46Tpz+WzkyJGG/N2OHTva/z1r1ix69OhBs2bN\nDMkixpo6darREaQQunE8OXv2rMFJHNfLL79sdAQRp1OzZk1q1qxpdIxCQ/Us/NSZu0+uXLnCyJEj\nSU1NJT4+nm7dutGtWzfCw8OJiIjghx9+YNeuXVy9epX333/ffqaa9PR0hg8fzvnz57FarYwePZo6\ndeowfPhwzp49S1ZWFr179+app54iPDycGjVqcOzYMa5cucLHH39MuXLlmDp1Kps2baJ06dKkpKQA\nMGPGDIKCgrh48SKXLl0iIiKCevXqceLECQYPHswXX3zB6tWrcXd3p3HjxgwZMoQZM2Zw9uxZkpKS\nOH/+PMOHD6dp06b88ccfTJ06FTc3NypUqMC4ceP4/vvvWb58OdnZ2QwYMIBHHnnEkLrv2bOHPn36\nkJycTNeuXSlfvjzTpk3D09OTEiVKMGHCBA4dOsSkSZPw8PCgc+fOzJ07l4ceeogjR45gMpn49NNP\n8fHxMST//+I/2067du1uq8eLL75Iq1atWLNmjf11aWlpDB48mMuXLxMSEmJfHh4eTkBAAJcuXWL2\n7NlERERw6tQpsrOzefvtt3n44Yd55plnCkXt4M51OHjwIOPHj8fNzQ1PT0/Gjx9P2bJl+eSTT1i7\ndi0BAQFcu3aNt956i4cfftjgLchfd6rPrW2kQ4cOnDp1ii5duhicNP9YrVbGjBmTYz+IjIy8bR/w\n9vZm7Nix7N+/n6CgIM6dO8esWbOYOXMmTz31FImJiWzYsIH09HROnz5Nv3796NixI0eOHCEyMhLA\nfrxy1v3pVunp6QwdOpT4+HjKlCnD9u3bqVy5MhEREYSFhbFo0SISExN5/vnnGTRoEKVLl+bMmTPU\nrVuXsWPHGh3/f/Kfx2A/Pz8WLlxIZmYmJpOJmTNncuzYMWbPno2HhwcXLlygS5cubN26lcOHD9Oz\nZ0+6devGM888Q+PGjTly5AihoaEEBgayY8cOzGYzs2fPJj09nZEjR9rf80eNGkX16tVp2bIloaGh\nhIWFMWLECIOrcW9OnjzJ8OHDcXd3Jzs7m86dO7NhwwamTp2aY3t69+7N6NGjycjIsB+fs7KyCl0b\numHFihWsX7+e9PR0EhIS6NmzJ+vWrePYsWMMHTqUMWPGsHnzZuD6DJwuXbpQsmTJHLWcPHkyp0+f\nZvHixUydOpVly5axaNEisrOzadWqFQMGDDB4K+V+UGfuPjl16hQdOnSgbdu2xMXFER4eTrdu3XI8\nJzQ0lFGjRuVYtnjxYnuHLCYmhl9//ZUDBw4QEBDApEmTuHLlCh07dqRJkyYA1KtXj5EjRzJ16lRW\nr17NI488wvbt2/nmm2+4evUqbdu2zbH+V199lQULFhAREcGKFSsAOHLkCGvWrGHx4sW4u7vz5ptv\nsn79egDMZjNz5sxh8+bNfPHFFzz++OOMHj2ar7/+msDAQKZNm8a3336Lu7s7vr6+zJo1K79Kek/c\n3d2ZO3cu586do1+/fmRkZLBo0SJKlSrFvHnzmDVrFi1atCAjI4Nly5YBMH36dDp06MDo0aMZNGgQ\nGzdupEOHDoZux3/jTm3n1nq8/PLLvPjii3d8XbVq1Rg4cCB79uxh27Zt9seefvpp2rRpw9dff42/\nvz8TJkwgJSWFHj16sHr1atLS0gpF7eDOdRg1ahTvv/8+NWvWZO3atXzwwQe89tprbNq0iW+++Qar\n1cozzzxjdPQCkVs7udFGbhxPCrNly5bdth9cu3bttn3A09OTixcv8s0335CcnHzbcRiuf+E3d+5c\nYmJi6N+/Px07dmT06NFMmDCBKlWqsGzZMubMmcPAgQMN2NL7a8mSJZQvX57p06cTHR3N008/TeXK\nle/43JiYGObOnUvRokVp3bo1CQkJBAcHF3Di++c/j8HPPvsss2fPpmjRorz33nv89ttvlCpVigsX\nLvDdd99x4MAB3nrrLX755Rfi4uJ444036NatG2lpaTz99NOMGTOG9u3bM3z4cAYOHEiPHj04fvw4\nq1atokmTJnTr1o2YmBiGDx/OokWLiI2NZcWKFfj7+xtdinu2ZcsW6tWrx5AhQ9ixYwfR0dH2x27d\nnrfffpvw8HCaN2/O77//zqRJkxg4cGCha0O3SktLs3/5/uWXX7J06VK2bdvGV199dcfn/2ctU1NT\n7Y8lJSURFRXFypUr8fT0ZPLkyaSlpVG8ePGC2hzJJ+rM3SdBQUHMmzePn3/+GW9vbzIzM297zp3e\nzE6cOGGfrlSpUiV69erF2LFjefTRR4HrV4YPCwvjzJkzANSqVQuA0qVLk5iYSExMDHXq1KFIkSJ4\ne3vf08UGT5w4Qf369fHw8ACgcePGHDt2DMA+FF+6dGksFgvJycnEx8fz9ttvA9e/cX300UepWLFi\nrm/OBalWrVqYTCaCg4OJjY0lJCSEUqVKAfDggw8yZcoUWrRocVvWG3UsU6aM0/7G5z/bjq+vb456\npKen3/F1MTExNG/eHID69evj7n7zMHCjTkePHuXPP/+0/94nMzOT5ORkoHDUDu5ch/j4ePs+8OCD\nDzJ58mSio6OpW7cubm5uuLm5UadOHSNjF5jc2okj7PcF5U77QUpKym37wLlz52jQoAEAAQEBhIaG\n3rauGjVq2F9jsVgAiI6Oto8iWK1WKlWqlN+bVCCio6Ptx6awsDACAgJyPH7rFZFCQkLB2sVZAAAF\nb0lEQVTw9vYGIDg42KmPKcBtx+DAwECGDRtG8eLFOXHihL2dVK1aFQ8PD3x8fAgJCcFsNuPn55dj\n+2vXrg2Ar6+vfTaPr68vGRkZHD16lK1bt9pnXVy6dAkAf39/p+rIAXTq1ImoqCj69u2Lj48Pjz32\nmP2xW7fn6NGjfP7558yZMwebzWY/JhW2NnSrG+9HPj4+hIWFYTKZbmsncHOf+s9a3vrl0JkzZ6ha\ntSpeXl4ADB48uIC2QvKbToByn3zxxRc0aNCASZMm0b59e+50+b4iRW4vd1hYGPv27QOu72iDBg0i\nLCyMHTt2ANe/zT169Cjly5e/49+tUqUKe/fuJTs7m6tXr3L8+PHbnvOfWUJDQ9m7dy+ZmZnYbDb7\nFBgAk8mU47n+/v6ULl2aTz/9lPnz59O/f3/7KOGdtqeg3ZrX39+fK1euEB8fD8Aff/xh/3D0n1n/\nczud0X+2nSlTptzTdoWFhbF7927g+rTCW794uPH60NBQOnTowPz584mKiqJ9+/aUKFEix3Oc3Z3q\nULJkSQ4fPgzA9u3bqVSpElWqVGHfvn1kZ2djsVg4ePCgkbELTG7tpLD8/9+LO+0Hfn5+t9WgatWq\n9lpdunSJmJiY29Z1p7pVrlyZiRMnMn/+fIYMGUKLFi3yYzMKXLVq1di1axcAp0+fJiUlBbPZTEJC\nAkCOfaiwtadbtyc1NZXp06czdepUIiMj8fT0tL8f38t25/Wc0NBQevXqxfz585k2bRrPPvss4Bjv\ny3/VunXraNSoEfPmzaN9+/ZERUXZH7t1e0JDQxk8eDDz589n7NixtG/fHih8behWeW1bZmYmaWlp\nWCwW+2e//6zlnDlz7M8PCQnhxIkT9i+TBgwYQFxcXP5ugBQIjczdJy1btiQyMpIffvgBHx8f3Nzc\n7DtMXrp06cKIESPo0aMHWVlZjBgxgurVqzN69Gi6du1KRkYGb7zxBoGBgXd8fc2aNWnWrBmdOnWi\nZMmSd3xeWFgYgwcPto/2Va9enSeffJKuXbuSnZ1No0aNaN26tf1D7K2KFCnCyJEjefnll7HZbBQv\nXpwPP/yQ2NjYv1ih/GcymYiMjOTNN9+0f3v1j3/8wz7qWNj8Z9vp3bu3/fcTeenatStDh/6/9u5n\nJZUwDuP4M4TWwk0QLQbdtA6vIMg2bnQThJozuSpoIS0MziS6UNJuoXXbrqCFIHQBrkUQXBfSZhD8\nk7YIhM7xhAdODWPfzwUMv3mZYeaZ9/2980vHx8fa2dmZz9D+fuxyuSzbtuW6rrLZrC9fEj6zaBxq\ntZqur681m820tramm5sbRSIR7e/vK5VKaXNzU4FA4MNs5qpa5jpZdcveB7FYTI+Pj8pkMtra2tLG\nxsZS41WpVOQ4zryfql6vf8VpfLujoyNdXV3JsiyZpqn19XXlcjlVq1WZpqnt7W2vS/wWoVBI0WhU\n6XR63prw9PT014+z/+L8/FylUkn39/dyXVf5fP4/VOyN3d1dOY6j29tbTadTnZycLNwF1nEcVSoV\nDYfDec/gT5bL5ZROpxUOh2WapqQ/x7JYLMp1XUnvqwbOzs5k27YMw9DBwcF8JRP8zZgtmkICAEh6\n7zN4eHiQZVkajUZKJBK6u7ubPzyBbrerdrutRCKhl5cXJZNJNZtNBYNBr0vzRKvV0mAw0N7ennq9\nnk5PT9VoNLwuCwBWEmEOAD4xnU5VKpXU6XRkGIbi8ThbzuODwWCgy8tL9ft9vb6+yrZtHR4eel2W\nZ56fn1UoFDQejzWZTHRxccGvcQDgixDmAAAAAMCHVqsJBgAAAAB+CMIcAAAAAPgQYQ4AAAAAfIgw\nBwAAAAA+RJgDAAAAAB8izAEAAACAD70BYfJHPhtTwLEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8955cbb940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# run a separate instance of model evaluation on test set\n",
    "# to create a single confusion matrix\n",
    "\n",
    "acc = evaluate(model, test_x, test_y)\n",
    "\n",
    "labels = [\"air conditioner\", \"horn\", \"children\", \"dog\", \"drill\", \"engine\", \"gun\", \"hammer\", \"siren\", \"music\"]\n",
    "print(\"Showing Confusion Matrix\")\n",
    "y_prob = model.predict(test_x, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=-1)\n",
    "y_true = np.argmax(test_y, 1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=' ')\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=' ')\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}s\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=' ')\n",
    "        print()\n",
    "\n",
    "print_cm(cm, labels)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, labels, labels)\n",
    "plt.figure(figsize=(16, 8))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
