{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# change the seed before anything else\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(7)\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras\n",
    "keras.backend.clear_session()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = 101\n",
    "bands = 60\n",
    "feature_size = bands * frames\n",
    "num_channels = 3\n",
    "num_labels = 10\n",
    "data_dir = 'folds_2channel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_folds(test_fold):\n",
    "    assert (type(test_fold) == int)\n",
    "    assert (test_fold > 0 and test_fold < 11)\n",
    "    subsequent_fold = False\n",
    "\n",
    "    train_set_range = list(range(1, 11))\n",
    "    train_set_range.remove(test_fold)\n",
    "    valid_fold = train_set_range.pop()\n",
    "\n",
    "    for k in train_set_range:\n",
    "        fold_name = 'fold' + str(k)\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        # flip the spectrogram for each channel\n",
    "        loaded_features = np.transpose(loaded_features, (0, 2, 1, 3))\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print(\"Adding \", fold_name, \"New Features: \", loaded_features.shape)\n",
    "\n",
    "        if subsequent_fold:\n",
    "            train_x_loaded = np.concatenate((train_x_loaded, loaded_features))\n",
    "            train_y_loaded = np.concatenate((train_y_loaded, loaded_labels))\n",
    "        else:\n",
    "            train_x_loaded = loaded_features\n",
    "            train_y_loaded = loaded_labels\n",
    "            subsequent_fold = True\n",
    "\n",
    "    # use the penultimate fold for validation\n",
    "    valid_fold_name = 'fold' + str(valid_fold)\n",
    "    feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "    valid_x = np.load(feature_file)\n",
    "    # flip the spectrogram for each channel\n",
    "    valid_x = np.transpose(valid_x, (0, 2, 1, 3))\n",
    "    valid_y = np.load(labels_file)\n",
    "\n",
    "    # and use the last fold for testing\n",
    "    test_fold_name = 'fold' + str(test_fold)\n",
    "    feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "    test_x = np.load(feature_file)\n",
    "    test_x = np.transpose(test_x, (0, 2, 1, 3))\n",
    "    test_y = np.load(labels_file)\n",
    "    return train_x_loaded, train_y_loaded, valid_x, valid_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y):\n",
    "    y_prob = model.predict(test_x, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=-1)\n",
    "    y_true = np.argmax(test_y, 1)\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "    print(\"\\nAccuracy = {:.4f}\".format(accuracy))\n",
    "    print(\"\\nError Rate = {:.4f}\".format(1. - accuracy))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    # create model \n",
    "    visible = Input(shape=(frames, bands, num_channels))\n",
    "    \n",
    "    # 2 conv + 2 pool layers\n",
    "    conv1 = Conv2D(80, kernel_size=(57, 6), strides=(1, 1), activation='relu', kernel_regularizer=l2(0.001))(visible)\n",
    "    dropout1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(4, 3), strides=(1, 3))(conv1) \n",
    "    conv2 =Conv2D(80, kernel_size=(1, 3), strides=(1, 1), activation='relu', kernel_regularizer=l2(0.001))(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(1, 3), strides=(1, 3))(conv2)\n",
    "    # flatten from 4 to only 2 dimensions\n",
    "    flatten = Flatten()(pool2)\n",
    "    # 2 fully connected Layers\n",
    "    fc1 = Dense(5000, activation = \"relu\", kernel_regularizer=l2(0.001))(flatten)\n",
    "    fc1 = Dropout(0.5)(fc1)\n",
    "    fc2 = Dense(5000, activation = \"relu\", kernel_regularizer=l2(0.001))(fc1)\n",
    "    fc2 = Dropout(0.5)(fc2)\n",
    "    # softmax output layer\n",
    "    softmax = Dense(10, activation = \"softmax\", kernel_regularizer=l2(0.001))(fc2)\n",
    "    model = Model(inputs=visible, outputs=softmax)\n",
    "    # print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply scaling factor to a dataset - train, validation or test\n",
    "def do_scale(x4d, verbose = True):\n",
    "    \"\"\"Do scale on the input sequence data.\n",
    "\n",
    "    Args:\n",
    "      x34d: ndarray, input sequence data, shape: (n_clips, n_time, n_freq, channel)      \n",
    "      verbose: boolean\n",
    "\n",
    "    Returns:\n",
    "      Scaled input sequence data.\n",
    "    \"\"\"\n",
    "    t1 = time.time()    \n",
    "    (n_clips, n_time, n_freq, n_channel) = x4d.shape\n",
    "    x4d_scaled = np.zeros(x4d.shape)\n",
    "    for channel in range(n_channel):\n",
    "        x2d = x4d[:,:,:,channel].reshape((n_clips * n_time, n_freq))\n",
    "        x2d_scaled = scaler_list[channel].transform(x2d)\n",
    "        x3d_scaled = x2d_scaled.reshape((n_clips, n_time, n_freq))\n",
    "        x4d_scaled[:,:,:,channel] = x3d_scaled\n",
    "\n",
    "    if verbose == 1:\n",
    "        print(\"Scaling time: %s\" % (time.time() - t1,))\n",
    "\n",
    "    return x4d_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening fold: 1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.829319953918457\n",
      "Scaling time: 0.2275373935699463\n",
      "Scaling time: 0.23914408683776855\n",
      "training model...hold tight\n",
      "Train on 7021 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7021/7021 [==============================] - 14s - loss: 15.1202 - acc: 0.1147 - val_loss: 15.0748 - val_acc: 0.1792\n",
      "Epoch 2/150\n",
      "7021/7021 [==============================] - 2s - loss: 15.0762 - acc: 0.1367 - val_loss: 15.0196 - val_acc: 0.1792\n",
      "Epoch 3/150\n",
      "7021/7021 [==============================] - 2s - loss: 15.0203 - acc: 0.1693 - val_loss: 14.9537 - val_acc: 0.1983\n",
      "Epoch 4/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.9659 - acc: 0.1849 - val_loss: 14.9020 - val_acc: 0.2091\n",
      "Epoch 5/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.9216 - acc: 0.2035 - val_loss: 14.8596 - val_acc: 0.2103\n",
      "Epoch 6/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.8834 - acc: 0.2108 - val_loss: 14.8230 - val_acc: 0.2461\n",
      "Epoch 7/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.8556 - acc: 0.2302 - val_loss: 14.7944 - val_acc: 0.2019\n",
      "Epoch 8/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.8195 - acc: 0.2411 - val_loss: 14.7541 - val_acc: 0.2772\n",
      "Epoch 9/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.7725 - acc: 0.2658 - val_loss: 14.7196 - val_acc: 0.2688\n",
      "Epoch 10/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.7398 - acc: 0.2648 - val_loss: 14.6712 - val_acc: 0.3417\n",
      "Epoch 11/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.6932 - acc: 0.2787 - val_loss: 14.6295 - val_acc: 0.3321\n",
      "Epoch 12/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.6574 - acc: 0.2928 - val_loss: 14.5983 - val_acc: 0.2951\n",
      "Epoch 13/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.6292 - acc: 0.2911 - val_loss: 14.5781 - val_acc: 0.3023\n",
      "Epoch 14/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5937 - acc: 0.3133 - val_loss: 14.5621 - val_acc: 0.3023\n",
      "Epoch 15/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5699 - acc: 0.3180 - val_loss: 14.5825 - val_acc: 0.2676\n",
      "Epoch 16/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5743 - acc: 0.3048 - val_loss: 14.5330 - val_acc: 0.2796\n",
      "Epoch 17/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5266 - acc: 0.3227 - val_loss: 14.5096 - val_acc: 0.2903\n",
      "Epoch 18/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.5022 - acc: 0.3358 - val_loss: 14.5014 - val_acc: 0.3011\n",
      "Epoch 19/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.4746 - acc: 0.3414 - val_loss: 14.4986 - val_acc: 0.2963\n",
      "Epoch 20/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.4524 - acc: 0.3488 - val_loss: 14.4701 - val_acc: 0.3751\n",
      "Epoch 21/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.4249 - acc: 0.3518 - val_loss: 14.4424 - val_acc: 0.3238\n",
      "Epoch 22/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.4106 - acc: 0.3595 - val_loss: 14.4523 - val_acc: 0.3274\n",
      "Epoch 23/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3896 - acc: 0.3712 - val_loss: 14.4353 - val_acc: 0.3274\n",
      "Epoch 24/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3681 - acc: 0.3824 - val_loss: 14.4231 - val_acc: 0.3047\n",
      "Epoch 25/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3456 - acc: 0.3905 - val_loss: 14.4464 - val_acc: 0.3297\n",
      "Epoch 26/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3436 - acc: 0.3836 - val_loss: 14.3790 - val_acc: 0.4098\n",
      "Epoch 27/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.3137 - acc: 0.3992 - val_loss: 14.3713 - val_acc: 0.3250\n",
      "Epoch 28/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2950 - acc: 0.4173 - val_loss: 14.3648 - val_acc: 0.4194\n",
      "Epoch 29/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.2837 - acc: 0.4123 - val_loss: 14.3690 - val_acc: 0.3369\n",
      "Epoch 30/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2670 - acc: 0.4220 - val_loss: 14.3440 - val_acc: 0.3728\n",
      "Epoch 31/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.2439 - acc: 0.4284 - val_loss: 14.3247 - val_acc: 0.4229\n",
      "Epoch 32/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2210 - acc: 0.4398 - val_loss: 14.3057 - val_acc: 0.4325\n",
      "Epoch 33/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.2131 - acc: 0.4346 - val_loss: 14.2972 - val_acc: 0.3859\n",
      "Epoch 34/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.1977 - acc: 0.4420 - val_loss: 14.3154 - val_acc: 0.4301\n",
      "Epoch 35/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.1769 - acc: 0.4487 - val_loss: 14.2587 - val_acc: 0.4098\n",
      "Epoch 36/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.1565 - acc: 0.4599 - val_loss: 14.2866 - val_acc: 0.4050\n",
      "Epoch 37/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.1416 - acc: 0.4638 - val_loss: 14.2655 - val_acc: 0.4205\n",
      "Epoch 38/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.1448 - acc: 0.4551 - val_loss: 14.2463 - val_acc: 0.3895\n",
      "Epoch 39/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.1097 - acc: 0.4733 - val_loss: 14.2257 - val_acc: 0.4456\n",
      "Epoch 40/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.1014 - acc: 0.4672 - val_loss: 14.1931 - val_acc: 0.4337\n",
      "Epoch 41/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0813 - acc: 0.4741 - val_loss: 14.1926 - val_acc: 0.4480\n",
      "Epoch 42/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.0644 - acc: 0.4828 - val_loss: 14.1916 - val_acc: 0.3871\n",
      "Epoch 43/150\n",
      "7021/7021 [==============================] - 2s - loss: 14.0504 - acc: 0.4818 - val_loss: 14.1653 - val_acc: 0.4385\n",
      "Epoch 44/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0447 - acc: 0.4811 - val_loss: 14.2576 - val_acc: 0.3548\n",
      "Epoch 45/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0338 - acc: 0.4892 - val_loss: 14.1542 - val_acc: 0.4540\n",
      "Epoch 46/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0303 - acc: 0.4776 - val_loss: 14.1709 - val_acc: 0.4659\n",
      "Epoch 47/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0040 - acc: 0.4877 - val_loss: 14.2084 - val_acc: 0.3955\n",
      "Epoch 48/150\n",
      "7021/7021 [==============================] - 3s - loss: 14.0002 - acc: 0.4918 - val_loss: 14.1610 - val_acc: 0.4217\n",
      "Epoch 49/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9868 - acc: 0.4945 - val_loss: 14.1558 - val_acc: 0.4946\n",
      "Epoch 50/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9643 - acc: 0.5008 - val_loss: 14.2541 - val_acc: 0.3787\n",
      "Epoch 51/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9598 - acc: 0.5018 - val_loss: 14.1205 - val_acc: 0.4683\n",
      "Epoch 52/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9523 - acc: 0.5038 - val_loss: 14.1290 - val_acc: 0.3907\n",
      "Epoch 53/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9495 - acc: 0.5002 - val_loss: 14.1355 - val_acc: 0.4086\n",
      "Epoch 54/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9340 - acc: 0.5176 - val_loss: 14.1089 - val_acc: 0.4086\n",
      "Epoch 55/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.9151 - acc: 0.5041 - val_loss: 14.1570 - val_acc: 0.3967\n",
      "Epoch 56/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.9175 - acc: 0.5089 - val_loss: 14.0807 - val_acc: 0.4337\n",
      "Epoch 57/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.8891 - acc: 0.5170 - val_loss: 14.0968 - val_acc: 0.4552\n",
      "Epoch 58/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8823 - acc: 0.5213 - val_loss: 14.0824 - val_acc: 0.4695\n",
      "Epoch 59/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8776 - acc: 0.5247 - val_loss: 14.0567 - val_acc: 0.4480\n",
      "Epoch 60/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8585 - acc: 0.5301 - val_loss: 14.0940 - val_acc: 0.3967\n",
      "Epoch 61/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8641 - acc: 0.5240 - val_loss: 14.2052 - val_acc: 0.3847\n",
      "Epoch 62/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8471 - acc: 0.5251 - val_loss: 14.0569 - val_acc: 0.4456\n",
      "Epoch 63/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8391 - acc: 0.5249 - val_loss: 14.0655 - val_acc: 0.4253\n",
      "Epoch 64/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.8182 - acc: 0.5431 - val_loss: 14.1537 - val_acc: 0.3799\n",
      "Epoch 65/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8212 - acc: 0.5337 - val_loss: 14.0600 - val_acc: 0.4146\n",
      "Epoch 66/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.8013 - acc: 0.5365 - val_loss: 14.1171 - val_acc: 0.4432\n",
      "Epoch 67/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8000 - acc: 0.5325 - val_loss: 14.0245 - val_acc: 0.4134\n",
      "Epoch 68/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7938 - acc: 0.5351 - val_loss: 14.0346 - val_acc: 0.4182\n",
      "Epoch 69/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7818 - acc: 0.5394 - val_loss: 14.3812 - val_acc: 0.3596\n",
      "Epoch 70/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.8041 - acc: 0.5318 - val_loss: 14.0080 - val_acc: 0.4253\n",
      "Epoch 71/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7549 - acc: 0.5529 - val_loss: 14.0087 - val_acc: 0.4875\n",
      "Epoch 72/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7573 - acc: 0.5412 - val_loss: 13.9917 - val_acc: 0.4648\n",
      "Epoch 73/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7356 - acc: 0.5535 - val_loss: 14.0452 - val_acc: 0.4468\n",
      "Epoch 74/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7450 - acc: 0.5523 - val_loss: 13.9720 - val_acc: 0.4875\n",
      "Epoch 75/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7155 - acc: 0.5553 - val_loss: 13.9846 - val_acc: 0.4182\n",
      "Epoch 76/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.7107 - acc: 0.5543 - val_loss: 13.9659 - val_acc: 0.4421\n",
      "Epoch 77/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6905 - acc: 0.5649 - val_loss: 13.9662 - val_acc: 0.4648\n",
      "Epoch 78/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6951 - acc: 0.5583 - val_loss: 13.9613 - val_acc: 0.4648\n",
      "Epoch 79/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6733 - acc: 0.5744 - val_loss: 13.9454 - val_acc: 0.4576\n",
      "Epoch 80/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6679 - acc: 0.5736 - val_loss: 14.1034 - val_acc: 0.4385\n",
      "Epoch 81/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6846 - acc: 0.5600 - val_loss: 13.9486 - val_acc: 0.5030\n",
      "Epoch 82/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6522 - acc: 0.5706 - val_loss: 13.9231 - val_acc: 0.4970\n",
      "Epoch 83/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6353 - acc: 0.5756 - val_loss: 13.9644 - val_acc: 0.5412\n",
      "Epoch 84/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6331 - acc: 0.5758 - val_loss: 13.9196 - val_acc: 0.5603\n",
      "Epoch 85/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6202 - acc: 0.5815 - val_loss: 14.0395 - val_acc: 0.4827\n",
      "Epoch 86/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.6309 - acc: 0.5801 - val_loss: 13.9116 - val_acc: 0.4851\n",
      "Epoch 87/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.6005 - acc: 0.5877 - val_loss: 13.9037 - val_acc: 0.4803\n",
      "Epoch 88/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5846 - acc: 0.5928 - val_loss: 13.9131 - val_acc: 0.4277\n",
      "Epoch 89/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5864 - acc: 0.5921 - val_loss: 13.9116 - val_acc: 0.4612\n",
      "Epoch 90/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5727 - acc: 0.5955 - val_loss: 14.1148 - val_acc: 0.4265\n",
      "Epoch 91/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.5928 - acc: 0.5891 - val_loss: 13.9893 - val_acc: 0.4432\n",
      "Epoch 92/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5754 - acc: 0.5905 - val_loss: 13.9107 - val_acc: 0.4361\n",
      "Epoch 93/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5662 - acc: 0.5901 - val_loss: 13.8727 - val_acc: 0.4671\n",
      "Epoch 94/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5376 - acc: 0.6038 - val_loss: 13.9970 - val_acc: 0.4970\n",
      "Epoch 95/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5505 - acc: 0.5938 - val_loss: 13.9595 - val_acc: 0.4910\n",
      "Epoch 96/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5444 - acc: 0.5988 - val_loss: 13.8632 - val_acc: 0.4504\n",
      "Epoch 97/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5129 - acc: 0.6140 - val_loss: 13.8570 - val_acc: 0.5090\n",
      "Epoch 98/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5048 - acc: 0.6083 - val_loss: 13.9939 - val_acc: 0.4421\n",
      "Epoch 99/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5205 - acc: 0.6038 - val_loss: 13.8583 - val_acc: 0.4480\n",
      "Epoch 100/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4873 - acc: 0.6204 - val_loss: 14.1976 - val_acc: 0.3907\n",
      "Epoch 101/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.5184 - acc: 0.6028 - val_loss: 13.8830 - val_acc: 0.4910\n",
      "Epoch 102/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4672 - acc: 0.6203 - val_loss: 13.8573 - val_acc: 0.5054\n",
      "Epoch 103/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4605 - acc: 0.6224 - val_loss: 13.8581 - val_acc: 0.4373\n",
      "Epoch 104/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4566 - acc: 0.6199 - val_loss: 13.8822 - val_acc: 0.4934\n",
      "Epoch 105/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4532 - acc: 0.6256 - val_loss: 13.8751 - val_acc: 0.4910\n",
      "Epoch 106/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4463 - acc: 0.6250 - val_loss: 14.1392 - val_acc: 0.3728\n",
      "Epoch 107/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4868 - acc: 0.6082 - val_loss: 13.8300 - val_acc: 0.5257\n",
      "Epoch 108/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4257 - acc: 0.6297 - val_loss: 13.8937 - val_acc: 0.4564\n",
      "Epoch 109/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4143 - acc: 0.6295 - val_loss: 13.8682 - val_acc: 0.4492\n",
      "Epoch 110/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4167 - acc: 0.6264 - val_loss: 13.8723 - val_acc: 0.4468\n",
      "Epoch 111/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4055 - acc: 0.6241 - val_loss: 13.9112 - val_acc: 0.5161\n",
      "Epoch 112/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4121 - acc: 0.6247 - val_loss: 13.8687 - val_acc: 0.5245\n",
      "Epoch 113/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3822 - acc: 0.6415 - val_loss: 13.8735 - val_acc: 0.5388\n",
      "Epoch 114/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3754 - acc: 0.6404 - val_loss: 13.8522 - val_acc: 0.4982\n",
      "Epoch 115/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3661 - acc: 0.6415 - val_loss: 13.7801 - val_acc: 0.5352\n",
      "Epoch 116/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.3567 - acc: 0.6424 - val_loss: 13.7589 - val_acc: 0.5400\n",
      "Epoch 117/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3473 - acc: 0.6406 - val_loss: 13.7515 - val_acc: 0.5902\n",
      "Epoch 118/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3313 - acc: 0.6503 - val_loss: 13.8061 - val_acc: 0.5125\n",
      "Epoch 119/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3394 - acc: 0.6532 - val_loss: 13.7662 - val_acc: 0.5245\n",
      "Epoch 120/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3298 - acc: 0.6495 - val_loss: 13.7726 - val_acc: 0.4540\n",
      "Epoch 121/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.3109 - acc: 0.6576 - val_loss: 13.7497 - val_acc: 0.4743\n",
      "Epoch 122/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.3008 - acc: 0.6570 - val_loss: 13.7451 - val_acc: 0.5376\n",
      "Epoch 123/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2962 - acc: 0.6543 - val_loss: 14.5733 - val_acc: 0.3560\n",
      "Epoch 124/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.4810 - acc: 0.6070 - val_loss: 13.7344 - val_acc: 0.5221\n",
      "Epoch 125/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2862 - acc: 0.6617 - val_loss: 13.7047 - val_acc: 0.5878\n",
      "Epoch 126/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2761 - acc: 0.6596 - val_loss: 13.7302 - val_acc: 0.5149\n",
      "Epoch 127/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2652 - acc: 0.6651 - val_loss: 13.7984 - val_acc: 0.5424\n",
      "Epoch 128/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2599 - acc: 0.6741 - val_loss: 13.7685 - val_acc: 0.4922\n",
      "Epoch 129/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2757 - acc: 0.6607 - val_loss: 13.8135 - val_acc: 0.4898\n",
      "Epoch 130/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2602 - acc: 0.6595 - val_loss: 13.7647 - val_acc: 0.4719\n",
      "Epoch 131/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2485 - acc: 0.6673 - val_loss: 13.8653 - val_acc: 0.5508\n",
      "Epoch 132/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2487 - acc: 0.6619 - val_loss: 13.7776 - val_acc: 0.4815\n",
      "Epoch 133/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2402 - acc: 0.6651 - val_loss: 13.7740 - val_acc: 0.5568\n",
      "Epoch 134/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2282 - acc: 0.6764 - val_loss: 13.7792 - val_acc: 0.4934\n",
      "Epoch 135/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.2280 - acc: 0.6673 - val_loss: 13.6944 - val_acc: 0.5532\n",
      "Epoch 136/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2001 - acc: 0.6801 - val_loss: 13.6719 - val_acc: 0.5030\n",
      "Epoch 137/150\n",
      "7021/7021 [==============================] - 2s - loss: 13.1955 - acc: 0.6774 - val_loss: 13.6989 - val_acc: 0.5090\n",
      "Epoch 138/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1954 - acc: 0.6785 - val_loss: 13.6874 - val_acc: 0.5352\n",
      "Epoch 139/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1763 - acc: 0.6820 - val_loss: 13.6626 - val_acc: 0.5568\n",
      "Epoch 140/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1653 - acc: 0.6828 - val_loss: 13.6939 - val_acc: 0.5412\n",
      "Epoch 141/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1618 - acc: 0.6794 - val_loss: 13.8183 - val_acc: 0.5376\n",
      "Epoch 142/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1744 - acc: 0.6784 - val_loss: 13.6522 - val_acc: 0.5341\n",
      "Epoch 143/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1554 - acc: 0.6844 - val_loss: 13.7281 - val_acc: 0.4767\n",
      "Epoch 144/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1798 - acc: 0.6669 - val_loss: 13.7572 - val_acc: 0.4695\n",
      "Epoch 145/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1526 - acc: 0.6805 - val_loss: 13.7778 - val_acc: 0.5173\n",
      "Epoch 146/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1445 - acc: 0.6858 - val_loss: 13.6386 - val_acc: 0.5759\n",
      "Epoch 147/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1119 - acc: 0.6894 - val_loss: 13.9435 - val_acc: 0.4863\n",
      "Epoch 148/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.2051 - acc: 0.6670 - val_loss: 13.7163 - val_acc: 0.5400\n",
      "Epoch 149/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1130 - acc: 0.6949 - val_loss: 13.6556 - val_acc: 0.5938\n",
      "Epoch 150/150\n",
      "7021/7021 [==============================] - 3s - loss: 13.1000 - acc: 0.6931 - val_loss: 13.6862 - val_acc: 0.5544\n",
      "training time: 464.1855278015137\n",
      "800/869 [==========================>...] - ETA: 0s\n",
      "Accuracy = 0.5834\n",
      "\n",
      "Error Rate = 0.4166\n",
      "training time: 0.7185590267181396\n",
      "opening fold: 2\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8251550197601318\n",
      "Scaling time: 0.2292191982269287\n",
      "Scaling time: 0.24295997619628906\n",
      "training model...hold tight\n",
      "Train on 7003 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7003/7003 [==============================] - 9s - loss: 15.1209 - acc: 0.1122 - val_loss: 15.0709 - val_acc: 0.1470\n",
      "Epoch 2/150\n",
      "7003/7003 [==============================] - 2s - loss: 15.0687 - acc: 0.1479 - val_loss: 15.0132 - val_acc: 0.1900\n",
      "Epoch 3/150\n",
      "7003/7003 [==============================] - 3s - loss: 15.0141 - acc: 0.1694 - val_loss: 14.9799 - val_acc: 0.1708\n",
      "Epoch 4/150\n",
      "7003/7003 [==============================] - 3s - loss: 15.0050 - acc: 0.1858 - val_loss: 14.9178 - val_acc: 0.2234\n",
      "Epoch 5/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.9372 - acc: 0.1912 - val_loss: 14.8913 - val_acc: 0.2139\n",
      "Epoch 6/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.8959 - acc: 0.1946 - val_loss: 14.8591 - val_acc: 0.1720\n",
      "Epoch 7/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.8723 - acc: 0.1996 - val_loss: 14.8102 - val_acc: 0.1744\n",
      "Epoch 8/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.8214 - acc: 0.2325 - val_loss: 14.7575 - val_acc: 0.2186\n",
      "Epoch 9/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7846 - acc: 0.2395 - val_loss: 14.7306 - val_acc: 0.2091\n",
      "Epoch 10/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7708 - acc: 0.2530 - val_loss: 14.6933 - val_acc: 0.2676\n",
      "Epoch 11/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7641 - acc: 0.2428 - val_loss: 14.6745 - val_acc: 0.2198\n",
      "Epoch 12/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7312 - acc: 0.2632 - val_loss: 14.7095 - val_acc: 0.2557\n",
      "Epoch 13/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.7125 - acc: 0.2692 - val_loss: 14.6066 - val_acc: 0.3548\n",
      "Epoch 14/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.6682 - acc: 0.2727 - val_loss: 14.6056 - val_acc: 0.2963\n",
      "Epoch 15/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.6536 - acc: 0.2623 - val_loss: 14.5975 - val_acc: 0.2963\n",
      "Epoch 16/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.6018 - acc: 0.2940 - val_loss: 14.6395 - val_acc: 0.2557\n",
      "Epoch 17/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.6168 - acc: 0.2773 - val_loss: 14.5533 - val_acc: 0.2951\n",
      "Epoch 18/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5853 - acc: 0.2919 - val_loss: 14.5442 - val_acc: 0.3190\n",
      "Epoch 19/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5710 - acc: 0.3176 - val_loss: 14.5285 - val_acc: 0.3560\n",
      "Epoch 20/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5446 - acc: 0.3147 - val_loss: 14.5237 - val_acc: 0.3668\n",
      "Epoch 21/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5485 - acc: 0.3217 - val_loss: 14.5245 - val_acc: 0.2975\n",
      "Epoch 22/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5281 - acc: 0.3166 - val_loss: 14.5111 - val_acc: 0.3345\n",
      "Epoch 23/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5319 - acc: 0.3264 - val_loss: 14.5331 - val_acc: 0.3369\n",
      "Epoch 24/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.5037 - acc: 0.3344 - val_loss: 14.5409 - val_acc: 0.2808\n",
      "Epoch 25/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4824 - acc: 0.3411 - val_loss: 14.4407 - val_acc: 0.3405\n",
      "Epoch 26/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4297 - acc: 0.3723 - val_loss: 14.4686 - val_acc: 0.3142\n",
      "Epoch 27/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.4060 - acc: 0.3797 - val_loss: 14.4416 - val_acc: 0.3094\n",
      "Epoch 28/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3899 - acc: 0.3774 - val_loss: 14.4074 - val_acc: 0.3978\n",
      "Epoch 29/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3758 - acc: 0.3844 - val_loss: 14.4572 - val_acc: 0.3847\n",
      "Epoch 30/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3758 - acc: 0.3691 - val_loss: 14.3977 - val_acc: 0.3907\n",
      "Epoch 31/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3657 - acc: 0.3865 - val_loss: 14.3815 - val_acc: 0.3823\n",
      "Epoch 32/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3286 - acc: 0.3913 - val_loss: 14.3379 - val_acc: 0.4134\n",
      "Epoch 33/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3139 - acc: 0.4040 - val_loss: 14.4996 - val_acc: 0.2521\n",
      "Epoch 34/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3611 - acc: 0.3630 - val_loss: 14.3555 - val_acc: 0.4456\n",
      "Epoch 35/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.3150 - acc: 0.3877 - val_loss: 14.3747 - val_acc: 0.3955\n",
      "Epoch 36/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.3118 - acc: 0.3953 - val_loss: 14.3289 - val_acc: 0.3811\n",
      "Epoch 37/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2564 - acc: 0.4041 - val_loss: 14.2814 - val_acc: 0.4122\n",
      "Epoch 38/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2329 - acc: 0.4245 - val_loss: 14.2582 - val_acc: 0.4194\n",
      "Epoch 39/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.1978 - acc: 0.4335 - val_loss: 14.3085 - val_acc: 0.3501\n",
      "Epoch 40/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.2086 - acc: 0.4300 - val_loss: 14.2809 - val_acc: 0.4289\n",
      "Epoch 41/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1668 - acc: 0.4387 - val_loss: 14.2524 - val_acc: 0.4600\n",
      "Epoch 42/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1670 - acc: 0.4388 - val_loss: 14.5239 - val_acc: 0.3286\n",
      "Epoch 43/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1701 - acc: 0.4480 - val_loss: 14.3100 - val_acc: 0.3513\n",
      "Epoch 44/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1834 - acc: 0.4437 - val_loss: 14.2288 - val_acc: 0.4062\n",
      "Epoch 45/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.1314 - acc: 0.4559 - val_loss: 14.1780 - val_acc: 0.4373\n",
      "Epoch 46/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.0860 - acc: 0.4611 - val_loss: 14.2787 - val_acc: 0.4229\n",
      "Epoch 47/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1201 - acc: 0.4455 - val_loss: 14.1914 - val_acc: 0.4265\n",
      "Epoch 48/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0734 - acc: 0.4712 - val_loss: 14.1337 - val_acc: 0.4863\n",
      "Epoch 49/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0816 - acc: 0.4554 - val_loss: 14.1334 - val_acc: 0.4516\n",
      "Epoch 50/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0365 - acc: 0.4728 - val_loss: 14.1826 - val_acc: 0.4361\n",
      "Epoch 51/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0422 - acc: 0.4684 - val_loss: 14.1389 - val_acc: 0.3955\n",
      "Epoch 52/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0200 - acc: 0.4814 - val_loss: 14.4363 - val_acc: 0.3309\n",
      "Epoch 53/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0380 - acc: 0.4731 - val_loss: 14.9934 - val_acc: 0.3166\n",
      "Epoch 54/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.1107 - acc: 0.4542 - val_loss: 14.1465 - val_acc: 0.4552\n",
      "Epoch 55/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.0446 - acc: 0.4717 - val_loss: 14.1240 - val_acc: 0.4456\n",
      "Epoch 56/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.0082 - acc: 0.4699 - val_loss: 14.2536 - val_acc: 0.3632\n",
      "Epoch 57/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0049 - acc: 0.4789 - val_loss: 14.1679 - val_acc: 0.4361\n",
      "Epoch 58/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0058 - acc: 0.4721 - val_loss: 14.2941 - val_acc: 0.3465\n",
      "Epoch 59/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0373 - acc: 0.4495 - val_loss: 14.3684 - val_acc: 0.3309\n",
      "Epoch 60/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0186 - acc: 0.4554 - val_loss: 14.1273 - val_acc: 0.4671\n",
      "Epoch 61/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9913 - acc: 0.4705 - val_loss: 14.5034 - val_acc: 0.3513\n",
      "Epoch 62/150\n",
      "7003/7003 [==============================] - 2s - loss: 14.2367 - acc: 0.4204 - val_loss: 14.3284 - val_acc: 0.3417\n",
      "Epoch 63/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0355 - acc: 0.4634 - val_loss: 14.2307 - val_acc: 0.3501\n",
      "Epoch 64/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0069 - acc: 0.4731 - val_loss: 14.1243 - val_acc: 0.4791\n",
      "Epoch 65/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9664 - acc: 0.4925 - val_loss: 14.1714 - val_acc: 0.4540\n",
      "Epoch 66/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9678 - acc: 0.4872 - val_loss: 14.1780 - val_acc: 0.4026\n",
      "Epoch 67/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9788 - acc: 0.4718 - val_loss: 14.1287 - val_acc: 0.4134\n",
      "Epoch 68/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9275 - acc: 0.4972 - val_loss: 15.1277 - val_acc: 0.2975\n",
      "Epoch 69/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0788 - acc: 0.4467 - val_loss: 14.2123 - val_acc: 0.4026\n",
      "Epoch 70/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0048 - acc: 0.4641 - val_loss: 14.1303 - val_acc: 0.4432\n",
      "Epoch 71/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9622 - acc: 0.4669 - val_loss: 14.0669 - val_acc: 0.4743\n",
      "Epoch 72/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9240 - acc: 0.4799 - val_loss: 14.0450 - val_acc: 0.4946\n",
      "Epoch 73/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8915 - acc: 0.4919 - val_loss: 14.0357 - val_acc: 0.4994\n",
      "Epoch 74/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8703 - acc: 0.4861 - val_loss: 14.0628 - val_acc: 0.4576\n",
      "Epoch 75/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8953 - acc: 0.4935 - val_loss: 14.0732 - val_acc: 0.4277\n",
      "Epoch 76/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8662 - acc: 0.5046 - val_loss: 14.1772 - val_acc: 0.4373\n",
      "Epoch 77/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.9195 - acc: 0.4835 - val_loss: 14.0508 - val_acc: 0.4361\n",
      "Epoch 78/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8178 - acc: 0.5151 - val_loss: 14.0761 - val_acc: 0.4385\n",
      "Epoch 79/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8038 - acc: 0.5145 - val_loss: 14.0956 - val_acc: 0.4110\n",
      "Epoch 80/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8450 - acc: 0.5128 - val_loss: 14.0737 - val_acc: 0.4552\n",
      "Epoch 81/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7990 - acc: 0.5256 - val_loss: 14.1063 - val_acc: 0.4444\n",
      "Epoch 82/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7849 - acc: 0.5203 - val_loss: 15.4032 - val_acc: 0.3226\n",
      "Epoch 83/150\n",
      "7003/7003 [==============================] - 3s - loss: 14.0284 - acc: 0.4731 - val_loss: 14.1196 - val_acc: 0.4600\n",
      "Epoch 84/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8692 - acc: 0.4918 - val_loss: 14.1163 - val_acc: 0.4026\n",
      "Epoch 85/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8217 - acc: 0.5122 - val_loss: 14.0379 - val_acc: 0.4456\n",
      "Epoch 86/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7916 - acc: 0.5229 - val_loss: 14.1008 - val_acc: 0.4158\n",
      "Epoch 87/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.8007 - acc: 0.5205 - val_loss: 14.0433 - val_acc: 0.4444\n",
      "Epoch 88/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7669 - acc: 0.5235 - val_loss: 14.2420 - val_acc: 0.3728\n",
      "Epoch 89/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.7711 - acc: 0.5231 - val_loss: 13.9895 - val_acc: 0.4875\n",
      "Epoch 90/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.7196 - acc: 0.5391 - val_loss: 14.0330 - val_acc: 0.5078\n",
      "Epoch 91/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7838 - acc: 0.5086 - val_loss: 14.0495 - val_acc: 0.4588\n",
      "Epoch 92/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7603 - acc: 0.5288 - val_loss: 13.9826 - val_acc: 0.4612\n",
      "Epoch 93/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.6747 - acc: 0.5489 - val_loss: 14.0797 - val_acc: 0.4528\n",
      "Epoch 94/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7346 - acc: 0.5291 - val_loss: 14.3566 - val_acc: 0.3501\n",
      "Epoch 95/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7268 - acc: 0.5366 - val_loss: 13.9343 - val_acc: 0.5412\n",
      "Epoch 96/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6692 - acc: 0.5503 - val_loss: 14.1187 - val_acc: 0.4038\n",
      "Epoch 97/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.6566 - acc: 0.5688 - val_loss: 13.9621 - val_acc: 0.4827\n",
      "Epoch 98/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6543 - acc: 0.5491 - val_loss: 13.9407 - val_acc: 0.4695\n",
      "Epoch 99/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6302 - acc: 0.5570 - val_loss: 13.8945 - val_acc: 0.4755\n",
      "Epoch 100/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.6174 - acc: 0.5546 - val_loss: 13.8769 - val_acc: 0.4803\n",
      "Epoch 101/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6290 - acc: 0.5550 - val_loss: 13.9314 - val_acc: 0.5125\n",
      "Epoch 102/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6201 - acc: 0.5468 - val_loss: 13.9736 - val_acc: 0.5054\n",
      "Epoch 103/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.5832 - acc: 0.5660 - val_loss: 13.8936 - val_acc: 0.4659\n",
      "Epoch 104/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5721 - acc: 0.5719 - val_loss: 14.0587 - val_acc: 0.4731\n",
      "Epoch 105/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7110 - acc: 0.5261 - val_loss: 13.9608 - val_acc: 0.5102\n",
      "Epoch 106/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6126 - acc: 0.5510 - val_loss: 13.8737 - val_acc: 0.4851\n",
      "Epoch 107/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5664 - acc: 0.5738 - val_loss: 13.9028 - val_acc: 0.5066\n",
      "Epoch 108/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5787 - acc: 0.5612 - val_loss: 13.8594 - val_acc: 0.4910\n",
      "Epoch 109/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5481 - acc: 0.5826 - val_loss: 13.9266 - val_acc: 0.4540\n",
      "Epoch 110/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5999 - acc: 0.5616 - val_loss: 13.9473 - val_acc: 0.4576\n",
      "Epoch 111/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6124 - acc: 0.5448 - val_loss: 13.8879 - val_acc: 0.4648\n",
      "Epoch 112/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5472 - acc: 0.5655 - val_loss: 13.8383 - val_acc: 0.5233\n",
      "Epoch 113/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5214 - acc: 0.5839 - val_loss: 13.8581 - val_acc: 0.4815\n",
      "Epoch 114/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5407 - acc: 0.5816 - val_loss: 13.8641 - val_acc: 0.4934\n",
      "Epoch 115/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5281 - acc: 0.5675 - val_loss: 14.8426 - val_acc: 0.3321\n",
      "Epoch 116/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.6229 - acc: 0.5556 - val_loss: 13.8524 - val_acc: 0.5054\n",
      "Epoch 117/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4977 - acc: 0.5880 - val_loss: 13.8746 - val_acc: 0.4970\n",
      "Epoch 118/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4998 - acc: 0.5852 - val_loss: 14.0040 - val_acc: 0.4970\n",
      "Epoch 119/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5263 - acc: 0.5623 - val_loss: 13.9114 - val_acc: 0.4671\n",
      "Epoch 120/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5020 - acc: 0.5773 - val_loss: 13.8667 - val_acc: 0.4958\n",
      "Epoch 121/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5102 - acc: 0.5730 - val_loss: 14.8517 - val_acc: 0.2915\n",
      "Epoch 122/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.7122 - acc: 0.5223 - val_loss: 13.9233 - val_acc: 0.3978\n",
      "Epoch 123/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.5290 - acc: 0.5623 - val_loss: 13.7949 - val_acc: 0.5257\n",
      "Epoch 124/150\n",
      "7003/7003 [==============================] - 2s - loss: 13.4640 - acc: 0.5750 - val_loss: 13.7621 - val_acc: 0.5448\n",
      "Epoch 125/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4301 - acc: 0.5955 - val_loss: 13.8175 - val_acc: 0.4612\n",
      "Epoch 126/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4366 - acc: 0.6047 - val_loss: 13.7711 - val_acc: 0.4970\n",
      "Epoch 127/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4102 - acc: 0.6075 - val_loss: 13.7124 - val_acc: 0.5627\n",
      "Epoch 128/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3784 - acc: 0.6169 - val_loss: 13.7574 - val_acc: 0.5508\n",
      "Epoch 129/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4466 - acc: 0.5748 - val_loss: 13.8150 - val_acc: 0.5030\n",
      "Epoch 130/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4213 - acc: 0.6036 - val_loss: 13.7516 - val_acc: 0.4970\n",
      "Epoch 131/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3685 - acc: 0.6100 - val_loss: 13.8158 - val_acc: 0.4552\n",
      "Epoch 132/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3803 - acc: 0.6072 - val_loss: 13.7835 - val_acc: 0.4803\n",
      "Epoch 133/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3782 - acc: 0.5956 - val_loss: 13.8273 - val_acc: 0.4325\n",
      "Epoch 134/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3845 - acc: 0.6043 - val_loss: 13.8065 - val_acc: 0.4719\n",
      "Epoch 135/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3813 - acc: 0.6052 - val_loss: 13.7229 - val_acc: 0.4946\n",
      "Epoch 136/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3380 - acc: 0.6209 - val_loss: 13.7272 - val_acc: 0.5078\n",
      "Epoch 137/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3152 - acc: 0.6214 - val_loss: 13.7400 - val_acc: 0.4504\n",
      "Epoch 138/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3270 - acc: 0.6049 - val_loss: 13.7532 - val_acc: 0.4827\n",
      "Epoch 139/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3205 - acc: 0.6167 - val_loss: 13.7075 - val_acc: 0.5149\n",
      "Epoch 140/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2896 - acc: 0.6307 - val_loss: 13.9443 - val_acc: 0.4492\n",
      "Epoch 141/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3825 - acc: 0.5949 - val_loss: 13.7143 - val_acc: 0.5579\n",
      "Epoch 142/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3332 - acc: 0.6133 - val_loss: 13.7476 - val_acc: 0.5042\n",
      "Epoch 143/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3330 - acc: 0.6090 - val_loss: 13.7695 - val_acc: 0.4898\n",
      "Epoch 144/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2935 - acc: 0.6237 - val_loss: 14.2171 - val_acc: 0.3369\n",
      "Epoch 145/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.4040 - acc: 0.5830 - val_loss: 13.7190 - val_acc: 0.4994\n",
      "Epoch 146/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2743 - acc: 0.6302 - val_loss: 13.7348 - val_acc: 0.4648\n",
      "Epoch 147/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2654 - acc: 0.6384 - val_loss: 13.7498 - val_acc: 0.4803\n",
      "Epoch 148/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2450 - acc: 0.6359 - val_loss: 13.7459 - val_acc: 0.5090\n",
      "Epoch 149/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.2635 - acc: 0.6309 - val_loss: 14.4653 - val_acc: 0.3644\n",
      "Epoch 150/150\n",
      "7003/7003 [==============================] - 3s - loss: 13.3314 - acc: 0.6189 - val_loss: 15.2992 - val_acc: 0.2820\n",
      "training time: 462.6304054260254\n",
      "800/887 [==========================>...] - ETA: 0s\n",
      "Accuracy = 0.3168\n",
      "\n",
      "Error Rate = 0.6832\n",
      "training time: 0.6755621433258057\n",
      "opening fold: 3\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8156318664550781\n",
      "Scaling time: 0.22962045669555664\n",
      "Scaling time: 0.2516350746154785\n",
      "training model...hold tight\n",
      "Train on 6965 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "6965/6965 [==============================] - 10s - loss: 15.1205 - acc: 0.1177 - val_loss: 15.0735 - val_acc: 0.1398\n",
      "Epoch 2/150\n",
      "6965/6965 [==============================] - 2s - loss: 15.0723 - acc: 0.1450 - val_loss: 15.0195 - val_acc: 0.2067\n",
      "Epoch 3/150\n",
      "6965/6965 [==============================] - 2s - loss: 15.0210 - acc: 0.1661 - val_loss: 14.9608 - val_acc: 0.1935\n",
      "Epoch 4/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.9670 - acc: 0.1874 - val_loss: 14.9053 - val_acc: 0.1924\n",
      "Epoch 5/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.9191 - acc: 0.2080 - val_loss: 14.8598 - val_acc: 0.2103\n",
      "Epoch 6/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.8759 - acc: 0.2085 - val_loss: 14.8227 - val_acc: 0.2354\n",
      "Epoch 7/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.8441 - acc: 0.2286 - val_loss: 14.7872 - val_acc: 0.2497\n",
      "Epoch 8/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.8183 - acc: 0.2469 - val_loss: 14.7515 - val_acc: 0.2640\n",
      "Epoch 9/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.7747 - acc: 0.2662 - val_loss: 14.7147 - val_acc: 0.2748\n",
      "Epoch 10/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.7336 - acc: 0.2793 - val_loss: 14.6769 - val_acc: 0.2772\n",
      "Epoch 11/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.7024 - acc: 0.2846 - val_loss: 14.6372 - val_acc: 0.2843\n",
      "Epoch 12/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.6680 - acc: 0.2915 - val_loss: 14.6049 - val_acc: 0.2772\n",
      "Epoch 13/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.6336 - acc: 0.2922 - val_loss: 14.5729 - val_acc: 0.2736\n",
      "Epoch 14/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.5938 - acc: 0.3126 - val_loss: 14.5443 - val_acc: 0.2796\n",
      "Epoch 15/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.5697 - acc: 0.3137 - val_loss: 14.5224 - val_acc: 0.2855\n",
      "Epoch 16/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.5344 - acc: 0.3328 - val_loss: 14.4974 - val_acc: 0.3011\n",
      "Epoch 17/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.5098 - acc: 0.3391 - val_loss: 14.4830 - val_acc: 0.2999\n",
      "Epoch 18/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.4796 - acc: 0.3520 - val_loss: 14.4617 - val_acc: 0.3070\n",
      "Epoch 19/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.4637 - acc: 0.3564 - val_loss: 14.4448 - val_acc: 0.3106\n",
      "Epoch 20/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.4317 - acc: 0.3664 - val_loss: 14.4274 - val_acc: 0.3190\n",
      "Epoch 21/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.4035 - acc: 0.3775 - val_loss: 14.4100 - val_acc: 0.3190\n",
      "Epoch 22/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.3896 - acc: 0.3833 - val_loss: 14.3950 - val_acc: 0.3620\n",
      "Epoch 23/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.3635 - acc: 0.3971 - val_loss: 14.3800 - val_acc: 0.3405\n",
      "Epoch 24/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.3423 - acc: 0.4069 - val_loss: 14.3713 - val_acc: 0.3441\n",
      "Epoch 25/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.3272 - acc: 0.4135 - val_loss: 14.3506 - val_acc: 0.3763\n",
      "Epoch 26/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2959 - acc: 0.4187 - val_loss: 14.3369 - val_acc: 0.3632\n",
      "Epoch 27/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2784 - acc: 0.4306 - val_loss: 14.3192 - val_acc: 0.3680\n",
      "Epoch 28/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2558 - acc: 0.4345 - val_loss: 14.3069 - val_acc: 0.3751\n",
      "Epoch 29/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2418 - acc: 0.4448 - val_loss: 14.2883 - val_acc: 0.3919\n",
      "Epoch 30/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.2187 - acc: 0.4495 - val_loss: 14.2831 - val_acc: 0.3859\n",
      "Epoch 31/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.2033 - acc: 0.4515 - val_loss: 14.2680 - val_acc: 0.4313\n",
      "Epoch 32/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1851 - acc: 0.4637 - val_loss: 14.2560 - val_acc: 0.3847\n",
      "Epoch 33/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1714 - acc: 0.4660 - val_loss: 14.2462 - val_acc: 0.3811\n",
      "Epoch 34/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1543 - acc: 0.4698 - val_loss: 14.2365 - val_acc: 0.4074\n",
      "Epoch 35/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1380 - acc: 0.4722 - val_loss: 14.2194 - val_acc: 0.4098\n",
      "Epoch 36/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.1164 - acc: 0.4788 - val_loss: 14.2099 - val_acc: 0.3931\n",
      "Epoch 37/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.1090 - acc: 0.4738 - val_loss: 14.2109 - val_acc: 0.4002\n",
      "Epoch 38/150\n",
      "6965/6965 [==============================] - 3s - loss: 14.0911 - acc: 0.4859 - val_loss: 14.1887 - val_acc: 0.4014\n",
      "Epoch 39/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0699 - acc: 0.4982 - val_loss: 14.1872 - val_acc: 0.4038\n",
      "Epoch 40/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0640 - acc: 0.4903 - val_loss: 14.1843 - val_acc: 0.4134\n",
      "Epoch 41/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0477 - acc: 0.4935 - val_loss: 14.1679 - val_acc: 0.4182\n",
      "Epoch 42/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0269 - acc: 0.5047 - val_loss: 14.1549 - val_acc: 0.4229\n",
      "Epoch 43/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0150 - acc: 0.5062 - val_loss: 14.1533 - val_acc: 0.4098\n",
      "Epoch 44/150\n",
      "6965/6965 [==============================] - 2s - loss: 14.0052 - acc: 0.5073 - val_loss: 14.1422 - val_acc: 0.4456\n",
      "Epoch 45/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9904 - acc: 0.5183 - val_loss: 14.1358 - val_acc: 0.4409\n",
      "Epoch 46/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9872 - acc: 0.5083 - val_loss: 14.1317 - val_acc: 0.4397\n",
      "Epoch 47/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9790 - acc: 0.5104 - val_loss: 14.1324 - val_acc: 0.4205\n",
      "Epoch 48/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.9618 - acc: 0.5230 - val_loss: 14.1150 - val_acc: 0.4349\n",
      "Epoch 49/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9412 - acc: 0.5269 - val_loss: 14.1162 - val_acc: 0.4146\n",
      "Epoch 50/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.9338 - acc: 0.5263 - val_loss: 14.0983 - val_acc: 0.4444\n",
      "Epoch 51/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.9214 - acc: 0.5332 - val_loss: 14.0959 - val_acc: 0.4337\n",
      "Epoch 52/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.9101 - acc: 0.5381 - val_loss: 14.0923 - val_acc: 0.4313\n",
      "Epoch 53/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8972 - acc: 0.5378 - val_loss: 14.1230 - val_acc: 0.4659\n",
      "Epoch 54/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8973 - acc: 0.5479 - val_loss: 14.0772 - val_acc: 0.4421\n",
      "Epoch 55/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8790 - acc: 0.5398 - val_loss: 14.0751 - val_acc: 0.4361\n",
      "Epoch 56/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8724 - acc: 0.5495 - val_loss: 14.0677 - val_acc: 0.4432\n",
      "Epoch 57/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8583 - acc: 0.5480 - val_loss: 14.0615 - val_acc: 0.4492\n",
      "Epoch 58/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.8502 - acc: 0.5500 - val_loss: 14.0562 - val_acc: 0.4719\n",
      "Epoch 59/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8451 - acc: 0.5531 - val_loss: 14.0390 - val_acc: 0.4624\n",
      "Epoch 60/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8242 - acc: 0.5562 - val_loss: 14.0494 - val_acc: 0.4456\n",
      "Epoch 61/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8234 - acc: 0.5578 - val_loss: 14.0483 - val_acc: 0.4755\n",
      "Epoch 62/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.8088 - acc: 0.5644 - val_loss: 14.0368 - val_acc: 0.4480\n",
      "Epoch 63/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.8003 - acc: 0.5647 - val_loss: 14.0266 - val_acc: 0.4588\n",
      "Epoch 64/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7857 - acc: 0.5697 - val_loss: 14.0196 - val_acc: 0.4779\n",
      "Epoch 65/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7831 - acc: 0.5732 - val_loss: 14.0276 - val_acc: 0.4743\n",
      "Epoch 66/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7665 - acc: 0.5803 - val_loss: 14.0355 - val_acc: 0.4815\n",
      "Epoch 67/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7658 - acc: 0.5757 - val_loss: 14.0323 - val_acc: 0.4731\n",
      "Epoch 68/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.7525 - acc: 0.5740 - val_loss: 14.0004 - val_acc: 0.4934\n",
      "Epoch 69/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7390 - acc: 0.5856 - val_loss: 14.0006 - val_acc: 0.4767\n",
      "Epoch 70/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7281 - acc: 0.5885 - val_loss: 13.9927 - val_acc: 0.4863\n",
      "Epoch 71/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7267 - acc: 0.5862 - val_loss: 13.9858 - val_acc: 0.4994\n",
      "Epoch 72/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7124 - acc: 0.5842 - val_loss: 13.9692 - val_acc: 0.5042\n",
      "Epoch 73/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.7049 - acc: 0.5911 - val_loss: 13.9687 - val_acc: 0.4803\n",
      "Epoch 74/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6951 - acc: 0.5977 - val_loss: 13.9688 - val_acc: 0.4827\n",
      "Epoch 75/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6882 - acc: 0.5990 - val_loss: 13.9731 - val_acc: 0.4767\n",
      "Epoch 76/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6759 - acc: 0.6019 - val_loss: 13.9574 - val_acc: 0.5114\n",
      "Epoch 77/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6591 - acc: 0.6065 - val_loss: 13.9507 - val_acc: 0.5114\n",
      "Epoch 78/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6565 - acc: 0.6020 - val_loss: 13.9416 - val_acc: 0.5293\n",
      "Epoch 79/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6537 - acc: 0.6020 - val_loss: 13.9471 - val_acc: 0.5173\n",
      "Epoch 80/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6319 - acc: 0.6179 - val_loss: 13.9399 - val_acc: 0.5197\n",
      "Epoch 81/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.6314 - acc: 0.6113 - val_loss: 13.9479 - val_acc: 0.5054\n",
      "Epoch 82/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6238 - acc: 0.6165 - val_loss: 13.9302 - val_acc: 0.5341\n",
      "Epoch 83/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6169 - acc: 0.6181 - val_loss: 13.9221 - val_acc: 0.5520\n",
      "Epoch 84/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.6050 - acc: 0.6205 - val_loss: 13.9228 - val_acc: 0.5209\n",
      "Epoch 85/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5910 - acc: 0.6279 - val_loss: 13.9174 - val_acc: 0.5329\n",
      "Epoch 86/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5847 - acc: 0.6291 - val_loss: 13.8991 - val_acc: 0.5735\n",
      "Epoch 87/150\n",
      "6965/6965 [==============================] - 4s - loss: 13.5725 - acc: 0.6342 - val_loss: 13.9125 - val_acc: 0.5125\n",
      "Epoch 88/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5657 - acc: 0.6370 - val_loss: 13.9022 - val_acc: 0.5173\n",
      "Epoch 89/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5521 - acc: 0.6335 - val_loss: 13.8959 - val_acc: 0.5149\n",
      "Epoch 90/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5486 - acc: 0.6332 - val_loss: 13.8948 - val_acc: 0.5735\n",
      "Epoch 91/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.5446 - acc: 0.6332 - val_loss: 13.9007 - val_acc: 0.5496\n",
      "Epoch 92/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5337 - acc: 0.6332 - val_loss: 13.8948 - val_acc: 0.5281\n",
      "Epoch 93/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5340 - acc: 0.6398 - val_loss: 13.8805 - val_acc: 0.5675\n",
      "Epoch 94/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5259 - acc: 0.6418 - val_loss: 13.8731 - val_acc: 0.5352\n",
      "Epoch 95/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.5043 - acc: 0.6439 - val_loss: 13.8654 - val_acc: 0.5687\n",
      "Epoch 96/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4957 - acc: 0.6490 - val_loss: 13.8567 - val_acc: 0.5771\n",
      "Epoch 97/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4932 - acc: 0.6472 - val_loss: 13.8657 - val_acc: 0.5412\n",
      "Epoch 98/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4803 - acc: 0.6497 - val_loss: 13.8664 - val_acc: 0.5317\n",
      "Epoch 99/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4768 - acc: 0.6564 - val_loss: 13.8426 - val_acc: 0.5783\n",
      "Epoch 100/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4675 - acc: 0.6576 - val_loss: 13.8451 - val_acc: 0.5651\n",
      "Epoch 101/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4558 - acc: 0.6607 - val_loss: 13.8653 - val_acc: 0.5579\n",
      "Epoch 102/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4601 - acc: 0.6498 - val_loss: 13.8782 - val_acc: 0.5364\n",
      "Epoch 103/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4483 - acc: 0.6538 - val_loss: 13.8274 - val_acc: 0.5771\n",
      "Epoch 104/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4342 - acc: 0.6655 - val_loss: 13.8415 - val_acc: 0.5675\n",
      "Epoch 105/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4315 - acc: 0.6625 - val_loss: 13.8122 - val_acc: 0.5878\n",
      "Epoch 106/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4147 - acc: 0.6708 - val_loss: 13.8058 - val_acc: 0.5806\n",
      "Epoch 107/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4239 - acc: 0.6653 - val_loss: 13.8317 - val_acc: 0.5783\n",
      "Epoch 108/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4066 - acc: 0.6646 - val_loss: 13.8151 - val_acc: 0.5532\n",
      "Epoch 109/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.4075 - acc: 0.6613 - val_loss: 13.8170 - val_acc: 0.5556\n",
      "Epoch 110/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3878 - acc: 0.6768 - val_loss: 13.8786 - val_acc: 0.5568\n",
      "Epoch 111/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.4116 - acc: 0.6626 - val_loss: 13.7982 - val_acc: 0.5806\n",
      "Epoch 112/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3708 - acc: 0.6770 - val_loss: 13.7929 - val_acc: 0.5902\n",
      "Epoch 113/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3748 - acc: 0.6715 - val_loss: 13.7980 - val_acc: 0.5795\n",
      "Epoch 114/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3519 - acc: 0.6866 - val_loss: 13.7788 - val_acc: 0.5902\n",
      "Epoch 115/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3457 - acc: 0.6833 - val_loss: 13.7862 - val_acc: 0.5842\n",
      "Epoch 116/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3383 - acc: 0.6872 - val_loss: 13.7684 - val_acc: 0.5842\n",
      "Epoch 117/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3275 - acc: 0.6833 - val_loss: 13.7946 - val_acc: 0.5842\n",
      "Epoch 118/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3667 - acc: 0.6764 - val_loss: 13.7518 - val_acc: 0.5914\n",
      "Epoch 119/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3237 - acc: 0.6915 - val_loss: 13.7696 - val_acc: 0.5806\n",
      "Epoch 120/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3169 - acc: 0.6828 - val_loss: 13.7586 - val_acc: 0.5890\n",
      "Epoch 121/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3078 - acc: 0.6899 - val_loss: 13.7404 - val_acc: 0.6010\n",
      "Epoch 122/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.3013 - acc: 0.6945 - val_loss: 13.7651 - val_acc: 0.5735\n",
      "Epoch 123/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.3102 - acc: 0.6860 - val_loss: 13.7687 - val_acc: 0.5830\n",
      "Epoch 124/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2835 - acc: 0.6973 - val_loss: 13.7328 - val_acc: 0.5962\n",
      "Epoch 125/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2666 - acc: 0.6994 - val_loss: 13.7319 - val_acc: 0.5926\n",
      "Epoch 126/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2597 - acc: 0.7084 - val_loss: 13.7520 - val_acc: 0.5902\n",
      "Epoch 127/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2617 - acc: 0.7034 - val_loss: 13.7290 - val_acc: 0.5986\n",
      "Epoch 128/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2712 - acc: 0.6912 - val_loss: 13.7525 - val_acc: 0.5926\n",
      "Epoch 129/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2574 - acc: 0.6962 - val_loss: 13.7429 - val_acc: 0.5938\n",
      "Epoch 130/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2436 - acc: 0.7085 - val_loss: 13.7195 - val_acc: 0.5962\n",
      "Epoch 131/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2262 - acc: 0.7091 - val_loss: 13.7443 - val_acc: 0.5890\n",
      "Epoch 132/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2200 - acc: 0.7065 - val_loss: 13.7248 - val_acc: 0.5878\n",
      "Epoch 133/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2202 - acc: 0.7088 - val_loss: 13.7107 - val_acc: 0.5974\n",
      "Epoch 134/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.2087 - acc: 0.7143 - val_loss: 13.7064 - val_acc: 0.5914\n",
      "Epoch 135/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1988 - acc: 0.7126 - val_loss: 13.6931 - val_acc: 0.5926\n",
      "Epoch 136/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2024 - acc: 0.7067 - val_loss: 13.7222 - val_acc: 0.5890\n",
      "Epoch 137/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.2176 - acc: 0.7085 - val_loss: 13.7023 - val_acc: 0.5914\n",
      "Epoch 138/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1862 - acc: 0.7173 - val_loss: 13.6828 - val_acc: 0.5938\n",
      "Epoch 139/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1705 - acc: 0.7196 - val_loss: 13.7080 - val_acc: 0.6033\n",
      "Epoch 140/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1926 - acc: 0.7118 - val_loss: 13.6979 - val_acc: 0.5902\n",
      "Epoch 141/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1741 - acc: 0.7189 - val_loss: 13.7105 - val_acc: 0.5890\n",
      "Epoch 142/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1510 - acc: 0.7215 - val_loss: 13.6652 - val_acc: 0.6033\n",
      "Epoch 143/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1445 - acc: 0.7263 - val_loss: 13.6730 - val_acc: 0.5914\n",
      "Epoch 144/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1658 - acc: 0.7166 - val_loss: 13.7003 - val_acc: 0.5962\n",
      "Epoch 145/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1363 - acc: 0.7243 - val_loss: 13.6584 - val_acc: 0.6022\n",
      "Epoch 146/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1255 - acc: 0.7268 - val_loss: 13.6522 - val_acc: 0.5938\n",
      "Epoch 147/150\n",
      "6965/6965 [==============================] - 3s - loss: 13.1148 - acc: 0.7265 - val_loss: 13.6330 - val_acc: 0.6081\n",
      "Epoch 148/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1103 - acc: 0.7275 - val_loss: 13.6663 - val_acc: 0.5962\n",
      "Epoch 149/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1221 - acc: 0.7218 - val_loss: 13.6376 - val_acc: 0.6117\n",
      "Epoch 150/150\n",
      "6965/6965 [==============================] - 2s - loss: 13.1070 - acc: 0.7235 - val_loss: 13.6339 - val_acc: 0.5974\n",
      "training time: 462.21525716781616\n",
      "925/925 [==============================] - 0s     \n",
      "\n",
      "Accuracy = 0.5070\n",
      "\n",
      "Error Rate = 0.4930\n",
      "training time: 0.8613269329071045\n",
      "opening fold: 4\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.798886775970459\n",
      "Scaling time: 0.23018622398376465\n",
      "Scaling time: 0.2700674533843994\n",
      "training model...hold tight\n",
      "Train on 6900 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "6900/6900 [==============================] - 10s - loss: 15.1219 - acc: 0.1048 - val_loss: 15.0813 - val_acc: 0.1063\n",
      "Epoch 2/150\n",
      "6900/6900 [==============================] - 2s - loss: 15.0735 - acc: 0.1281 - val_loss: 15.0335 - val_acc: 0.1278\n",
      "Epoch 3/150\n",
      "6900/6900 [==============================] - 3s - loss: 15.0369 - acc: 0.1503 - val_loss: 14.9953 - val_acc: 0.1852\n",
      "Epoch 4/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.9969 - acc: 0.1736 - val_loss: 14.9567 - val_acc: 0.2019\n",
      "Epoch 5/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.9607 - acc: 0.1899 - val_loss: 14.9161 - val_acc: 0.1947\n",
      "Epoch 6/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.9130 - acc: 0.2061 - val_loss: 14.8753 - val_acc: 0.1959\n",
      "Epoch 7/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.8766 - acc: 0.2157 - val_loss: 14.8376 - val_acc: 0.2616\n",
      "Epoch 8/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.8488 - acc: 0.2294 - val_loss: 14.8029 - val_acc: 0.2772\n",
      "Epoch 9/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.8132 - acc: 0.2407 - val_loss: 14.7702 - val_acc: 0.2796\n",
      "Epoch 10/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.7814 - acc: 0.2570 - val_loss: 14.7322 - val_acc: 0.2557\n",
      "Epoch 11/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.7473 - acc: 0.2623 - val_loss: 14.6952 - val_acc: 0.2903\n",
      "Epoch 12/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.7074 - acc: 0.2752 - val_loss: 14.6615 - val_acc: 0.2867\n",
      "Epoch 13/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.6804 - acc: 0.2851 - val_loss: 14.6267 - val_acc: 0.3011\n",
      "Epoch 14/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.6501 - acc: 0.2877 - val_loss: 14.5959 - val_acc: 0.2712\n",
      "Epoch 15/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.6080 - acc: 0.3070 - val_loss: 14.5655 - val_acc: 0.3238\n",
      "Epoch 16/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5771 - acc: 0.3128 - val_loss: 14.5393 - val_acc: 0.3596\n",
      "Epoch 17/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5494 - acc: 0.3155 - val_loss: 14.5150 - val_acc: 0.3489\n",
      "Epoch 18/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5290 - acc: 0.3245 - val_loss: 14.4923 - val_acc: 0.3668\n",
      "Epoch 19/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.5009 - acc: 0.3403 - val_loss: 14.4703 - val_acc: 0.3704\n",
      "Epoch 20/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.4692 - acc: 0.3507 - val_loss: 14.4544 - val_acc: 0.3513\n",
      "Epoch 21/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.4390 - acc: 0.3655 - val_loss: 14.4340 - val_acc: 0.3967\n",
      "Epoch 22/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.4184 - acc: 0.3748 - val_loss: 14.4115 - val_acc: 0.4170\n",
      "Epoch 23/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.3856 - acc: 0.3891 - val_loss: 14.3959 - val_acc: 0.4253\n",
      "Epoch 24/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.3811 - acc: 0.3864 - val_loss: 14.3762 - val_acc: 0.4301\n",
      "Epoch 25/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.3500 - acc: 0.4014 - val_loss: 14.3640 - val_acc: 0.4038\n",
      "Epoch 26/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.3237 - acc: 0.4114 - val_loss: 14.3511 - val_acc: 0.4265\n",
      "Epoch 27/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.3062 - acc: 0.4168 - val_loss: 14.3311 - val_acc: 0.4409\n",
      "Epoch 28/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.2879 - acc: 0.4193 - val_loss: 14.3135 - val_acc: 0.4552\n",
      "Epoch 29/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.2704 - acc: 0.4206 - val_loss: 14.3026 - val_acc: 0.4636\n",
      "Epoch 30/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.2401 - acc: 0.4384 - val_loss: 14.2843 - val_acc: 0.4385\n",
      "Epoch 31/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.2310 - acc: 0.4375 - val_loss: 14.2793 - val_acc: 0.4612\n",
      "Epoch 32/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.2089 - acc: 0.4464 - val_loss: 14.2601 - val_acc: 0.4516\n",
      "Epoch 33/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1963 - acc: 0.4520 - val_loss: 14.2489 - val_acc: 0.4755\n",
      "Epoch 34/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.1793 - acc: 0.4604 - val_loss: 14.2383 - val_acc: 0.4731\n",
      "Epoch 35/150\n",
      "6900/6900 [==============================] - 3s - loss: 14.1586 - acc: 0.4629 - val_loss: 14.2229 - val_acc: 0.4719\n",
      "Epoch 36/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1489 - acc: 0.4697 - val_loss: 14.2074 - val_acc: 0.4910\n",
      "Epoch 37/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1309 - acc: 0.4668 - val_loss: 14.2069 - val_acc: 0.4755\n",
      "Epoch 38/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.1161 - acc: 0.4754 - val_loss: 14.2011 - val_acc: 0.4576\n",
      "Epoch 39/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0884 - acc: 0.4859 - val_loss: 14.1897 - val_acc: 0.4432\n",
      "Epoch 40/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0932 - acc: 0.4713 - val_loss: 14.1830 - val_acc: 0.4504\n",
      "Epoch 41/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0796 - acc: 0.4833 - val_loss: 14.1805 - val_acc: 0.4648\n",
      "Epoch 42/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0579 - acc: 0.4878 - val_loss: 14.1688 - val_acc: 0.4683\n",
      "Epoch 43/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0470 - acc: 0.4917 - val_loss: 14.1574 - val_acc: 0.4695\n",
      "Epoch 44/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0358 - acc: 0.4930 - val_loss: 14.1434 - val_acc: 0.4719\n",
      "Epoch 45/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0241 - acc: 0.4945 - val_loss: 14.1361 - val_acc: 0.4564\n",
      "Epoch 46/150\n",
      "6900/6900 [==============================] - 2s - loss: 14.0081 - acc: 0.5023 - val_loss: 14.1357 - val_acc: 0.4875\n",
      "Epoch 47/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9904 - acc: 0.5062 - val_loss: 14.1284 - val_acc: 0.4875\n",
      "Epoch 48/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9833 - acc: 0.5033 - val_loss: 14.1147 - val_acc: 0.4683\n",
      "Epoch 49/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9755 - acc: 0.5046 - val_loss: 14.1075 - val_acc: 0.4946\n",
      "Epoch 50/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9687 - acc: 0.5017 - val_loss: 14.1036 - val_acc: 0.4612\n",
      "Epoch 51/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9545 - acc: 0.5103 - val_loss: 14.0959 - val_acc: 0.4934\n",
      "Epoch 52/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.9347 - acc: 0.5174 - val_loss: 14.0891 - val_acc: 0.4636\n",
      "Epoch 53/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.9277 - acc: 0.5214 - val_loss: 14.0822 - val_acc: 0.4564\n",
      "Epoch 54/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9121 - acc: 0.5184 - val_loss: 14.0749 - val_acc: 0.4636\n",
      "Epoch 55/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.9144 - acc: 0.5168 - val_loss: 14.0786 - val_acc: 0.4612\n",
      "Epoch 56/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.8966 - acc: 0.5300 - val_loss: 14.0579 - val_acc: 0.4779\n",
      "Epoch 57/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8863 - acc: 0.5294 - val_loss: 14.0600 - val_acc: 0.4528\n",
      "Epoch 58/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8730 - acc: 0.5348 - val_loss: 14.0445 - val_acc: 0.5066\n",
      "Epoch 59/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8651 - acc: 0.5383 - val_loss: 14.0406 - val_acc: 0.5221\n",
      "Epoch 60/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8562 - acc: 0.5400 - val_loss: 14.0425 - val_acc: 0.4743\n",
      "Epoch 61/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8443 - acc: 0.5372 - val_loss: 14.0319 - val_acc: 0.5030\n",
      "Epoch 62/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.8407 - acc: 0.5355 - val_loss: 14.0271 - val_acc: 0.5054\n",
      "Epoch 63/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.8174 - acc: 0.5488 - val_loss: 14.0284 - val_acc: 0.5114\n",
      "Epoch 64/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.8200 - acc: 0.5464 - val_loss: 14.0245 - val_acc: 0.5209\n",
      "Epoch 65/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.8029 - acc: 0.5597 - val_loss: 14.0078 - val_acc: 0.5114\n",
      "Epoch 66/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.7977 - acc: 0.5564 - val_loss: 13.9980 - val_acc: 0.5257\n",
      "Epoch 67/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7870 - acc: 0.5577 - val_loss: 14.0013 - val_acc: 0.4863\n",
      "Epoch 68/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7734 - acc: 0.5635 - val_loss: 13.9930 - val_acc: 0.5257\n",
      "Epoch 69/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7791 - acc: 0.5548 - val_loss: 13.9846 - val_acc: 0.4994\n",
      "Epoch 70/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.7635 - acc: 0.5590 - val_loss: 13.9704 - val_acc: 0.5221\n",
      "Epoch 71/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.7532 - acc: 0.5699 - val_loss: 13.9655 - val_acc: 0.5257\n",
      "Epoch 72/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.7399 - acc: 0.5687 - val_loss: 13.9662 - val_acc: 0.5460\n",
      "Epoch 73/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.7350 - acc: 0.5710 - val_loss: 13.9635 - val_acc: 0.4863\n",
      "Epoch 74/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7217 - acc: 0.5733 - val_loss: 13.9527 - val_acc: 0.5412\n",
      "Epoch 75/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7173 - acc: 0.5709 - val_loss: 13.9504 - val_acc: 0.5281\n",
      "Epoch 76/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.7031 - acc: 0.5777 - val_loss: 13.9432 - val_acc: 0.5149\n",
      "Epoch 77/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.6887 - acc: 0.5842 - val_loss: 13.9399 - val_acc: 0.5293\n",
      "Epoch 78/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6807 - acc: 0.5871 - val_loss: 13.9374 - val_acc: 0.5364\n",
      "Epoch 79/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6765 - acc: 0.5904 - val_loss: 13.9312 - val_acc: 0.5281\n",
      "Epoch 80/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6697 - acc: 0.5884 - val_loss: 13.9238 - val_acc: 0.5269\n",
      "Epoch 81/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6640 - acc: 0.5897 - val_loss: 13.9231 - val_acc: 0.5376\n",
      "Epoch 82/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6514 - acc: 0.5957 - val_loss: 13.9273 - val_acc: 0.5185\n",
      "Epoch 83/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6425 - acc: 0.5903 - val_loss: 13.9102 - val_acc: 0.5460\n",
      "Epoch 84/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.6297 - acc: 0.6017 - val_loss: 13.8985 - val_acc: 0.5496\n",
      "Epoch 85/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6265 - acc: 0.6026 - val_loss: 13.8919 - val_acc: 0.5579\n",
      "Epoch 86/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6148 - acc: 0.6055 - val_loss: 13.8835 - val_acc: 0.5424\n",
      "Epoch 87/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.6082 - acc: 0.6084 - val_loss: 13.8808 - val_acc: 0.5544\n",
      "Epoch 88/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.6068 - acc: 0.6078 - val_loss: 13.8903 - val_acc: 0.5352\n",
      "Epoch 89/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5868 - acc: 0.6097 - val_loss: 13.8730 - val_acc: 0.5412\n",
      "Epoch 90/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5793 - acc: 0.6186 - val_loss: 13.8860 - val_acc: 0.5460\n",
      "Epoch 91/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5727 - acc: 0.6167 - val_loss: 13.8693 - val_acc: 0.5711\n",
      "Epoch 92/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5618 - acc: 0.6220 - val_loss: 13.8558 - val_acc: 0.5842\n",
      "Epoch 93/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5608 - acc: 0.6188 - val_loss: 13.8547 - val_acc: 0.5711\n",
      "Epoch 94/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5405 - acc: 0.6232 - val_loss: 13.8401 - val_acc: 0.5986\n",
      "Epoch 95/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5306 - acc: 0.6290 - val_loss: 13.8515 - val_acc: 0.5579\n",
      "Epoch 96/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.5264 - acc: 0.6312 - val_loss: 13.8540 - val_acc: 0.5842\n",
      "Epoch 97/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5246 - acc: 0.6286 - val_loss: 13.8336 - val_acc: 0.5974\n",
      "Epoch 98/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.5086 - acc: 0.6358 - val_loss: 13.8583 - val_acc: 0.5460\n",
      "Epoch 99/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.4961 - acc: 0.6422 - val_loss: 13.8385 - val_acc: 0.5830\n",
      "Epoch 100/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4962 - acc: 0.6396 - val_loss: 13.8353 - val_acc: 0.5269\n",
      "Epoch 101/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.4873 - acc: 0.6367 - val_loss: 13.8126 - val_acc: 0.5974\n",
      "Epoch 102/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.4748 - acc: 0.6442 - val_loss: 13.8431 - val_acc: 0.5651\n",
      "Epoch 103/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4724 - acc: 0.6406 - val_loss: 13.8148 - val_acc: 0.5699\n",
      "Epoch 104/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4593 - acc: 0.6487 - val_loss: 13.7980 - val_acc: 0.5974\n",
      "Epoch 105/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4555 - acc: 0.6467 - val_loss: 13.8038 - val_acc: 0.5938\n",
      "Epoch 106/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.4403 - acc: 0.6510 - val_loss: 13.8042 - val_acc: 0.5818\n",
      "Epoch 107/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.4354 - acc: 0.6496 - val_loss: 13.8101 - val_acc: 0.5890\n",
      "Epoch 108/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4292 - acc: 0.6487 - val_loss: 13.7824 - val_acc: 0.5998\n",
      "Epoch 109/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4185 - acc: 0.6535 - val_loss: 13.7808 - val_acc: 0.5950\n",
      "Epoch 110/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4075 - acc: 0.6590 - val_loss: 13.7827 - val_acc: 0.5962\n",
      "Epoch 111/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4156 - acc: 0.6522 - val_loss: 13.7585 - val_acc: 0.6093\n",
      "Epoch 112/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.4040 - acc: 0.6578 - val_loss: 13.7847 - val_acc: 0.6022\n",
      "Epoch 113/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3924 - acc: 0.6577 - val_loss: 13.7589 - val_acc: 0.6081\n",
      "Epoch 114/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3814 - acc: 0.6622 - val_loss: 13.7479 - val_acc: 0.6165\n",
      "Epoch 115/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3724 - acc: 0.6614 - val_loss: 13.7468 - val_acc: 0.6141\n",
      "Epoch 116/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3722 - acc: 0.6629 - val_loss: 13.7590 - val_acc: 0.6069\n",
      "Epoch 117/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3614 - acc: 0.6648 - val_loss: 13.7378 - val_acc: 0.6057\n",
      "Epoch 118/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3545 - acc: 0.6699 - val_loss: 13.7752 - val_acc: 0.5974\n",
      "Epoch 119/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3468 - acc: 0.6765 - val_loss: 13.7371 - val_acc: 0.6010\n",
      "Epoch 120/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3439 - acc: 0.6696 - val_loss: 13.7329 - val_acc: 0.5783\n",
      "Epoch 121/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3259 - acc: 0.6717 - val_loss: 13.7170 - val_acc: 0.6129\n",
      "Epoch 122/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.3282 - acc: 0.6733 - val_loss: 13.7430 - val_acc: 0.6022\n",
      "Epoch 123/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.3183 - acc: 0.6767 - val_loss: 13.7261 - val_acc: 0.5890\n",
      "Epoch 124/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.3110 - acc: 0.6770 - val_loss: 13.7249 - val_acc: 0.6081\n",
      "Epoch 125/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2968 - acc: 0.6841 - val_loss: 13.7102 - val_acc: 0.6165\n",
      "Epoch 126/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2983 - acc: 0.6787 - val_loss: 13.7009 - val_acc: 0.6093\n",
      "Epoch 127/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2837 - acc: 0.6835 - val_loss: 13.7012 - val_acc: 0.5986\n",
      "Epoch 128/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2727 - acc: 0.6838 - val_loss: 13.6936 - val_acc: 0.6153\n",
      "Epoch 129/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2740 - acc: 0.6857 - val_loss: 13.7040 - val_acc: 0.6033\n",
      "Epoch 130/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2708 - acc: 0.6810 - val_loss: 13.6801 - val_acc: 0.6153\n",
      "Epoch 131/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2617 - acc: 0.6843 - val_loss: 13.6850 - val_acc: 0.6177\n",
      "Epoch 132/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2473 - acc: 0.6904 - val_loss: 13.6813 - val_acc: 0.6153\n",
      "Epoch 133/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2669 - acc: 0.6870 - val_loss: 13.7005 - val_acc: 0.5830\n",
      "Epoch 134/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2456 - acc: 0.6886 - val_loss: 13.6800 - val_acc: 0.6022\n",
      "Epoch 135/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2326 - acc: 0.6957 - val_loss: 13.6665 - val_acc: 0.6117\n",
      "Epoch 136/150\n",
      "6900/6900 [==============================] - 4s - loss: 13.2288 - acc: 0.6962 - val_loss: 13.6767 - val_acc: 0.6093\n",
      "Epoch 137/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.2116 - acc: 0.6945 - val_loss: 13.6849 - val_acc: 0.6057\n",
      "Epoch 138/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2102 - acc: 0.6909 - val_loss: 13.6841 - val_acc: 0.6069\n",
      "Epoch 139/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.2352 - acc: 0.6842 - val_loss: 13.6700 - val_acc: 0.6010\n",
      "Epoch 140/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1981 - acc: 0.6933 - val_loss: 13.6744 - val_acc: 0.6057\n",
      "Epoch 141/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1896 - acc: 0.7012 - val_loss: 13.6706 - val_acc: 0.5974\n",
      "Epoch 142/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1794 - acc: 0.7029 - val_loss: 13.6327 - val_acc: 0.6225\n",
      "Epoch 143/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1805 - acc: 0.6981 - val_loss: 13.6544 - val_acc: 0.6093\n",
      "Epoch 144/150\n",
      "6900/6900 [==============================] - 3s - loss: 13.1767 - acc: 0.6978 - val_loss: 13.6382 - val_acc: 0.6201\n",
      "Epoch 145/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1591 - acc: 0.7035 - val_loss: 13.6459 - val_acc: 0.6105\n",
      "Epoch 146/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1445 - acc: 0.7130 - val_loss: 13.6360 - val_acc: 0.6177\n",
      "Epoch 147/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1460 - acc: 0.7125 - val_loss: 13.6302 - val_acc: 0.6081\n",
      "Epoch 148/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1370 - acc: 0.7114 - val_loss: 13.6126 - val_acc: 0.6296\n",
      "Epoch 149/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1351 - acc: 0.7161 - val_loss: 13.6781 - val_acc: 0.6033\n",
      "Epoch 150/150\n",
      "6900/6900 [==============================] - 2s - loss: 13.1478 - acc: 0.7028 - val_loss: 13.6155 - val_acc: 0.6272\n",
      "training time: 465.7360270023346\n",
      "928/990 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.6212\n",
      "\n",
      "Error Rate = 0.3788\n",
      "training time: 0.7543373107910156\n",
      "opening fold: 5\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8191912174224854\n",
      "Scaling time: 0.22964739799499512\n",
      "Scaling time: 0.2621266841888428\n",
      "training model...hold tight\n",
      "Train on 6954 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "6954/6954 [==============================] - 10s - loss: 15.1193 - acc: 0.1047 - val_loss: 15.0563 - val_acc: 0.1864\n",
      "Epoch 2/150\n",
      "6954/6954 [==============================] - 2s - loss: 15.0643 - acc: 0.1497 - val_loss: 14.9970 - val_acc: 0.2557\n",
      "Epoch 3/150\n",
      "6954/6954 [==============================] - 3s - loss: 15.0030 - acc: 0.1750 - val_loss: 14.9416 - val_acc: 0.2557\n",
      "Epoch 4/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.9490 - acc: 0.1944 - val_loss: 14.8907 - val_acc: 0.2055\n",
      "Epoch 5/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.8967 - acc: 0.2036 - val_loss: 14.8471 - val_acc: 0.2234\n",
      "Epoch 6/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.8535 - acc: 0.2284 - val_loss: 14.8069 - val_acc: 0.2294\n",
      "Epoch 7/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.8099 - acc: 0.2494 - val_loss: 14.7656 - val_acc: 0.2437\n",
      "Epoch 8/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.7691 - acc: 0.2669 - val_loss: 14.7257 - val_acc: 0.2700\n",
      "Epoch 9/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.7175 - acc: 0.2827 - val_loss: 14.6848 - val_acc: 0.2796\n",
      "Epoch 10/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.6847 - acc: 0.2833 - val_loss: 14.6469 - val_acc: 0.2820\n",
      "Epoch 11/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.6439 - acc: 0.2998 - val_loss: 14.6135 - val_acc: 0.3047\n",
      "Epoch 12/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.6044 - acc: 0.3016 - val_loss: 14.5853 - val_acc: 0.3214\n",
      "Epoch 13/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.5723 - acc: 0.3225 - val_loss: 14.5576 - val_acc: 0.3238\n",
      "Epoch 14/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.5413 - acc: 0.3253 - val_loss: 14.5350 - val_acc: 0.2999\n",
      "Epoch 15/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.5125 - acc: 0.3422 - val_loss: 14.5168 - val_acc: 0.3094\n",
      "Epoch 16/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.4810 - acc: 0.3592 - val_loss: 14.4932 - val_acc: 0.3465\n",
      "Epoch 17/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.4592 - acc: 0.3645 - val_loss: 14.4740 - val_acc: 0.3524\n",
      "Epoch 18/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.4391 - acc: 0.3657 - val_loss: 14.4590 - val_acc: 0.3357\n",
      "Epoch 19/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.4071 - acc: 0.3819 - val_loss: 14.4394 - val_acc: 0.3369\n",
      "Epoch 20/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.3812 - acc: 0.3920 - val_loss: 14.4230 - val_acc: 0.3524\n",
      "Epoch 21/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.3581 - acc: 0.3966 - val_loss: 14.4033 - val_acc: 0.3728\n",
      "Epoch 22/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.3282 - acc: 0.4208 - val_loss: 14.3875 - val_acc: 0.3883\n",
      "Epoch 23/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.3020 - acc: 0.4285 - val_loss: 14.3732 - val_acc: 0.3847\n",
      "Epoch 24/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.2957 - acc: 0.4259 - val_loss: 14.3597 - val_acc: 0.3728\n",
      "Epoch 25/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.2652 - acc: 0.4423 - val_loss: 14.3456 - val_acc: 0.3955\n",
      "Epoch 26/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.2450 - acc: 0.4464 - val_loss: 14.3295 - val_acc: 0.4038\n",
      "Epoch 27/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.2325 - acc: 0.4502 - val_loss: 14.3134 - val_acc: 0.4134\n",
      "Epoch 28/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.2127 - acc: 0.4530 - val_loss: 14.3087 - val_acc: 0.3823\n",
      "Epoch 29/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1832 - acc: 0.4632 - val_loss: 14.2982 - val_acc: 0.3692\n",
      "Epoch 30/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1797 - acc: 0.4684 - val_loss: 14.2762 - val_acc: 0.4062\n",
      "Epoch 31/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.1544 - acc: 0.4689 - val_loss: 14.2698 - val_acc: 0.3740\n",
      "Epoch 32/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.1389 - acc: 0.4783 - val_loss: 14.2541 - val_acc: 0.4110\n",
      "Epoch 33/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.1197 - acc: 0.4842 - val_loss: 14.2498 - val_acc: 0.3835\n",
      "Epoch 34/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.1081 - acc: 0.4813 - val_loss: 14.2389 - val_acc: 0.3907\n",
      "Epoch 35/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0896 - acc: 0.4918 - val_loss: 14.2315 - val_acc: 0.4146\n",
      "Epoch 36/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.0869 - acc: 0.4868 - val_loss: 14.2231 - val_acc: 0.4182\n",
      "Epoch 37/150\n",
      "6954/6954 [==============================] - 2s - loss: 14.0743 - acc: 0.4895 - val_loss: 14.2193 - val_acc: 0.3799\n",
      "Epoch 38/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0587 - acc: 0.5027 - val_loss: 14.2049 - val_acc: 0.4170\n",
      "Epoch 39/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0437 - acc: 0.4974 - val_loss: 14.1953 - val_acc: 0.4182\n",
      "Epoch 40/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0279 - acc: 0.5112 - val_loss: 14.1896 - val_acc: 0.4062\n",
      "Epoch 41/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0197 - acc: 0.5037 - val_loss: 14.1830 - val_acc: 0.4146\n",
      "Epoch 42/150\n",
      "6954/6954 [==============================] - 3s - loss: 14.0078 - acc: 0.5047 - val_loss: 14.1689 - val_acc: 0.4170\n",
      "Epoch 43/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9916 - acc: 0.5147 - val_loss: 14.1651 - val_acc: 0.4002\n",
      "Epoch 44/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9832 - acc: 0.5180 - val_loss: 14.1525 - val_acc: 0.4552\n",
      "Epoch 45/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9692 - acc: 0.5255 - val_loss: 14.1495 - val_acc: 0.4528\n",
      "Epoch 46/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9545 - acc: 0.5249 - val_loss: 14.1484 - val_acc: 0.4074\n",
      "Epoch 47/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9451 - acc: 0.5318 - val_loss: 14.1375 - val_acc: 0.4337\n",
      "Epoch 48/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9278 - acc: 0.5292 - val_loss: 14.1350 - val_acc: 0.4421\n",
      "Epoch 49/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9281 - acc: 0.5311 - val_loss: 14.1270 - val_acc: 0.4659\n",
      "Epoch 50/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.9201 - acc: 0.5361 - val_loss: 14.1406 - val_acc: 0.4026\n",
      "Epoch 51/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.9024 - acc: 0.5362 - val_loss: 14.1203 - val_acc: 0.4158\n",
      "Epoch 52/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.8999 - acc: 0.5374 - val_loss: 14.1072 - val_acc: 0.4588\n",
      "Epoch 53/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8838 - acc: 0.5406 - val_loss: 14.0963 - val_acc: 0.4600\n",
      "Epoch 54/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8707 - acc: 0.5444 - val_loss: 14.1076 - val_acc: 0.4170\n",
      "Epoch 55/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8614 - acc: 0.5446 - val_loss: 14.0919 - val_acc: 0.4277\n",
      "Epoch 56/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.8556 - acc: 0.5510 - val_loss: 14.0867 - val_acc: 0.4385\n",
      "Epoch 57/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.8469 - acc: 0.5545 - val_loss: 14.0787 - val_acc: 0.4409\n",
      "Epoch 58/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8337 - acc: 0.5539 - val_loss: 14.0734 - val_acc: 0.4504\n",
      "Epoch 59/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8205 - acc: 0.5569 - val_loss: 14.0674 - val_acc: 0.4444\n",
      "Epoch 60/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.8161 - acc: 0.5605 - val_loss: 14.0677 - val_acc: 0.4313\n",
      "Epoch 61/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.8061 - acc: 0.5594 - val_loss: 14.0584 - val_acc: 0.4516\n",
      "Epoch 62/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7900 - acc: 0.5626 - val_loss: 14.0503 - val_acc: 0.4397\n",
      "Epoch 63/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7885 - acc: 0.5689 - val_loss: 14.0522 - val_acc: 0.4791\n",
      "Epoch 64/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7776 - acc: 0.5728 - val_loss: 14.0424 - val_acc: 0.4456\n",
      "Epoch 65/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7627 - acc: 0.5686 - val_loss: 14.0312 - val_acc: 0.4719\n",
      "Epoch 66/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7520 - acc: 0.5680 - val_loss: 14.0266 - val_acc: 0.4624\n",
      "Epoch 67/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7488 - acc: 0.5821 - val_loss: 14.0136 - val_acc: 0.5030\n",
      "Epoch 68/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7414 - acc: 0.5723 - val_loss: 14.0156 - val_acc: 0.4779\n",
      "Epoch 69/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7355 - acc: 0.5765 - val_loss: 14.0028 - val_acc: 0.4875\n",
      "Epoch 70/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7189 - acc: 0.5848 - val_loss: 14.0040 - val_acc: 0.4922\n",
      "Epoch 71/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.7054 - acc: 0.5847 - val_loss: 13.9953 - val_acc: 0.5149\n",
      "Epoch 72/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.7039 - acc: 0.5882 - val_loss: 14.0072 - val_acc: 0.4982\n",
      "Epoch 73/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6982 - acc: 0.5900 - val_loss: 13.9982 - val_acc: 0.4898\n",
      "Epoch 74/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6883 - acc: 0.5910 - val_loss: 13.9890 - val_acc: 0.4803\n",
      "Epoch 75/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6746 - acc: 0.5910 - val_loss: 13.9799 - val_acc: 0.4910\n",
      "Epoch 76/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6551 - acc: 0.6061 - val_loss: 13.9735 - val_acc: 0.4946\n",
      "Epoch 77/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6543 - acc: 0.5994 - val_loss: 13.9683 - val_acc: 0.4803\n",
      "Epoch 78/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6403 - acc: 0.6044 - val_loss: 13.9672 - val_acc: 0.5054\n",
      "Epoch 79/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6381 - acc: 0.6071 - val_loss: 13.9498 - val_acc: 0.5185\n",
      "Epoch 80/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.6260 - acc: 0.6110 - val_loss: 13.9637 - val_acc: 0.4970\n",
      "Epoch 81/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6182 - acc: 0.6119 - val_loss: 13.9454 - val_acc: 0.5125\n",
      "Epoch 82/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.6112 - acc: 0.6110 - val_loss: 13.9495 - val_acc: 0.5042\n",
      "Epoch 83/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5972 - acc: 0.6166 - val_loss: 13.9444 - val_acc: 0.5006\n",
      "Epoch 84/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5991 - acc: 0.6077 - val_loss: 13.9358 - val_acc: 0.5185\n",
      "Epoch 85/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5798 - acc: 0.6194 - val_loss: 13.9415 - val_acc: 0.5161\n",
      "Epoch 86/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.5803 - acc: 0.6186 - val_loss: 13.9386 - val_acc: 0.5054\n",
      "Epoch 87/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5657 - acc: 0.6215 - val_loss: 13.9270 - val_acc: 0.5114\n",
      "Epoch 88/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5590 - acc: 0.6274 - val_loss: 13.9151 - val_acc: 0.5424\n",
      "Epoch 89/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5437 - acc: 0.6286 - val_loss: 13.9097 - val_acc: 0.5161\n",
      "Epoch 90/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5451 - acc: 0.6253 - val_loss: 13.9091 - val_acc: 0.5125\n",
      "Epoch 91/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5265 - acc: 0.6323 - val_loss: 13.8984 - val_acc: 0.5412\n",
      "Epoch 92/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5317 - acc: 0.6283 - val_loss: 13.9112 - val_acc: 0.5579\n",
      "Epoch 93/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5159 - acc: 0.6366 - val_loss: 13.9121 - val_acc: 0.5102\n",
      "Epoch 94/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.5033 - acc: 0.6408 - val_loss: 13.8955 - val_acc: 0.5568\n",
      "Epoch 95/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4997 - acc: 0.6404 - val_loss: 13.8879 - val_acc: 0.5197\n",
      "Epoch 96/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4886 - acc: 0.6395 - val_loss: 13.8997 - val_acc: 0.5090\n",
      "Epoch 97/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4809 - acc: 0.6441 - val_loss: 13.8818 - val_acc: 0.5544\n",
      "Epoch 98/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4754 - acc: 0.6411 - val_loss: 13.8601 - val_acc: 0.5818\n",
      "Epoch 99/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4712 - acc: 0.6514 - val_loss: 13.8724 - val_acc: 0.5388\n",
      "Epoch 100/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4599 - acc: 0.6460 - val_loss: 13.8569 - val_acc: 0.5902\n",
      "Epoch 101/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4448 - acc: 0.6562 - val_loss: 13.8676 - val_acc: 0.5293\n",
      "Epoch 102/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4449 - acc: 0.6473 - val_loss: 13.8662 - val_acc: 0.5400\n",
      "Epoch 103/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.4289 - acc: 0.6549 - val_loss: 13.8437 - val_acc: 0.5747\n",
      "Epoch 104/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4289 - acc: 0.6563 - val_loss: 13.8502 - val_acc: 0.5317\n",
      "Epoch 105/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4256 - acc: 0.6553 - val_loss: 13.8567 - val_acc: 0.5221\n",
      "Epoch 106/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4103 - acc: 0.6609 - val_loss: 13.8237 - val_acc: 0.5998\n",
      "Epoch 107/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.4032 - acc: 0.6590 - val_loss: 13.8474 - val_acc: 0.5209\n",
      "Epoch 108/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3890 - acc: 0.6622 - val_loss: 13.8331 - val_acc: 0.5890\n",
      "Epoch 109/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3926 - acc: 0.6605 - val_loss: 13.8256 - val_acc: 0.5723\n",
      "Epoch 110/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3828 - acc: 0.6678 - val_loss: 13.8374 - val_acc: 0.5902\n",
      "Epoch 111/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3732 - acc: 0.6678 - val_loss: 13.8181 - val_acc: 0.5603\n",
      "Epoch 112/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3678 - acc: 0.6697 - val_loss: 13.8659 - val_acc: 0.5747\n",
      "Epoch 113/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3685 - acc: 0.6674 - val_loss: 13.8187 - val_acc: 0.5818\n",
      "Epoch 114/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3508 - acc: 0.6747 - val_loss: 13.8075 - val_acc: 0.5890\n",
      "Epoch 115/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3399 - acc: 0.6718 - val_loss: 13.8135 - val_acc: 0.5986\n",
      "Epoch 116/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3375 - acc: 0.6746 - val_loss: 13.8157 - val_acc: 0.5806\n",
      "Epoch 117/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3324 - acc: 0.6790 - val_loss: 13.7831 - val_acc: 0.5926\n",
      "Epoch 118/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.3197 - acc: 0.6806 - val_loss: 13.7832 - val_acc: 0.5771\n",
      "Epoch 119/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3179 - acc: 0.6800 - val_loss: 13.7900 - val_acc: 0.6045\n",
      "Epoch 120/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3059 - acc: 0.6831 - val_loss: 13.7921 - val_acc: 0.5878\n",
      "Epoch 121/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.3067 - acc: 0.6792 - val_loss: 13.7739 - val_acc: 0.5914\n",
      "Epoch 122/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2886 - acc: 0.6856 - val_loss: 13.7610 - val_acc: 0.6045\n",
      "Epoch 123/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2973 - acc: 0.6841 - val_loss: 13.7797 - val_acc: 0.6022\n",
      "Epoch 124/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2769 - acc: 0.6871 - val_loss: 13.7672 - val_acc: 0.5926\n",
      "Epoch 125/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2703 - acc: 0.6846 - val_loss: 13.7646 - val_acc: 0.6057\n",
      "Epoch 126/150\n",
      "6954/6954 [==============================] - 4s - loss: 13.2538 - acc: 0.6923 - val_loss: 13.7531 - val_acc: 0.5998\n",
      "Epoch 127/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2573 - acc: 0.6884 - val_loss: 13.7594 - val_acc: 0.5890\n",
      "Epoch 128/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2639 - acc: 0.6858 - val_loss: 13.7726 - val_acc: 0.6069\n",
      "Epoch 129/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2360 - acc: 0.6976 - val_loss: 13.7436 - val_acc: 0.5962\n",
      "Epoch 130/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2280 - acc: 0.6982 - val_loss: 13.7954 - val_acc: 0.5950\n",
      "Epoch 131/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.2572 - acc: 0.6859 - val_loss: 13.7372 - val_acc: 0.6117\n",
      "Epoch 132/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2317 - acc: 0.6849 - val_loss: 13.7446 - val_acc: 0.5735\n",
      "Epoch 133/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2182 - acc: 0.6983 - val_loss: 13.7605 - val_acc: 0.5998\n",
      "Epoch 134/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2171 - acc: 0.6949 - val_loss: 13.7762 - val_acc: 0.5986\n",
      "Epoch 135/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.2031 - acc: 0.6989 - val_loss: 13.7044 - val_acc: 0.6129\n",
      "Epoch 136/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1927 - acc: 0.7068 - val_loss: 13.7149 - val_acc: 0.6057\n",
      "Epoch 137/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1925 - acc: 0.7064 - val_loss: 13.7333 - val_acc: 0.6093\n",
      "Epoch 138/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1808 - acc: 0.7078 - val_loss: 13.7175 - val_acc: 0.6129\n",
      "Epoch 139/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1755 - acc: 0.7074 - val_loss: 13.7329 - val_acc: 0.6189\n",
      "Epoch 140/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1707 - acc: 0.7062 - val_loss: 13.7134 - val_acc: 0.6093\n",
      "Epoch 141/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1883 - acc: 0.6961 - val_loss: 13.7506 - val_acc: 0.5938\n",
      "Epoch 142/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1649 - acc: 0.7035 - val_loss: 13.7046 - val_acc: 0.6153\n",
      "Epoch 143/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1387 - acc: 0.7140 - val_loss: 13.6933 - val_acc: 0.6081\n",
      "Epoch 144/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1331 - acc: 0.7158 - val_loss: 13.7145 - val_acc: 0.6069\n",
      "Epoch 145/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1514 - acc: 0.7072 - val_loss: 13.7581 - val_acc: 0.5902\n",
      "Epoch 146/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1629 - acc: 0.7023 - val_loss: 13.7138 - val_acc: 0.6033\n",
      "Epoch 147/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1193 - acc: 0.7180 - val_loss: 13.6791 - val_acc: 0.6141\n",
      "Epoch 148/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1160 - acc: 0.7098 - val_loss: 13.7031 - val_acc: 0.6117\n",
      "Epoch 149/150\n",
      "6954/6954 [==============================] - 2s - loss: 13.1108 - acc: 0.7143 - val_loss: 13.6902 - val_acc: 0.6117\n",
      "Epoch 150/150\n",
      "6954/6954 [==============================] - 3s - loss: 13.1053 - acc: 0.7189 - val_loss: 13.6899 - val_acc: 0.6177\n",
      "training time: 468.64045572280884\n",
      "928/936 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.5994\n",
      "\n",
      "Error Rate = 0.4006\n",
      "training time: 0.7617785930633545\n",
      "opening fold: 6\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8498468399047852\n",
      "Scaling time: 0.22745633125305176\n",
      "Scaling time: 0.22518277168273926\n",
      "training model...hold tight\n",
      "Train on 7067 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7067/7067 [==============================] - 9s - loss: 15.1283 - acc: 0.1080 - val_loss: 15.0711 - val_acc: 0.1756\n",
      "Epoch 2/150\n",
      "7067/7067 [==============================] - 3s - loss: 15.0719 - acc: 0.1373 - val_loss: 15.0107 - val_acc: 0.1912\n",
      "Epoch 3/150\n",
      "7067/7067 [==============================] - 3s - loss: 15.0190 - acc: 0.1736 - val_loss: 14.9569 - val_acc: 0.1876\n",
      "Epoch 4/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.9640 - acc: 0.2014 - val_loss: 14.8969 - val_acc: 0.2151\n",
      "Epoch 5/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.9104 - acc: 0.2108 - val_loss: 14.8441 - val_acc: 0.2640\n",
      "Epoch 6/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.8621 - acc: 0.2278 - val_loss: 14.7915 - val_acc: 0.2378\n",
      "Epoch 7/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.8195 - acc: 0.2496 - val_loss: 14.7411 - val_acc: 0.2748\n",
      "Epoch 8/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.7678 - acc: 0.2551 - val_loss: 14.6916 - val_acc: 0.2808\n",
      "Epoch 9/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.7279 - acc: 0.2782 - val_loss: 14.6448 - val_acc: 0.3214\n",
      "Epoch 10/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.6840 - acc: 0.2873 - val_loss: 14.6094 - val_acc: 0.3274\n",
      "Epoch 11/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.6436 - acc: 0.2925 - val_loss: 14.5740 - val_acc: 0.3142\n",
      "Epoch 12/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.6108 - acc: 0.3045 - val_loss: 14.5399 - val_acc: 0.3082\n",
      "Epoch 13/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.5751 - acc: 0.3090 - val_loss: 14.5146 - val_acc: 0.3011\n",
      "Epoch 14/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.5469 - acc: 0.3257 - val_loss: 14.4960 - val_acc: 0.3680\n",
      "Epoch 15/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.5214 - acc: 0.3276 - val_loss: 14.4672 - val_acc: 0.3501\n",
      "Epoch 16/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.4910 - acc: 0.3382 - val_loss: 14.4392 - val_acc: 0.3883\n",
      "Epoch 17/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.4505 - acc: 0.3581 - val_loss: 14.4272 - val_acc: 0.3955\n",
      "Epoch 18/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.4346 - acc: 0.3601 - val_loss: 14.4035 - val_acc: 0.3644\n",
      "Epoch 19/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3972 - acc: 0.3707 - val_loss: 14.3914 - val_acc: 0.4265\n",
      "Epoch 20/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3773 - acc: 0.3857 - val_loss: 14.3661 - val_acc: 0.4289\n",
      "Epoch 21/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3410 - acc: 0.4055 - val_loss: 14.3648 - val_acc: 0.4516\n",
      "Epoch 22/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3252 - acc: 0.4041 - val_loss: 14.3463 - val_acc: 0.4194\n",
      "Epoch 23/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.3046 - acc: 0.4203 - val_loss: 14.3226 - val_acc: 0.4385\n",
      "Epoch 24/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2744 - acc: 0.4280 - val_loss: 14.2950 - val_acc: 0.4648\n",
      "Epoch 25/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2587 - acc: 0.4313 - val_loss: 14.2873 - val_acc: 0.4229\n",
      "Epoch 26/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2411 - acc: 0.4439 - val_loss: 14.2742 - val_acc: 0.3907\n",
      "Epoch 27/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.2231 - acc: 0.4399 - val_loss: 14.2689 - val_acc: 0.4552\n",
      "Epoch 28/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1986 - acc: 0.4508 - val_loss: 14.2468 - val_acc: 0.4480\n",
      "Epoch 29/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1835 - acc: 0.4484 - val_loss: 14.2544 - val_acc: 0.4194\n",
      "Epoch 30/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1759 - acc: 0.4541 - val_loss: 14.2327 - val_acc: 0.3763\n",
      "Epoch 31/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1456 - acc: 0.4664 - val_loss: 14.2618 - val_acc: 0.4480\n",
      "Epoch 32/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1368 - acc: 0.4617 - val_loss: 14.2240 - val_acc: 0.4588\n",
      "Epoch 33/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1181 - acc: 0.4749 - val_loss: 14.1809 - val_acc: 0.4552\n",
      "Epoch 34/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.1033 - acc: 0.4743 - val_loss: 14.1834 - val_acc: 0.4146\n",
      "Epoch 35/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0808 - acc: 0.4813 - val_loss: 14.1557 - val_acc: 0.5281\n",
      "Epoch 36/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0729 - acc: 0.4889 - val_loss: 14.1455 - val_acc: 0.5185\n",
      "Epoch 37/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0479 - acc: 0.4923 - val_loss: 14.1645 - val_acc: 0.4576\n",
      "Epoch 38/150\n",
      "7067/7067 [==============================] - 4s - loss: 14.0368 - acc: 0.4960 - val_loss: 14.1472 - val_acc: 0.5221\n",
      "Epoch 39/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0270 - acc: 0.4936 - val_loss: 14.1698 - val_acc: 0.4659\n",
      "Epoch 40/150\n",
      "7067/7067 [==============================] - 3s - loss: 14.0103 - acc: 0.5029 - val_loss: 14.1077 - val_acc: 0.5341\n",
      "Epoch 41/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9956 - acc: 0.5073 - val_loss: 14.1092 - val_acc: 0.4719\n",
      "Epoch 42/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9888 - acc: 0.4984 - val_loss: 14.1121 - val_acc: 0.4982\n",
      "Epoch 43/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9793 - acc: 0.5094 - val_loss: 14.1087 - val_acc: 0.4552\n",
      "Epoch 44/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9629 - acc: 0.5111 - val_loss: 14.0809 - val_acc: 0.4863\n",
      "Epoch 45/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9489 - acc: 0.5169 - val_loss: 14.0872 - val_acc: 0.4385\n",
      "Epoch 46/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9382 - acc: 0.5204 - val_loss: 14.0590 - val_acc: 0.4851\n",
      "Epoch 47/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9199 - acc: 0.5186 - val_loss: 14.0567 - val_acc: 0.4612\n",
      "Epoch 48/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.9079 - acc: 0.5264 - val_loss: 14.0863 - val_acc: 0.4839\n",
      "Epoch 49/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8986 - acc: 0.5302 - val_loss: 14.0414 - val_acc: 0.5018\n",
      "Epoch 50/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8824 - acc: 0.5343 - val_loss: 14.1112 - val_acc: 0.4325\n",
      "Epoch 51/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8871 - acc: 0.5366 - val_loss: 14.0377 - val_acc: 0.5137\n",
      "Epoch 52/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8673 - acc: 0.5339 - val_loss: 14.0227 - val_acc: 0.4552\n",
      "Epoch 53/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8599 - acc: 0.5343 - val_loss: 14.0283 - val_acc: 0.4791\n",
      "Epoch 54/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8535 - acc: 0.5381 - val_loss: 14.0341 - val_acc: 0.4958\n",
      "Epoch 55/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8336 - acc: 0.5411 - val_loss: 14.0137 - val_acc: 0.4648\n",
      "Epoch 56/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8243 - acc: 0.5490 - val_loss: 14.0556 - val_acc: 0.4432\n",
      "Epoch 57/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8200 - acc: 0.5571 - val_loss: 14.0031 - val_acc: 0.4839\n",
      "Epoch 58/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.8014 - acc: 0.5510 - val_loss: 13.9858 - val_acc: 0.4600\n",
      "Epoch 59/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7899 - acc: 0.5637 - val_loss: 13.9764 - val_acc: 0.5472\n",
      "Epoch 60/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7859 - acc: 0.5553 - val_loss: 13.9870 - val_acc: 0.4767\n",
      "Epoch 61/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7835 - acc: 0.5611 - val_loss: 14.0037 - val_acc: 0.5090\n",
      "Epoch 62/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7636 - acc: 0.5666 - val_loss: 14.0176 - val_acc: 0.4898\n",
      "Epoch 63/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7626 - acc: 0.5701 - val_loss: 13.9796 - val_acc: 0.4731\n",
      "Epoch 64/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7434 - acc: 0.5724 - val_loss: 13.9614 - val_acc: 0.5102\n",
      "Epoch 65/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7356 - acc: 0.5742 - val_loss: 13.9618 - val_acc: 0.4707\n",
      "Epoch 66/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7249 - acc: 0.5790 - val_loss: 13.9377 - val_acc: 0.4707\n",
      "Epoch 67/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.7076 - acc: 0.5841 - val_loss: 13.9469 - val_acc: 0.4659\n",
      "Epoch 68/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6972 - acc: 0.5828 - val_loss: 13.9347 - val_acc: 0.5400\n",
      "Epoch 69/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6885 - acc: 0.5899 - val_loss: 14.0636 - val_acc: 0.4839\n",
      "Epoch 70/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6962 - acc: 0.5853 - val_loss: 13.9186 - val_acc: 0.5257\n",
      "Epoch 71/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6671 - acc: 0.5878 - val_loss: 13.9209 - val_acc: 0.5149\n",
      "Epoch 72/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6570 - acc: 0.5963 - val_loss: 13.9908 - val_acc: 0.5125\n",
      "Epoch 73/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6612 - acc: 0.5949 - val_loss: 13.9656 - val_acc: 0.4659\n",
      "Epoch 74/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6566 - acc: 0.5930 - val_loss: 13.8961 - val_acc: 0.5364\n",
      "Epoch 75/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6404 - acc: 0.5956 - val_loss: 13.9474 - val_acc: 0.4970\n",
      "Epoch 76/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6272 - acc: 0.6069 - val_loss: 13.8894 - val_acc: 0.5245\n",
      "Epoch 77/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6167 - acc: 0.6048 - val_loss: 13.9278 - val_acc: 0.4695\n",
      "Epoch 78/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.6090 - acc: 0.6093 - val_loss: 13.8845 - val_acc: 0.5950\n",
      "Epoch 79/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.6051 - acc: 0.6112 - val_loss: 13.9744 - val_acc: 0.4827\n",
      "Epoch 80/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5923 - acc: 0.6141 - val_loss: 13.8590 - val_acc: 0.5579\n",
      "Epoch 81/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5740 - acc: 0.6184 - val_loss: 13.9359 - val_acc: 0.5161\n",
      "Epoch 82/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5738 - acc: 0.6172 - val_loss: 13.8723 - val_acc: 0.5161\n",
      "Epoch 83/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5625 - acc: 0.6177 - val_loss: 13.8453 - val_acc: 0.5532\n",
      "Epoch 84/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5426 - acc: 0.6230 - val_loss: 13.9080 - val_acc: 0.5209\n",
      "Epoch 85/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5400 - acc: 0.6257 - val_loss: 13.9118 - val_acc: 0.5090\n",
      "Epoch 86/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5405 - acc: 0.6206 - val_loss: 13.8520 - val_acc: 0.5568\n",
      "Epoch 87/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5139 - acc: 0.6297 - val_loss: 13.8620 - val_acc: 0.4468\n",
      "Epoch 88/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5180 - acc: 0.6298 - val_loss: 13.8201 - val_acc: 0.5687\n",
      "Epoch 89/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5034 - acc: 0.6353 - val_loss: 13.8105 - val_acc: 0.5854\n",
      "Epoch 90/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4884 - acc: 0.6404 - val_loss: 14.0371 - val_acc: 0.4516\n",
      "Epoch 91/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.5216 - acc: 0.6246 - val_loss: 13.8199 - val_acc: 0.5938\n",
      "Epoch 92/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4844 - acc: 0.6338 - val_loss: 13.7786 - val_acc: 0.6081\n",
      "Epoch 93/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.4663 - acc: 0.6465 - val_loss: 13.7896 - val_acc: 0.5591\n",
      "Epoch 94/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4484 - acc: 0.6468 - val_loss: 13.7873 - val_acc: 0.5938\n",
      "Epoch 95/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4448 - acc: 0.6553 - val_loss: 13.8610 - val_acc: 0.5233\n",
      "Epoch 96/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4417 - acc: 0.6516 - val_loss: 13.8747 - val_acc: 0.5185\n",
      "Epoch 97/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4299 - acc: 0.6529 - val_loss: 13.7860 - val_acc: 0.5568\n",
      "Epoch 98/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4162 - acc: 0.6556 - val_loss: 13.7772 - val_acc: 0.5914\n",
      "Epoch 99/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4069 - acc: 0.6628 - val_loss: 13.8911 - val_acc: 0.5125\n",
      "Epoch 100/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.4276 - acc: 0.6447 - val_loss: 13.7510 - val_acc: 0.5890\n",
      "Epoch 101/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3933 - acc: 0.6587 - val_loss: 13.7741 - val_acc: 0.5795\n",
      "Epoch 102/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3868 - acc: 0.6649 - val_loss: 13.7797 - val_acc: 0.5412\n",
      "Epoch 103/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3750 - acc: 0.6638 - val_loss: 13.8067 - val_acc: 0.5603\n",
      "Epoch 104/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3715 - acc: 0.6639 - val_loss: 13.7414 - val_acc: 0.5974\n",
      "Epoch 105/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3575 - acc: 0.6646 - val_loss: 13.7478 - val_acc: 0.5914\n",
      "Epoch 106/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3514 - acc: 0.6687 - val_loss: 13.7323 - val_acc: 0.5866\n",
      "Epoch 107/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3418 - acc: 0.6703 - val_loss: 13.7740 - val_acc: 0.4946\n",
      "Epoch 108/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3446 - acc: 0.6750 - val_loss: 13.7195 - val_acc: 0.5950\n",
      "Epoch 109/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3276 - acc: 0.6697 - val_loss: 13.7178 - val_acc: 0.5269\n",
      "Epoch 110/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3204 - acc: 0.6707 - val_loss: 13.7094 - val_acc: 0.6141\n",
      "Epoch 111/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3096 - acc: 0.6758 - val_loss: 13.7258 - val_acc: 0.5532\n",
      "Epoch 112/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2981 - acc: 0.6811 - val_loss: 13.8275 - val_acc: 0.5484\n",
      "Epoch 113/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.3046 - acc: 0.6803 - val_loss: 13.7378 - val_acc: 0.5735\n",
      "Epoch 114/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2852 - acc: 0.6876 - val_loss: 13.7380 - val_acc: 0.5508\n",
      "Epoch 115/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2883 - acc: 0.6819 - val_loss: 13.7236 - val_acc: 0.5890\n",
      "Epoch 116/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2680 - acc: 0.6836 - val_loss: 13.7110 - val_acc: 0.5675\n",
      "Epoch 117/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2624 - acc: 0.6847 - val_loss: 13.7115 - val_acc: 0.5388\n",
      "Epoch 118/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2629 - acc: 0.6854 - val_loss: 13.6797 - val_acc: 0.5986\n",
      "Epoch 119/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2477 - acc: 0.6884 - val_loss: 13.6960 - val_acc: 0.5914\n",
      "Epoch 120/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2417 - acc: 0.6953 - val_loss: 13.6995 - val_acc: 0.5998\n",
      "Epoch 121/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2233 - acc: 0.6968 - val_loss: 13.6647 - val_acc: 0.6165\n",
      "Epoch 122/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2276 - acc: 0.6856 - val_loss: 13.6660 - val_acc: 0.5974\n",
      "Epoch 123/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2199 - acc: 0.6929 - val_loss: 13.6738 - val_acc: 0.5998\n",
      "Epoch 124/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1981 - acc: 0.7017 - val_loss: 13.6397 - val_acc: 0.5890\n",
      "Epoch 125/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.2052 - acc: 0.6996 - val_loss: 13.6486 - val_acc: 0.6069\n",
      "Epoch 126/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1880 - acc: 0.7027 - val_loss: 13.6445 - val_acc: 0.5986\n",
      "Epoch 127/150\n",
      "7067/7067 [==============================] - 4s - loss: 13.1755 - acc: 0.7048 - val_loss: 13.6693 - val_acc: 0.5591\n",
      "Epoch 128/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1726 - acc: 0.7069 - val_loss: 13.6261 - val_acc: 0.6081\n",
      "Epoch 129/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1572 - acc: 0.7068 - val_loss: 13.6742 - val_acc: 0.6093\n",
      "Epoch 130/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1691 - acc: 0.7033 - val_loss: 13.5950 - val_acc: 0.6260\n",
      "Epoch 131/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1420 - acc: 0.7095 - val_loss: 13.5998 - val_acc: 0.6189\n",
      "Epoch 132/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1486 - acc: 0.7108 - val_loss: 13.6350 - val_acc: 0.5842\n",
      "Epoch 133/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1383 - acc: 0.7119 - val_loss: 13.6406 - val_acc: 0.5496\n",
      "Epoch 134/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1270 - acc: 0.7108 - val_loss: 13.5980 - val_acc: 0.6237\n",
      "Epoch 135/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1201 - acc: 0.7120 - val_loss: 13.6103 - val_acc: 0.5878\n",
      "Epoch 136/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1181 - acc: 0.7105 - val_loss: 13.6171 - val_acc: 0.5926\n",
      "Epoch 137/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1133 - acc: 0.7062 - val_loss: 13.6019 - val_acc: 0.6105\n",
      "Epoch 138/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.1015 - acc: 0.7149 - val_loss: 13.5992 - val_acc: 0.6129\n",
      "Epoch 139/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0917 - acc: 0.7157 - val_loss: 13.6134 - val_acc: 0.5938\n",
      "Epoch 140/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0800 - acc: 0.7191 - val_loss: 13.5655 - val_acc: 0.6177\n",
      "Epoch 141/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0746 - acc: 0.7227 - val_loss: 13.5609 - val_acc: 0.6177\n",
      "Epoch 142/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0912 - acc: 0.7197 - val_loss: 13.5605 - val_acc: 0.6165\n",
      "Epoch 143/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0557 - acc: 0.7241 - val_loss: 13.5972 - val_acc: 0.6189\n",
      "Epoch 144/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0567 - acc: 0.7194 - val_loss: 13.5767 - val_acc: 0.5747\n",
      "Epoch 145/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0402 - acc: 0.7227 - val_loss: 13.6938 - val_acc: 0.5245\n",
      "Epoch 146/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0550 - acc: 0.7156 - val_loss: 13.5366 - val_acc: 0.6464\n",
      "Epoch 147/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0307 - acc: 0.7273 - val_loss: 13.5440 - val_acc: 0.6308\n",
      "Epoch 148/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0381 - acc: 0.7256 - val_loss: 13.5476 - val_acc: 0.6033\n",
      "Epoch 149/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0254 - acc: 0.7236 - val_loss: 13.6908 - val_acc: 0.5795\n",
      "Epoch 150/150\n",
      "7067/7067 [==============================] - 3s - loss: 13.0383 - acc: 0.7231 - val_loss: 13.5389 - val_acc: 0.6117\n",
      "training time: 481.2002623081207\n",
      "800/823 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.5407\n",
      "\n",
      "Error Rate = 0.4593\n",
      "training time: 0.6413257122039795\n",
      "opening fold: 7\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.837918996810913\n",
      "Scaling time: 0.2282853126525879\n",
      "Scaling time: 0.22926068305969238\n",
      "training model...hold tight\n",
      "Train on 7052 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7052/7052 [==============================] - 9s - loss: 15.1299 - acc: 0.1045 - val_loss: 15.0785 - val_acc: 0.2318\n",
      "Epoch 2/150\n",
      "7052/7052 [==============================] - 3s - loss: 15.0801 - acc: 0.1523 - val_loss: 15.0253 - val_acc: 0.2401\n",
      "Epoch 3/150\n",
      "7052/7052 [==============================] - 3s - loss: 15.0282 - acc: 0.1720 - val_loss: 14.9762 - val_acc: 0.2497\n",
      "Epoch 4/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.9824 - acc: 0.1866 - val_loss: 14.9272 - val_acc: 0.2664\n",
      "Epoch 5/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.9361 - acc: 0.2065 - val_loss: 14.8788 - val_acc: 0.2616\n",
      "Epoch 6/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.8917 - acc: 0.2059 - val_loss: 14.8350 - val_acc: 0.2700\n",
      "Epoch 7/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.8475 - acc: 0.2284 - val_loss: 14.7923 - val_acc: 0.2772\n",
      "Epoch 8/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.8033 - acc: 0.2483 - val_loss: 14.7487 - val_acc: 0.2784\n",
      "Epoch 9/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.7679 - acc: 0.2538 - val_loss: 14.7087 - val_acc: 0.2963\n",
      "Epoch 10/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.7257 - acc: 0.2744 - val_loss: 14.6699 - val_acc: 0.2605\n",
      "Epoch 11/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.6863 - acc: 0.2816 - val_loss: 14.6447 - val_acc: 0.2437\n",
      "Epoch 12/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.6544 - acc: 0.2872 - val_loss: 14.6104 - val_acc: 0.3226\n",
      "Epoch 13/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.6219 - acc: 0.2904 - val_loss: 14.5809 - val_acc: 0.2748\n",
      "Epoch 14/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5893 - acc: 0.2982 - val_loss: 14.5542 - val_acc: 0.2915\n",
      "Epoch 15/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5566 - acc: 0.3009 - val_loss: 14.5380 - val_acc: 0.3166\n",
      "Epoch 16/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5240 - acc: 0.3206 - val_loss: 14.5059 - val_acc: 0.2963\n",
      "Epoch 17/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.5005 - acc: 0.3291 - val_loss: 14.4873 - val_acc: 0.3190\n",
      "Epoch 18/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.4816 - acc: 0.3405 - val_loss: 14.4775 - val_acc: 0.3477\n",
      "Epoch 19/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.4532 - acc: 0.3471 - val_loss: 14.4456 - val_acc: 0.3297\n",
      "Epoch 20/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.4213 - acc: 0.3660 - val_loss: 14.4326 - val_acc: 0.3584\n",
      "Epoch 21/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3956 - acc: 0.3783 - val_loss: 14.4172 - val_acc: 0.3859\n",
      "Epoch 22/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3725 - acc: 0.3864 - val_loss: 14.4017 - val_acc: 0.3728\n",
      "Epoch 23/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3502 - acc: 0.4013 - val_loss: 14.3853 - val_acc: 0.3775\n",
      "Epoch 24/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3331 - acc: 0.4078 - val_loss: 14.3504 - val_acc: 0.4158\n",
      "Epoch 25/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.3030 - acc: 0.4095 - val_loss: 14.3673 - val_acc: 0.3763\n",
      "Epoch 26/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2954 - acc: 0.4156 - val_loss: 14.3297 - val_acc: 0.4134\n",
      "Epoch 27/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2664 - acc: 0.4244 - val_loss: 14.3131 - val_acc: 0.3847\n",
      "Epoch 28/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2411 - acc: 0.4387 - val_loss: 14.2876 - val_acc: 0.3967\n",
      "Epoch 29/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2184 - acc: 0.4414 - val_loss: 14.2866 - val_acc: 0.4062\n",
      "Epoch 30/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.2034 - acc: 0.4482 - val_loss: 14.2647 - val_acc: 0.4002\n",
      "Epoch 31/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1809 - acc: 0.4535 - val_loss: 14.2524 - val_acc: 0.4182\n",
      "Epoch 32/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1674 - acc: 0.4604 - val_loss: 14.2308 - val_acc: 0.3799\n",
      "Epoch 33/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1434 - acc: 0.4633 - val_loss: 14.2068 - val_acc: 0.4241\n",
      "Epoch 34/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1243 - acc: 0.4670 - val_loss: 14.2215 - val_acc: 0.3859\n",
      "Epoch 35/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1224 - acc: 0.4628 - val_loss: 14.2002 - val_acc: 0.4194\n",
      "Epoch 36/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.1073 - acc: 0.4651 - val_loss: 14.2210 - val_acc: 0.4265\n",
      "Epoch 37/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0888 - acc: 0.4722 - val_loss: 14.1936 - val_acc: 0.4182\n",
      "Epoch 38/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0672 - acc: 0.4813 - val_loss: 14.1874 - val_acc: 0.4767\n",
      "Epoch 39/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0605 - acc: 0.4733 - val_loss: 14.1723 - val_acc: 0.4265\n",
      "Epoch 40/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0398 - acc: 0.4783 - val_loss: 14.1530 - val_acc: 0.4456\n",
      "Epoch 41/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0250 - acc: 0.4872 - val_loss: 14.1420 - val_acc: 0.4444\n",
      "Epoch 42/150\n",
      "7052/7052 [==============================] - 3s - loss: 14.0084 - acc: 0.4936 - val_loss: 14.1460 - val_acc: 0.4480\n",
      "Epoch 43/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9999 - acc: 0.4993 - val_loss: 14.1271 - val_acc: 0.4325\n",
      "Epoch 44/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9827 - acc: 0.4946 - val_loss: 14.1669 - val_acc: 0.3847\n",
      "Epoch 45/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9757 - acc: 0.5030 - val_loss: 14.1398 - val_acc: 0.4074\n",
      "Epoch 46/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9625 - acc: 0.5037 - val_loss: 14.1239 - val_acc: 0.4265\n",
      "Epoch 47/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9452 - acc: 0.5095 - val_loss: 14.1236 - val_acc: 0.4182\n",
      "Epoch 48/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9379 - acc: 0.5166 - val_loss: 14.0954 - val_acc: 0.4600\n",
      "Epoch 49/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9240 - acc: 0.5172 - val_loss: 14.0888 - val_acc: 0.4480\n",
      "Epoch 50/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.9063 - acc: 0.5220 - val_loss: 14.1716 - val_acc: 0.4325\n",
      "Epoch 51/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8997 - acc: 0.5196 - val_loss: 14.1155 - val_acc: 0.4349\n",
      "Epoch 52/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8969 - acc: 0.5252 - val_loss: 14.0636 - val_acc: 0.4707\n",
      "Epoch 53/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8816 - acc: 0.5177 - val_loss: 14.1009 - val_acc: 0.4277\n",
      "Epoch 54/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8719 - acc: 0.5230 - val_loss: 14.1169 - val_acc: 0.4205\n",
      "Epoch 55/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8533 - acc: 0.5292 - val_loss: 14.0537 - val_acc: 0.4098\n",
      "Epoch 56/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8453 - acc: 0.5339 - val_loss: 14.0859 - val_acc: 0.4683\n",
      "Epoch 57/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8507 - acc: 0.5360 - val_loss: 14.0525 - val_acc: 0.4397\n",
      "Epoch 58/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8192 - acc: 0.5424 - val_loss: 14.0509 - val_acc: 0.4205\n",
      "Epoch 59/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8127 - acc: 0.5350 - val_loss: 14.0223 - val_acc: 0.4671\n",
      "Epoch 60/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.8014 - acc: 0.5481 - val_loss: 14.0302 - val_acc: 0.4552\n",
      "Epoch 61/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7958 - acc: 0.5444 - val_loss: 14.0131 - val_acc: 0.4695\n",
      "Epoch 62/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7783 - acc: 0.5478 - val_loss: 14.0328 - val_acc: 0.4970\n",
      "Epoch 63/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7719 - acc: 0.5545 - val_loss: 14.0484 - val_acc: 0.4277\n",
      "Epoch 64/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7575 - acc: 0.5597 - val_loss: 14.0516 - val_acc: 0.4301\n",
      "Epoch 65/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7501 - acc: 0.5576 - val_loss: 13.9899 - val_acc: 0.4659\n",
      "Epoch 66/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7391 - acc: 0.5618 - val_loss: 13.9974 - val_acc: 0.4731\n",
      "Epoch 67/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7317 - acc: 0.5600 - val_loss: 14.1320 - val_acc: 0.4492\n",
      "Epoch 68/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7407 - acc: 0.5606 - val_loss: 14.0450 - val_acc: 0.4468\n",
      "Epoch 69/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.7190 - acc: 0.5574 - val_loss: 13.9737 - val_acc: 0.4564\n",
      "Epoch 70/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6980 - acc: 0.5732 - val_loss: 13.9770 - val_acc: 0.5114\n",
      "Epoch 71/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6863 - acc: 0.5783 - val_loss: 13.9478 - val_acc: 0.4934\n",
      "Epoch 72/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6727 - acc: 0.5764 - val_loss: 13.9755 - val_acc: 0.4648\n",
      "Epoch 73/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6624 - acc: 0.5834 - val_loss: 13.9597 - val_acc: 0.4671\n",
      "Epoch 74/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6523 - acc: 0.5830 - val_loss: 13.9385 - val_acc: 0.4910\n",
      "Epoch 75/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6483 - acc: 0.5934 - val_loss: 13.9287 - val_acc: 0.4839\n",
      "Epoch 76/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6369 - acc: 0.5913 - val_loss: 13.9341 - val_acc: 0.4743\n",
      "Epoch 77/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6263 - acc: 0.5858 - val_loss: 13.9185 - val_acc: 0.4886\n",
      "Epoch 78/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6223 - acc: 0.5862 - val_loss: 13.9252 - val_acc: 0.4922\n",
      "Epoch 79/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6048 - acc: 0.5953 - val_loss: 13.9581 - val_acc: 0.5030\n",
      "Epoch 80/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.6147 - acc: 0.5858 - val_loss: 13.9015 - val_acc: 0.5018\n",
      "Epoch 81/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5896 - acc: 0.6029 - val_loss: 13.9197 - val_acc: 0.4612\n",
      "Epoch 82/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5733 - acc: 0.6032 - val_loss: 13.8993 - val_acc: 0.4779\n",
      "Epoch 83/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5648 - acc: 0.6076 - val_loss: 14.0498 - val_acc: 0.4922\n",
      "Epoch 84/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5889 - acc: 0.5974 - val_loss: 13.9277 - val_acc: 0.4552\n",
      "Epoch 85/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5479 - acc: 0.6120 - val_loss: 13.8929 - val_acc: 0.4898\n",
      "Epoch 86/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5445 - acc: 0.6069 - val_loss: 13.8890 - val_acc: 0.4970\n",
      "Epoch 87/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5289 - acc: 0.6176 - val_loss: 13.8836 - val_acc: 0.4707\n",
      "Epoch 88/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5260 - acc: 0.6211 - val_loss: 13.9358 - val_acc: 0.5460\n",
      "Epoch 89/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5187 - acc: 0.6149 - val_loss: 13.8664 - val_acc: 0.5329\n",
      "Epoch 90/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.5143 - acc: 0.6229 - val_loss: 13.8737 - val_acc: 0.4934\n",
      "Epoch 91/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4987 - acc: 0.6198 - val_loss: 13.8356 - val_acc: 0.5006\n",
      "Epoch 92/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4808 - acc: 0.6366 - val_loss: 13.9107 - val_acc: 0.4910\n",
      "Epoch 93/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4914 - acc: 0.6228 - val_loss: 13.8418 - val_acc: 0.5114\n",
      "Epoch 94/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4751 - acc: 0.6307 - val_loss: 13.8630 - val_acc: 0.4886\n",
      "Epoch 95/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4667 - acc: 0.6266 - val_loss: 13.8334 - val_acc: 0.5556\n",
      "Epoch 96/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4483 - acc: 0.6357 - val_loss: 13.8459 - val_acc: 0.5579\n",
      "Epoch 97/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4359 - acc: 0.6432 - val_loss: 13.8811 - val_acc: 0.4564\n",
      "Epoch 98/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4344 - acc: 0.6435 - val_loss: 13.8726 - val_acc: 0.5269\n",
      "Epoch 99/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4300 - acc: 0.6377 - val_loss: 13.8838 - val_acc: 0.4934\n",
      "Epoch 100/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4253 - acc: 0.6439 - val_loss: 13.8655 - val_acc: 0.4540\n",
      "Epoch 101/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4117 - acc: 0.6404 - val_loss: 13.8197 - val_acc: 0.4922\n",
      "Epoch 102/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3871 - acc: 0.6618 - val_loss: 13.8106 - val_acc: 0.5102\n",
      "Epoch 103/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.4027 - acc: 0.6388 - val_loss: 13.8201 - val_acc: 0.5233\n",
      "Epoch 104/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3854 - acc: 0.6523 - val_loss: 13.8044 - val_acc: 0.5006\n",
      "Epoch 105/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3627 - acc: 0.6550 - val_loss: 13.8089 - val_acc: 0.5257\n",
      "Epoch 106/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3705 - acc: 0.6435 - val_loss: 13.7840 - val_acc: 0.5102\n",
      "Epoch 107/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3539 - acc: 0.6548 - val_loss: 13.7893 - val_acc: 0.4588\n",
      "Epoch 108/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3527 - acc: 0.6567 - val_loss: 13.7885 - val_acc: 0.4982\n",
      "Epoch 109/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3419 - acc: 0.6631 - val_loss: 13.7940 - val_acc: 0.4958\n",
      "Epoch 110/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3264 - acc: 0.6639 - val_loss: 13.9073 - val_acc: 0.5114\n",
      "Epoch 111/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3521 - acc: 0.6537 - val_loss: 13.7697 - val_acc: 0.4922\n",
      "Epoch 112/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3143 - acc: 0.6656 - val_loss: 13.7731 - val_acc: 0.5030\n",
      "Epoch 113/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3054 - acc: 0.6706 - val_loss: 13.8180 - val_acc: 0.5054\n",
      "Epoch 114/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3074 - acc: 0.6669 - val_loss: 13.8102 - val_acc: 0.4898\n",
      "Epoch 115/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2951 - acc: 0.6724 - val_loss: 13.7705 - val_acc: 0.5197\n",
      "Epoch 116/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2880 - acc: 0.6678 - val_loss: 13.7491 - val_acc: 0.5125\n",
      "Epoch 117/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2827 - acc: 0.6666 - val_loss: 13.8345 - val_acc: 0.4851\n",
      "Epoch 118/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2825 - acc: 0.6703 - val_loss: 13.9246 - val_acc: 0.5376\n",
      "Epoch 119/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.3116 - acc: 0.6556 - val_loss: 13.7429 - val_acc: 0.4779\n",
      "Epoch 120/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2505 - acc: 0.6841 - val_loss: 13.7407 - val_acc: 0.5317\n",
      "Epoch 121/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2461 - acc: 0.6805 - val_loss: 13.8521 - val_acc: 0.5890\n",
      "Epoch 122/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2652 - acc: 0.6695 - val_loss: 13.8568 - val_acc: 0.5556\n",
      "Epoch 123/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2481 - acc: 0.6767 - val_loss: 13.7316 - val_acc: 0.6189\n",
      "Epoch 124/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2250 - acc: 0.6866 - val_loss: 13.7394 - val_acc: 0.5114\n",
      "Epoch 125/150\n",
      "7052/7052 [==============================] - 4s - loss: 13.2093 - acc: 0.6826 - val_loss: 13.7221 - val_acc: 0.5914\n",
      "Epoch 126/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2110 - acc: 0.6856 - val_loss: 13.7609 - val_acc: 0.5436\n",
      "Epoch 127/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1951 - acc: 0.6904 - val_loss: 13.8516 - val_acc: 0.5209\n",
      "Epoch 128/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2166 - acc: 0.6851 - val_loss: 13.7439 - val_acc: 0.5042\n",
      "Epoch 129/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1877 - acc: 0.6883 - val_loss: 13.7860 - val_acc: 0.6069\n",
      "Epoch 130/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1882 - acc: 0.6907 - val_loss: 13.7321 - val_acc: 0.5185\n",
      "Epoch 131/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1665 - acc: 0.6975 - val_loss: 13.7618 - val_acc: 0.5221\n",
      "Epoch 132/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1744 - acc: 0.6964 - val_loss: 13.7633 - val_acc: 0.5520\n",
      "Epoch 133/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1661 - acc: 0.6944 - val_loss: 13.7374 - val_acc: 0.5926\n",
      "Epoch 134/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1462 - acc: 0.6971 - val_loss: 13.6710 - val_acc: 0.6105\n",
      "Epoch 135/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1313 - acc: 0.7077 - val_loss: 13.6663 - val_acc: 0.5806\n",
      "Epoch 136/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1362 - acc: 0.7035 - val_loss: 13.7424 - val_acc: 0.5018\n",
      "Epoch 137/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1329 - acc: 0.7004 - val_loss: 13.7778 - val_acc: 0.5687\n",
      "Epoch 138/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1464 - acc: 0.6955 - val_loss: 13.6750 - val_acc: 0.5639\n",
      "Epoch 139/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1197 - acc: 0.6933 - val_loss: 13.6747 - val_acc: 0.6081\n",
      "Epoch 140/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.1025 - acc: 0.7050 - val_loss: 13.6887 - val_acc: 0.5568\n",
      "Epoch 141/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0914 - acc: 0.7087 - val_loss: 13.6582 - val_acc: 0.6105\n",
      "Epoch 142/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0836 - acc: 0.7092 - val_loss: 13.6742 - val_acc: 0.6165\n",
      "Epoch 143/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0680 - acc: 0.7170 - val_loss: 14.1583 - val_acc: 0.4194\n",
      "Epoch 144/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.2307 - acc: 0.6748 - val_loss: 13.6687 - val_acc: 0.5197\n",
      "Epoch 145/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0773 - acc: 0.7089 - val_loss: 13.6402 - val_acc: 0.5568\n",
      "Epoch 146/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0566 - acc: 0.7155 - val_loss: 13.6210 - val_acc: 0.5544\n",
      "Epoch 147/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0629 - acc: 0.7123 - val_loss: 13.6851 - val_acc: 0.5615\n",
      "Epoch 148/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0560 - acc: 0.7087 - val_loss: 13.6848 - val_acc: 0.5173\n",
      "Epoch 149/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0496 - acc: 0.7170 - val_loss: 13.6512 - val_acc: 0.5986\n",
      "Epoch 150/150\n",
      "7052/7052 [==============================] - 3s - loss: 13.0362 - acc: 0.7324 - val_loss: 13.6157 - val_acc: 0.5723\n",
      "training time: 476.38975405693054\n",
      "800/838 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.6229\n",
      "\n",
      "Error Rate = 0.3771\n",
      "training time: 0.6866040229797363\n",
      "opening fold: 8\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold9 New Features:  (816, 101, 60, 3)\n",
      "Scaling time: 1.8431062698364258\n",
      "Scaling time: 0.22751355171203613\n",
      "Scaling time: 0.22051763534545898\n",
      "training model...hold tight\n",
      "Train on 7084 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7084/7084 [==============================] - 9s - loss: 15.1140 - acc: 0.1141 - val_loss: 15.0628 - val_acc: 0.1864\n",
      "Epoch 2/150\n",
      "7084/7084 [==============================] - 3s - loss: 15.0595 - acc: 0.1591 - val_loss: 15.0052 - val_acc: 0.1864\n",
      "Epoch 3/150\n",
      "7084/7084 [==============================] - 3s - loss: 15.0083 - acc: 0.1838 - val_loss: 14.9451 - val_acc: 0.1864\n",
      "Epoch 4/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.9414 - acc: 0.2023 - val_loss: 14.8930 - val_acc: 0.1840\n",
      "Epoch 5/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.8990 - acc: 0.2098 - val_loss: 14.8466 - val_acc: 0.2449\n",
      "Epoch 6/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.8642 - acc: 0.2233 - val_loss: 14.8057 - val_acc: 0.2425\n",
      "Epoch 7/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.8242 - acc: 0.2466 - val_loss: 14.7666 - val_acc: 0.2664\n",
      "Epoch 8/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.7850 - acc: 0.2518 - val_loss: 14.7261 - val_acc: 0.2628\n",
      "Epoch 9/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.7387 - acc: 0.2688 - val_loss: 14.6843 - val_acc: 0.2557\n",
      "Epoch 10/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.7011 - acc: 0.2761 - val_loss: 14.6468 - val_acc: 0.2533\n",
      "Epoch 11/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.6666 - acc: 0.2851 - val_loss: 14.6156 - val_acc: 0.2569\n",
      "Epoch 12/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.6280 - acc: 0.2952 - val_loss: 14.5887 - val_acc: 0.2616\n",
      "Epoch 13/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.5954 - acc: 0.3084 - val_loss: 14.5685 - val_acc: 0.2891\n",
      "Epoch 14/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.5643 - acc: 0.3199 - val_loss: 14.5449 - val_acc: 0.2879\n",
      "Epoch 15/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.5395 - acc: 0.3135 - val_loss: 14.5205 - val_acc: 0.2927\n",
      "Epoch 16/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.5110 - acc: 0.3330 - val_loss: 14.5061 - val_acc: 0.3536\n",
      "Epoch 17/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4905 - acc: 0.3377 - val_loss: 14.4948 - val_acc: 0.3130\n",
      "Epoch 18/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4560 - acc: 0.3631 - val_loss: 14.4690 - val_acc: 0.3357\n",
      "Epoch 19/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4484 - acc: 0.3550 - val_loss: 14.4578 - val_acc: 0.3166\n",
      "Epoch 20/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.4149 - acc: 0.3718 - val_loss: 14.4414 - val_acc: 0.3429\n",
      "Epoch 21/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3976 - acc: 0.3776 - val_loss: 14.4245 - val_acc: 0.3250\n",
      "Epoch 22/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3686 - acc: 0.3882 - val_loss: 14.4057 - val_acc: 0.3274\n",
      "Epoch 23/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3547 - acc: 0.3920 - val_loss: 14.3855 - val_acc: 0.3513\n",
      "Epoch 24/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3306 - acc: 0.3981 - val_loss: 14.3739 - val_acc: 0.3835\n",
      "Epoch 25/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.3075 - acc: 0.4167 - val_loss: 14.3622 - val_acc: 0.3429\n",
      "Epoch 26/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2819 - acc: 0.4259 - val_loss: 14.3455 - val_acc: 0.3751\n",
      "Epoch 27/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2694 - acc: 0.4246 - val_loss: 14.3342 - val_acc: 0.3441\n",
      "Epoch 28/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2501 - acc: 0.4385 - val_loss: 14.3374 - val_acc: 0.3381\n",
      "Epoch 29/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2344 - acc: 0.4346 - val_loss: 14.2861 - val_acc: 0.4002\n",
      "Epoch 30/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.2061 - acc: 0.4390 - val_loss: 14.3039 - val_acc: 0.3405\n",
      "Epoch 31/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1961 - acc: 0.4514 - val_loss: 14.2822 - val_acc: 0.3560\n",
      "Epoch 32/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1764 - acc: 0.4483 - val_loss: 14.2615 - val_acc: 0.3644\n",
      "Epoch 33/150\n",
      "7084/7084 [==============================] - 4s - loss: 14.1508 - acc: 0.4616 - val_loss: 14.2661 - val_acc: 0.3859\n",
      "Epoch 34/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1373 - acc: 0.4664 - val_loss: 14.2379 - val_acc: 0.3632\n",
      "Epoch 35/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1235 - acc: 0.4723 - val_loss: 14.2331 - val_acc: 0.3656\n",
      "Epoch 36/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.1052 - acc: 0.4716 - val_loss: 14.2467 - val_acc: 0.3548\n",
      "Epoch 37/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0869 - acc: 0.4846 - val_loss: 14.2308 - val_acc: 0.3620\n",
      "Epoch 38/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0736 - acc: 0.4808 - val_loss: 14.1948 - val_acc: 0.4253\n",
      "Epoch 39/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0627 - acc: 0.4788 - val_loss: 14.2021 - val_acc: 0.3608\n",
      "Epoch 40/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0470 - acc: 0.4920 - val_loss: 14.1830 - val_acc: 0.3704\n",
      "Epoch 41/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0338 - acc: 0.4870 - val_loss: 14.1685 - val_acc: 0.3907\n",
      "Epoch 42/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0177 - acc: 0.4900 - val_loss: 14.1631 - val_acc: 0.3704\n",
      "Epoch 43/150\n",
      "7084/7084 [==============================] - 3s - loss: 14.0068 - acc: 0.4928 - val_loss: 14.1499 - val_acc: 0.3871\n",
      "Epoch 44/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9911 - acc: 0.5000 - val_loss: 14.1598 - val_acc: 0.3847\n",
      "Epoch 45/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9793 - acc: 0.5066 - val_loss: 14.1436 - val_acc: 0.3656\n",
      "Epoch 46/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9690 - acc: 0.5069 - val_loss: 14.1819 - val_acc: 0.3787\n",
      "Epoch 47/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9604 - acc: 0.5104 - val_loss: 14.1810 - val_acc: 0.3728\n",
      "Epoch 48/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9526 - acc: 0.5024 - val_loss: 14.1174 - val_acc: 0.4050\n",
      "Epoch 49/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9290 - acc: 0.5152 - val_loss: 14.1261 - val_acc: 0.3847\n",
      "Epoch 50/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9198 - acc: 0.5158 - val_loss: 14.1266 - val_acc: 0.3978\n",
      "Epoch 51/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.9161 - acc: 0.5186 - val_loss: 14.1120 - val_acc: 0.4229\n",
      "Epoch 52/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8927 - acc: 0.5280 - val_loss: 14.1046 - val_acc: 0.4074\n",
      "Epoch 53/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8908 - acc: 0.5244 - val_loss: 14.0764 - val_acc: 0.4122\n",
      "Epoch 54/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8728 - acc: 0.5298 - val_loss: 14.0920 - val_acc: 0.3978\n",
      "Epoch 55/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8644 - acc: 0.5291 - val_loss: 14.0997 - val_acc: 0.4122\n",
      "Epoch 56/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8607 - acc: 0.5296 - val_loss: 14.0879 - val_acc: 0.4289\n",
      "Epoch 57/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8431 - acc: 0.5392 - val_loss: 14.0473 - val_acc: 0.4432\n",
      "Epoch 58/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8292 - acc: 0.5360 - val_loss: 14.0696 - val_acc: 0.4086\n",
      "Epoch 59/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8222 - acc: 0.5360 - val_loss: 14.0939 - val_acc: 0.4229\n",
      "Epoch 60/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.8097 - acc: 0.5460 - val_loss: 14.0596 - val_acc: 0.3931\n",
      "Epoch 61/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7986 - acc: 0.5494 - val_loss: 14.0377 - val_acc: 0.4409\n",
      "Epoch 62/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7811 - acc: 0.5532 - val_loss: 14.0452 - val_acc: 0.4373\n",
      "Epoch 63/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7826 - acc: 0.5541 - val_loss: 14.1491 - val_acc: 0.4038\n",
      "Epoch 64/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7915 - acc: 0.5433 - val_loss: 14.0427 - val_acc: 0.4194\n",
      "Epoch 65/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.7523 - acc: 0.5671 - val_loss: 14.0098 - val_acc: 0.4480\n",
      "Epoch 66/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7521 - acc: 0.5634 - val_loss: 13.9962 - val_acc: 0.4409\n",
      "Epoch 67/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7363 - acc: 0.5648 - val_loss: 14.0053 - val_acc: 0.4194\n",
      "Epoch 68/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7235 - acc: 0.5669 - val_loss: 14.0226 - val_acc: 0.4337\n",
      "Epoch 69/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7182 - acc: 0.5720 - val_loss: 13.9861 - val_acc: 0.4265\n",
      "Epoch 70/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.7006 - acc: 0.5774 - val_loss: 14.0157 - val_acc: 0.4170\n",
      "Epoch 71/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6949 - acc: 0.5764 - val_loss: 13.9699 - val_acc: 0.4516\n",
      "Epoch 72/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6778 - acc: 0.5887 - val_loss: 14.0218 - val_acc: 0.4444\n",
      "Epoch 73/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6731 - acc: 0.5796 - val_loss: 13.9965 - val_acc: 0.4253\n",
      "Epoch 74/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6676 - acc: 0.5885 - val_loss: 13.9786 - val_acc: 0.4540\n",
      "Epoch 75/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6506 - acc: 0.5887 - val_loss: 13.9703 - val_acc: 0.4671\n",
      "Epoch 76/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6383 - acc: 0.5985 - val_loss: 14.0340 - val_acc: 0.4480\n",
      "Epoch 77/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6579 - acc: 0.5783 - val_loss: 13.9446 - val_acc: 0.4361\n",
      "Epoch 78/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6229 - acc: 0.6043 - val_loss: 13.9415 - val_acc: 0.4624\n",
      "Epoch 79/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6145 - acc: 0.5987 - val_loss: 13.9421 - val_acc: 0.4552\n",
      "Epoch 80/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.6032 - acc: 0.6086 - val_loss: 13.9366 - val_acc: 0.4982\n",
      "Epoch 81/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5936 - acc: 0.6032 - val_loss: 13.9595 - val_acc: 0.4229\n",
      "Epoch 82/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5899 - acc: 0.6057 - val_loss: 13.9929 - val_acc: 0.5233\n",
      "Epoch 83/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5930 - acc: 0.6015 - val_loss: 13.9202 - val_acc: 0.4468\n",
      "Epoch 84/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5729 - acc: 0.6087 - val_loss: 13.9038 - val_acc: 0.4779\n",
      "Epoch 85/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5615 - acc: 0.6122 - val_loss: 13.8773 - val_acc: 0.4612\n",
      "Epoch 86/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5501 - acc: 0.6117 - val_loss: 13.8972 - val_acc: 0.4719\n",
      "Epoch 87/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5419 - acc: 0.6235 - val_loss: 13.8974 - val_acc: 0.4468\n",
      "Epoch 88/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5272 - acc: 0.6187 - val_loss: 13.8741 - val_acc: 0.4648\n",
      "Epoch 89/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5150 - acc: 0.6235 - val_loss: 13.8883 - val_acc: 0.4337\n",
      "Epoch 90/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5107 - acc: 0.6259 - val_loss: 13.8883 - val_acc: 0.4588\n",
      "Epoch 91/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.5008 - acc: 0.6310 - val_loss: 13.8604 - val_acc: 0.4767\n",
      "Epoch 92/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4967 - acc: 0.6362 - val_loss: 13.8792 - val_acc: 0.4827\n",
      "Epoch 93/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4842 - acc: 0.6368 - val_loss: 13.8909 - val_acc: 0.4361\n",
      "Epoch 94/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4715 - acc: 0.6358 - val_loss: 13.8745 - val_acc: 0.4444\n",
      "Epoch 95/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4635 - acc: 0.6413 - val_loss: 13.8553 - val_acc: 0.4815\n",
      "Epoch 96/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4611 - acc: 0.6328 - val_loss: 13.8437 - val_acc: 0.4886\n",
      "Epoch 97/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4441 - acc: 0.6414 - val_loss: 13.8733 - val_acc: 0.4671\n",
      "Epoch 98/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4327 - acc: 0.6444 - val_loss: 13.8497 - val_acc: 0.4528\n",
      "Epoch 99/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4293 - acc: 0.6471 - val_loss: 13.8971 - val_acc: 0.4731\n",
      "Epoch 100/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4354 - acc: 0.6438 - val_loss: 13.8768 - val_acc: 0.4504\n",
      "Epoch 101/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.4169 - acc: 0.6457 - val_loss: 13.8199 - val_acc: 0.5018\n",
      "Epoch 102/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.3961 - acc: 0.6585 - val_loss: 13.8074 - val_acc: 0.4863\n",
      "Epoch 103/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3923 - acc: 0.6547 - val_loss: 13.8318 - val_acc: 0.4934\n",
      "Epoch 104/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3832 - acc: 0.6608 - val_loss: 13.7825 - val_acc: 0.5161\n",
      "Epoch 105/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3691 - acc: 0.6621 - val_loss: 13.7952 - val_acc: 0.5687\n",
      "Epoch 106/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3618 - acc: 0.6587 - val_loss: 13.7689 - val_acc: 0.5090\n",
      "Epoch 107/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3581 - acc: 0.6667 - val_loss: 13.8724 - val_acc: 0.5030\n",
      "Epoch 108/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3673 - acc: 0.6518 - val_loss: 13.8001 - val_acc: 0.4898\n",
      "Epoch 109/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3346 - acc: 0.6705 - val_loss: 13.7666 - val_acc: 0.5556\n",
      "Epoch 110/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3230 - acc: 0.6684 - val_loss: 13.7793 - val_acc: 0.5102\n",
      "Epoch 111/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3167 - acc: 0.6748 - val_loss: 13.7671 - val_acc: 0.5090\n",
      "Epoch 112/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3156 - acc: 0.6676 - val_loss: 13.7748 - val_acc: 0.5233\n",
      "Epoch 113/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3018 - acc: 0.6733 - val_loss: 13.7769 - val_acc: 0.5030\n",
      "Epoch 114/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.3110 - acc: 0.6704 - val_loss: 13.7451 - val_acc: 0.5747\n",
      "Epoch 115/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2976 - acc: 0.6733 - val_loss: 13.8386 - val_acc: 0.4803\n",
      "Epoch 116/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2852 - acc: 0.6831 - val_loss: 13.7269 - val_acc: 0.5556\n",
      "Epoch 117/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2757 - acc: 0.6787 - val_loss: 13.7888 - val_acc: 0.5042\n",
      "Epoch 118/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2771 - acc: 0.6787 - val_loss: 13.7212 - val_acc: 0.5364\n",
      "Epoch 119/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2543 - acc: 0.6828 - val_loss: 13.7467 - val_acc: 0.5591\n",
      "Epoch 120/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2632 - acc: 0.6781 - val_loss: 13.8508 - val_acc: 0.4624\n",
      "Epoch 121/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2473 - acc: 0.6861 - val_loss: 13.7894 - val_acc: 0.4767\n",
      "Epoch 122/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2425 - acc: 0.6837 - val_loss: 13.7385 - val_acc: 0.4851\n",
      "Epoch 123/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2379 - acc: 0.6817 - val_loss: 13.7270 - val_acc: 0.5173\n",
      "Epoch 124/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2173 - acc: 0.6897 - val_loss: 13.7175 - val_acc: 0.5723\n",
      "Epoch 125/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.2062 - acc: 0.6951 - val_loss: 13.7006 - val_acc: 0.5185\n",
      "Epoch 126/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.2145 - acc: 0.6870 - val_loss: 13.7859 - val_acc: 0.5568\n",
      "Epoch 127/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1942 - acc: 0.6957 - val_loss: 13.6771 - val_acc: 0.5950\n",
      "Epoch 128/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1726 - acc: 0.6976 - val_loss: 13.7531 - val_acc: 0.5066\n",
      "Epoch 129/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1912 - acc: 0.6913 - val_loss: 13.7506 - val_acc: 0.5675\n",
      "Epoch 130/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1793 - acc: 0.6920 - val_loss: 13.7100 - val_acc: 0.5591\n",
      "Epoch 131/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1598 - acc: 0.7003 - val_loss: 13.7525 - val_acc: 0.5532\n",
      "Epoch 132/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1617 - acc: 0.7033 - val_loss: 13.6790 - val_acc: 0.5257\n",
      "Epoch 133/150\n",
      "7084/7084 [==============================] - 4s - loss: 13.1502 - acc: 0.7071 - val_loss: 13.6613 - val_acc: 0.5890\n",
      "Epoch 134/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1366 - acc: 0.6983 - val_loss: 13.8667 - val_acc: 0.5090\n",
      "Epoch 135/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1689 - acc: 0.6928 - val_loss: 13.6562 - val_acc: 0.5329\n",
      "Epoch 136/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1176 - acc: 0.7074 - val_loss: 13.6382 - val_acc: 0.6010\n",
      "Epoch 137/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1172 - acc: 0.7103 - val_loss: 13.6254 - val_acc: 0.5341\n",
      "Epoch 138/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1056 - acc: 0.7102 - val_loss: 13.6357 - val_acc: 0.5341\n",
      "Epoch 139/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0985 - acc: 0.7096 - val_loss: 13.6830 - val_acc: 0.5149\n",
      "Epoch 140/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.1111 - acc: 0.7020 - val_loss: 13.6477 - val_acc: 0.5926\n",
      "Epoch 141/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0893 - acc: 0.7112 - val_loss: 13.6133 - val_acc: 0.5305\n",
      "Epoch 142/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0867 - acc: 0.7103 - val_loss: 13.6218 - val_acc: 0.5090\n",
      "Epoch 143/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0736 - acc: 0.7180 - val_loss: 13.6964 - val_acc: 0.5651\n",
      "Epoch 144/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0857 - acc: 0.7134 - val_loss: 13.6248 - val_acc: 0.5914\n",
      "Epoch 145/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0638 - acc: 0.7215 - val_loss: 13.6090 - val_acc: 0.5615\n",
      "Epoch 146/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0524 - acc: 0.7189 - val_loss: 13.6369 - val_acc: 0.5364\n",
      "Epoch 147/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0536 - acc: 0.7165 - val_loss: 13.5904 - val_acc: 0.5352\n",
      "Epoch 148/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0398 - acc: 0.7230 - val_loss: 13.6014 - val_acc: 0.5783\n",
      "Epoch 149/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0226 - acc: 0.7281 - val_loss: 13.6029 - val_acc: 0.5317\n",
      "Epoch 150/150\n",
      "7084/7084 [==============================] - 3s - loss: 13.0063 - acc: 0.7307 - val_loss: 13.6564 - val_acc: 0.5890\n",
      "training time: 481.19774556159973\n",
      "800/806 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.6266\n",
      "\n",
      "Error Rate = 0.3734\n",
      "training time: 0.6146576404571533\n",
      "opening fold: 9\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Scaling time: 1.8409485816955566\n",
      "Scaling time: 0.22888851165771484\n",
      "Scaling time: 0.22393560409545898\n",
      "training model...hold tight\n",
      "Train on 7074 samples, validate on 837 samples\n",
      "Epoch 1/150\n",
      "7074/7074 [==============================] - 9s - loss: 15.1183 - acc: 0.1125 - val_loss: 15.0684 - val_acc: 0.1195\n",
      "Epoch 2/150\n",
      "7074/7074 [==============================] - 3s - loss: 15.0676 - acc: 0.1387 - val_loss: 15.0226 - val_acc: 0.2007\n",
      "Epoch 3/150\n",
      "7074/7074 [==============================] - 3s - loss: 15.0284 - acc: 0.1658 - val_loss: 14.9793 - val_acc: 0.1912\n",
      "Epoch 4/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9842 - acc: 0.1894 - val_loss: 14.9337 - val_acc: 0.2198\n",
      "Epoch 5/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9422 - acc: 0.2058 - val_loss: 14.8835 - val_acc: 0.2246\n",
      "Epoch 6/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8910 - acc: 0.2129 - val_loss: 14.8330 - val_acc: 0.2521\n",
      "Epoch 7/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8545 - acc: 0.2277 - val_loss: 14.7882 - val_acc: 0.2748\n",
      "Epoch 8/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8144 - acc: 0.2434 - val_loss: 14.7483 - val_acc: 0.2808\n",
      "Epoch 9/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7760 - acc: 0.2578 - val_loss: 14.7010 - val_acc: 0.2724\n",
      "Epoch 10/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7395 - acc: 0.2618 - val_loss: 14.6641 - val_acc: 0.2999\n",
      "Epoch 11/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7031 - acc: 0.2662 - val_loss: 14.6262 - val_acc: 0.3047\n",
      "Epoch 12/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6683 - acc: 0.2803 - val_loss: 14.6028 - val_acc: 0.2664\n",
      "Epoch 13/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6269 - acc: 0.2964 - val_loss: 14.5798 - val_acc: 0.2700\n",
      "Epoch 14/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6032 - acc: 0.2986 - val_loss: 14.5507 - val_acc: 0.3035\n",
      "Epoch 15/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5748 - acc: 0.3035 - val_loss: 14.5215 - val_acc: 0.3417\n",
      "Epoch 16/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5423 - acc: 0.3192 - val_loss: 14.4955 - val_acc: 0.3082\n",
      "Epoch 17/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5073 - acc: 0.3355 - val_loss: 14.4885 - val_acc: 0.3214\n",
      "Epoch 18/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4840 - acc: 0.3451 - val_loss: 14.4534 - val_acc: 0.3584\n",
      "Epoch 19/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4672 - acc: 0.3516 - val_loss: 14.4400 - val_acc: 0.3369\n",
      "Epoch 20/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4319 - acc: 0.3695 - val_loss: 14.4164 - val_acc: 0.3584\n",
      "Epoch 21/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4073 - acc: 0.3831 - val_loss: 14.3975 - val_acc: 0.3369\n",
      "Epoch 22/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3794 - acc: 0.3933 - val_loss: 14.3693 - val_acc: 0.3644\n",
      "Epoch 23/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3509 - acc: 0.4064 - val_loss: 14.3614 - val_acc: 0.3453\n",
      "Epoch 24/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3351 - acc: 0.4061 - val_loss: 14.3542 - val_acc: 0.3465\n",
      "Epoch 25/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3121 - acc: 0.4259 - val_loss: 14.3254 - val_acc: 0.3763\n",
      "Epoch 26/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2854 - acc: 0.4285 - val_loss: 14.3212 - val_acc: 0.3740\n",
      "Epoch 27/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2717 - acc: 0.4293 - val_loss: 14.2934 - val_acc: 0.4110\n",
      "Epoch 28/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2332 - acc: 0.4478 - val_loss: 14.2717 - val_acc: 0.4432\n",
      "Epoch 29/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2203 - acc: 0.4444 - val_loss: 14.2659 - val_acc: 0.3955\n",
      "Epoch 30/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2048 - acc: 0.4536 - val_loss: 14.2393 - val_acc: 0.4229\n",
      "Epoch 31/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1830 - acc: 0.4555 - val_loss: 14.2397 - val_acc: 0.4337\n",
      "Epoch 32/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1700 - acc: 0.4556 - val_loss: 14.2217 - val_acc: 0.4588\n",
      "Epoch 33/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1482 - acc: 0.4647 - val_loss: 14.2110 - val_acc: 0.3955\n",
      "Epoch 34/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1345 - acc: 0.4722 - val_loss: 14.2181 - val_acc: 0.4456\n",
      "Epoch 35/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1141 - acc: 0.4746 - val_loss: 14.1898 - val_acc: 0.4277\n",
      "Epoch 36/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0981 - acc: 0.4832 - val_loss: 14.1837 - val_acc: 0.4277\n",
      "Epoch 37/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0897 - acc: 0.4869 - val_loss: 14.1566 - val_acc: 0.4409\n",
      "Epoch 38/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0609 - acc: 0.4894 - val_loss: 14.1475 - val_acc: 0.4552\n",
      "Epoch 39/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0579 - acc: 0.4840 - val_loss: 14.1855 - val_acc: 0.4229\n",
      "Epoch 40/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0482 - acc: 0.4966 - val_loss: 14.1703 - val_acc: 0.4182\n",
      "Epoch 41/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0324 - acc: 0.4941 - val_loss: 14.1459 - val_acc: 0.3692\n",
      "Epoch 42/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0193 - acc: 0.5035 - val_loss: 14.1269 - val_acc: 0.4397\n",
      "Epoch 43/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0011 - acc: 0.5098 - val_loss: 14.1183 - val_acc: 0.4086\n",
      "Epoch 44/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.9917 - acc: 0.5075 - val_loss: 14.1267 - val_acc: 0.4229\n",
      "Epoch 45/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9769 - acc: 0.5095 - val_loss: 14.1264 - val_acc: 0.4182\n",
      "Epoch 46/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9763 - acc: 0.5096 - val_loss: 14.0920 - val_acc: 0.4146\n",
      "Epoch 47/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9485 - acc: 0.5182 - val_loss: 14.2165 - val_acc: 0.3895\n",
      "Epoch 48/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9654 - acc: 0.5172 - val_loss: 14.0812 - val_acc: 0.4576\n",
      "Epoch 49/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9311 - acc: 0.5233 - val_loss: 14.0946 - val_acc: 0.4468\n",
      "Epoch 50/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9265 - acc: 0.5259 - val_loss: 14.0583 - val_acc: 0.4373\n",
      "Epoch 51/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9072 - acc: 0.5310 - val_loss: 14.0507 - val_acc: 0.4540\n",
      "Epoch 52/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8912 - acc: 0.5325 - val_loss: 14.0573 - val_acc: 0.4492\n",
      "Epoch 53/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8780 - acc: 0.5352 - val_loss: 14.0527 - val_acc: 0.4707\n",
      "Epoch 54/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8712 - acc: 0.5377 - val_loss: 14.0963 - val_acc: 0.4086\n",
      "Epoch 55/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8653 - acc: 0.5404 - val_loss: 14.0278 - val_acc: 0.4540\n",
      "Epoch 56/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8487 - acc: 0.5370 - val_loss: 14.0363 - val_acc: 0.4552\n",
      "Epoch 57/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8365 - acc: 0.5424 - val_loss: 14.0425 - val_acc: 0.5030\n",
      "Epoch 58/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8229 - acc: 0.5507 - val_loss: 14.0108 - val_acc: 0.5221\n",
      "Epoch 59/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8074 - acc: 0.5478 - val_loss: 14.0103 - val_acc: 0.4289\n",
      "Epoch 60/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8022 - acc: 0.5486 - val_loss: 14.0282 - val_acc: 0.4241\n",
      "Epoch 61/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7965 - acc: 0.5496 - val_loss: 14.0035 - val_acc: 0.4552\n",
      "Epoch 62/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7846 - acc: 0.5582 - val_loss: 13.9888 - val_acc: 0.4970\n",
      "Epoch 63/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7800 - acc: 0.5591 - val_loss: 13.9923 - val_acc: 0.4624\n",
      "Epoch 64/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7640 - acc: 0.5652 - val_loss: 13.9497 - val_acc: 0.5305\n",
      "Epoch 65/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7563 - acc: 0.5601 - val_loss: 14.0527 - val_acc: 0.4528\n",
      "Epoch 66/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7797 - acc: 0.5544 - val_loss: 13.9694 - val_acc: 0.4516\n",
      "Epoch 67/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.7370 - acc: 0.5679 - val_loss: 14.0781 - val_acc: 0.4002\n",
      "Epoch 68/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7576 - acc: 0.5666 - val_loss: 13.9596 - val_acc: 0.4612\n",
      "Epoch 69/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7158 - acc: 0.5755 - val_loss: 13.9542 - val_acc: 0.5161\n",
      "Epoch 70/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7068 - acc: 0.5751 - val_loss: 13.9360 - val_acc: 0.5364\n",
      "Epoch 71/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6976 - acc: 0.5708 - val_loss: 13.9680 - val_acc: 0.4600\n",
      "Epoch 72/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6856 - acc: 0.5908 - val_loss: 13.9524 - val_acc: 0.5090\n",
      "Epoch 73/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6773 - acc: 0.5841 - val_loss: 13.9272 - val_acc: 0.4671\n",
      "Epoch 74/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6664 - acc: 0.5787 - val_loss: 13.9226 - val_acc: 0.5388\n",
      "Epoch 75/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6551 - acc: 0.5840 - val_loss: 13.9217 - val_acc: 0.4731\n",
      "Epoch 76/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6512 - acc: 0.5922 - val_loss: 13.9428 - val_acc: 0.4612\n",
      "Epoch 77/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6353 - acc: 0.5933 - val_loss: 13.9069 - val_acc: 0.5723\n",
      "Epoch 78/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6241 - acc: 0.6021 - val_loss: 13.9022 - val_acc: 0.5114\n",
      "Epoch 79/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6145 - acc: 0.5975 - val_loss: 13.9120 - val_acc: 0.5544\n",
      "Epoch 80/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6116 - acc: 0.5895 - val_loss: 13.8970 - val_acc: 0.5006\n",
      "Epoch 81/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5941 - acc: 0.6118 - val_loss: 14.0521 - val_acc: 0.4217\n",
      "Epoch 82/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6146 - acc: 0.6002 - val_loss: 13.9068 - val_acc: 0.4922\n",
      "Epoch 83/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5772 - acc: 0.6121 - val_loss: 13.9549 - val_acc: 0.4576\n",
      "Epoch 84/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5769 - acc: 0.6045 - val_loss: 13.8980 - val_acc: 0.5125\n",
      "Epoch 85/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5690 - acc: 0.6077 - val_loss: 13.9588 - val_acc: 0.5090\n",
      "Epoch 86/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5605 - acc: 0.6151 - val_loss: 13.8943 - val_acc: 0.4946\n",
      "Epoch 87/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5419 - acc: 0.6192 - val_loss: 13.9897 - val_acc: 0.4851\n",
      "Epoch 88/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5565 - acc: 0.6121 - val_loss: 13.8393 - val_acc: 0.5173\n",
      "Epoch 89/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5322 - acc: 0.6180 - val_loss: 13.8830 - val_acc: 0.5448\n",
      "Epoch 90/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.5147 - acc: 0.6268 - val_loss: 13.8308 - val_acc: 0.5197\n",
      "Epoch 91/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5000 - acc: 0.6299 - val_loss: 13.8640 - val_acc: 0.5484\n",
      "Epoch 92/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4972 - acc: 0.6302 - val_loss: 13.8157 - val_acc: 0.5615\n",
      "Epoch 93/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4896 - acc: 0.6288 - val_loss: 13.8394 - val_acc: 0.5018\n",
      "Epoch 94/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4861 - acc: 0.6327 - val_loss: 13.8563 - val_acc: 0.5078\n",
      "Epoch 95/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4866 - acc: 0.6275 - val_loss: 13.8281 - val_acc: 0.5508\n",
      "Epoch 96/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4574 - acc: 0.6391 - val_loss: 13.8258 - val_acc: 0.5544\n",
      "Epoch 97/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4478 - acc: 0.6383 - val_loss: 13.8169 - val_acc: 0.5711\n",
      "Epoch 98/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4339 - acc: 0.6489 - val_loss: 13.8222 - val_acc: 0.5747\n",
      "Epoch 99/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4372 - acc: 0.6387 - val_loss: 13.8019 - val_acc: 0.5974\n",
      "Epoch 100/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4369 - acc: 0.6455 - val_loss: 13.7888 - val_acc: 0.5496\n",
      "Epoch 101/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4093 - acc: 0.6522 - val_loss: 13.7871 - val_acc: 0.5352\n",
      "Epoch 102/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4145 - acc: 0.6443 - val_loss: 13.8093 - val_acc: 0.5412\n",
      "Epoch 103/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4050 - acc: 0.6424 - val_loss: 13.7912 - val_acc: 0.5699\n",
      "Epoch 104/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3898 - acc: 0.6559 - val_loss: 13.7679 - val_acc: 0.5818\n",
      "Epoch 105/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3811 - acc: 0.6565 - val_loss: 13.7727 - val_acc: 0.5663\n",
      "Epoch 106/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.3807 - acc: 0.6556 - val_loss: 13.7959 - val_acc: 0.5675\n",
      "Epoch 107/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3896 - acc: 0.6507 - val_loss: 13.7704 - val_acc: 0.5950\n",
      "Epoch 108/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3698 - acc: 0.6606 - val_loss: 13.8632 - val_acc: 0.5281\n",
      "Epoch 109/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3685 - acc: 0.6556 - val_loss: 13.7463 - val_acc: 0.5783\n",
      "Epoch 110/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3448 - acc: 0.6631 - val_loss: 13.7388 - val_acc: 0.5830\n",
      "Epoch 111/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3327 - acc: 0.6692 - val_loss: 13.8142 - val_acc: 0.4922\n",
      "Epoch 112/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3327 - acc: 0.6617 - val_loss: 13.7891 - val_acc: 0.5556\n",
      "Epoch 113/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3231 - acc: 0.6706 - val_loss: 13.7445 - val_acc: 0.4982\n",
      "Epoch 114/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3102 - acc: 0.6696 - val_loss: 13.7271 - val_acc: 0.5544\n",
      "Epoch 115/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2960 - acc: 0.6715 - val_loss: 13.7544 - val_acc: 0.4970\n",
      "Epoch 116/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2925 - acc: 0.6694 - val_loss: 13.7281 - val_acc: 0.5771\n",
      "Epoch 117/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2812 - acc: 0.6760 - val_loss: 13.7172 - val_acc: 0.5556\n",
      "Epoch 118/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.2741 - acc: 0.6801 - val_loss: 13.6952 - val_acc: 0.5878\n",
      "Epoch 119/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2660 - acc: 0.6841 - val_loss: 13.7261 - val_acc: 0.5305\n",
      "Epoch 120/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2769 - acc: 0.6759 - val_loss: 13.7207 - val_acc: 0.5711\n",
      "Epoch 121/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2550 - acc: 0.6831 - val_loss: 13.7158 - val_acc: 0.5305\n",
      "Epoch 122/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2495 - acc: 0.6825 - val_loss: 13.6831 - val_acc: 0.5699\n",
      "Epoch 123/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2356 - acc: 0.6897 - val_loss: 13.7530 - val_acc: 0.5878\n",
      "Epoch 124/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2464 - acc: 0.6726 - val_loss: 13.6613 - val_acc: 0.5926\n",
      "Epoch 125/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2272 - acc: 0.6876 - val_loss: 13.6637 - val_acc: 0.5675\n",
      "Epoch 126/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2225 - acc: 0.6835 - val_loss: 13.6672 - val_acc: 0.6045\n",
      "Epoch 127/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2163 - acc: 0.6870 - val_loss: 13.6636 - val_acc: 0.5795\n",
      "Epoch 128/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1986 - acc: 0.6932 - val_loss: 13.6509 - val_acc: 0.5842\n",
      "Epoch 129/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1943 - acc: 0.6900 - val_loss: 13.6473 - val_acc: 0.5938\n",
      "Epoch 130/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1857 - acc: 0.6969 - val_loss: 13.6828 - val_acc: 0.6022\n",
      "Epoch 131/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1975 - acc: 0.6883 - val_loss: 13.6471 - val_acc: 0.6022\n",
      "Epoch 132/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1767 - acc: 0.6959 - val_loss: 13.6379 - val_acc: 0.5771\n",
      "Epoch 133/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.1536 - acc: 0.7013 - val_loss: 13.6554 - val_acc: 0.5293\n",
      "Epoch 134/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1499 - acc: 0.7024 - val_loss: 13.7161 - val_acc: 0.5173\n",
      "Epoch 135/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1782 - acc: 0.6862 - val_loss: 13.7901 - val_acc: 0.5305\n",
      "Epoch 136/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1772 - acc: 0.6903 - val_loss: 13.6401 - val_acc: 0.5866\n",
      "Epoch 137/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1374 - acc: 0.7003 - val_loss: 13.6074 - val_acc: 0.5914\n",
      "Epoch 138/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1177 - acc: 0.7064 - val_loss: 13.6248 - val_acc: 0.5854\n",
      "Epoch 139/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1005 - acc: 0.7161 - val_loss: 13.6059 - val_acc: 0.5962\n",
      "Epoch 140/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1004 - acc: 0.7101 - val_loss: 13.5823 - val_acc: 0.6177\n",
      "Epoch 141/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1113 - acc: 0.7062 - val_loss: 13.6229 - val_acc: 0.6022\n",
      "Epoch 142/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0858 - acc: 0.7109 - val_loss: 13.6238 - val_acc: 0.6045\n",
      "Epoch 143/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1219 - acc: 0.7054 - val_loss: 13.6403 - val_acc: 0.5699\n",
      "Epoch 144/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0754 - acc: 0.7120 - val_loss: 13.6249 - val_acc: 0.5866\n",
      "Epoch 145/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0781 - acc: 0.7092 - val_loss: 13.5817 - val_acc: 0.6153\n",
      "Epoch 146/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0771 - acc: 0.7171 - val_loss: 13.6348 - val_acc: 0.5532\n",
      "Epoch 147/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0678 - acc: 0.7156 - val_loss: 13.5611 - val_acc: 0.6033\n",
      "Epoch 148/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0446 - acc: 0.7204 - val_loss: 13.5878 - val_acc: 0.6033\n",
      "Epoch 149/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0452 - acc: 0.7219 - val_loss: 13.5528 - val_acc: 0.6225\n",
      "Epoch 150/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0443 - acc: 0.7190 - val_loss: 13.5692 - val_acc: 0.6213\n",
      "training time: 482.31098914146423\n",
      "800/816 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.6373\n",
      "\n",
      "Error Rate = 0.3627\n",
      "training time: 0.6374964714050293\n",
      "opening fold: 10\n",
      "Adding  fold1 New Features:  (869, 101, 60, 3)\n",
      "Adding  fold2 New Features:  (887, 101, 60, 3)\n",
      "Adding  fold3 New Features:  (925, 101, 60, 3)\n",
      "Adding  fold4 New Features:  (990, 101, 60, 3)\n",
      "Adding  fold5 New Features:  (936, 101, 60, 3)\n",
      "Adding  fold6 New Features:  (823, 101, 60, 3)\n",
      "Adding  fold7 New Features:  (838, 101, 60, 3)\n",
      "Adding  fold8 New Features:  (806, 101, 60, 3)\n",
      "Scaling time: 1.840364694595337\n",
      "Scaling time: 0.22175836563110352\n",
      "Scaling time: 0.23423242568969727\n",
      "training model...hold tight\n",
      "Train on 7074 samples, validate on 816 samples\n",
      "Epoch 1/150\n",
      "7074/7074 [==============================] - 10s - loss: 15.1356 - acc: 0.1176 - val_loss: 15.0698 - val_acc: 0.1495\n",
      "Epoch 2/150\n",
      "7074/7074 [==============================] - 3s - loss: 15.0614 - acc: 0.1459 - val_loss: 15.0007 - val_acc: 0.1961\n",
      "Epoch 3/150\n",
      "7074/7074 [==============================] - 3s - loss: 15.0015 - acc: 0.1726 - val_loss: 14.9374 - val_acc: 0.1814\n",
      "Epoch 4/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9516 - acc: 0.1918 - val_loss: 14.8697 - val_acc: 0.1900\n",
      "Epoch 5/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.9048 - acc: 0.2003 - val_loss: 14.8049 - val_acc: 0.2880\n",
      "Epoch 6/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8602 - acc: 0.2198 - val_loss: 14.7535 - val_acc: 0.3407\n",
      "Epoch 7/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.8166 - acc: 0.2485 - val_loss: 14.7027 - val_acc: 0.3824\n",
      "Epoch 8/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7808 - acc: 0.2576 - val_loss: 14.6470 - val_acc: 0.3689\n",
      "Epoch 9/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.7446 - acc: 0.2686 - val_loss: 14.5971 - val_acc: 0.3566\n",
      "Epoch 10/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6947 - acc: 0.2853 - val_loss: 14.5479 - val_acc: 0.3811\n",
      "Epoch 11/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6519 - acc: 0.2925 - val_loss: 14.5030 - val_acc: 0.3787\n",
      "Epoch 12/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.6257 - acc: 0.2977 - val_loss: 14.4610 - val_acc: 0.3652\n",
      "Epoch 13/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5875 - acc: 0.3097 - val_loss: 14.4289 - val_acc: 0.3860\n",
      "Epoch 14/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5564 - acc: 0.3202 - val_loss: 14.3928 - val_acc: 0.3738\n",
      "Epoch 15/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.5233 - acc: 0.3374 - val_loss: 14.3713 - val_acc: 0.3591\n",
      "Epoch 16/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4933 - acc: 0.3506 - val_loss: 14.3499 - val_acc: 0.3922\n",
      "Epoch 17/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4628 - acc: 0.3606 - val_loss: 14.3341 - val_acc: 0.3897\n",
      "Epoch 18/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4433 - acc: 0.3637 - val_loss: 14.3182 - val_acc: 0.4179\n",
      "Epoch 19/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.4093 - acc: 0.3895 - val_loss: 14.2997 - val_acc: 0.4179\n",
      "Epoch 20/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3950 - acc: 0.3907 - val_loss: 14.2842 - val_acc: 0.4056\n",
      "Epoch 21/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3594 - acc: 0.4104 - val_loss: 14.2607 - val_acc: 0.4240\n",
      "Epoch 22/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3359 - acc: 0.4074 - val_loss: 14.2462 - val_acc: 0.4105\n",
      "Epoch 23/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.3148 - acc: 0.4299 - val_loss: 14.2284 - val_acc: 0.4240\n",
      "Epoch 24/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2880 - acc: 0.4343 - val_loss: 14.2239 - val_acc: 0.4240\n",
      "Epoch 25/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2669 - acc: 0.4344 - val_loss: 14.2088 - val_acc: 0.3922\n",
      "Epoch 26/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2500 - acc: 0.4355 - val_loss: 14.1830 - val_acc: 0.4289\n",
      "Epoch 27/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2335 - acc: 0.4487 - val_loss: 14.1840 - val_acc: 0.4473\n",
      "Epoch 28/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.2094 - acc: 0.4590 - val_loss: 14.1444 - val_acc: 0.4203\n",
      "Epoch 29/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1852 - acc: 0.4625 - val_loss: 14.1697 - val_acc: 0.4375\n",
      "Epoch 30/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1585 - acc: 0.4656 - val_loss: 14.1530 - val_acc: 0.4608\n",
      "Epoch 31/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1598 - acc: 0.4628 - val_loss: 14.1325 - val_acc: 0.3946\n",
      "Epoch 32/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1397 - acc: 0.4645 - val_loss: 14.1332 - val_acc: 0.4167\n",
      "Epoch 33/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1268 - acc: 0.4700 - val_loss: 14.1009 - val_acc: 0.4240\n",
      "Epoch 34/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.1079 - acc: 0.4801 - val_loss: 14.1407 - val_acc: 0.4449\n",
      "Epoch 35/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0970 - acc: 0.4798 - val_loss: 14.1609 - val_acc: 0.4130\n",
      "Epoch 36/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0786 - acc: 0.4876 - val_loss: 14.0772 - val_acc: 0.4326\n",
      "Epoch 37/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0678 - acc: 0.4870 - val_loss: 14.0867 - val_acc: 0.4277\n",
      "Epoch 38/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0497 - acc: 0.4897 - val_loss: 14.0750 - val_acc: 0.4338\n",
      "Epoch 39/150\n",
      "7074/7074 [==============================] - 4s - loss: 14.0340 - acc: 0.4939 - val_loss: 14.0587 - val_acc: 0.4216\n",
      "Epoch 40/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0200 - acc: 0.5024 - val_loss: 14.0739 - val_acc: 0.4142\n",
      "Epoch 41/150\n",
      "7074/7074 [==============================] - 3s - loss: 14.0111 - acc: 0.4999 - val_loss: 14.0797 - val_acc: 0.4203\n",
      "Epoch 42/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9981 - acc: 0.5081 - val_loss: 14.0509 - val_acc: 0.4154\n",
      "Epoch 43/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9898 - acc: 0.5051 - val_loss: 14.0715 - val_acc: 0.4228\n",
      "Epoch 44/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9618 - acc: 0.5164 - val_loss: 14.1207 - val_acc: 0.4252\n",
      "Epoch 45/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9524 - acc: 0.5219 - val_loss: 14.0527 - val_acc: 0.4473\n",
      "Epoch 46/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9527 - acc: 0.5178 - val_loss: 14.1291 - val_acc: 0.4449\n",
      "Epoch 47/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9393 - acc: 0.5226 - val_loss: 14.0508 - val_acc: 0.4436\n",
      "Epoch 48/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9097 - acc: 0.5300 - val_loss: 14.0465 - val_acc: 0.4387\n",
      "Epoch 49/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9086 - acc: 0.5273 - val_loss: 14.0807 - val_acc: 0.4498\n",
      "Epoch 50/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.9028 - acc: 0.5259 - val_loss: 13.9958 - val_acc: 0.4424\n",
      "Epoch 51/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8958 - acc: 0.5246 - val_loss: 13.9924 - val_acc: 0.4498\n",
      "Epoch 52/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8757 - acc: 0.5373 - val_loss: 13.9884 - val_acc: 0.4534\n",
      "Epoch 53/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8658 - acc: 0.5370 - val_loss: 14.1640 - val_acc: 0.4044\n",
      "Epoch 54/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8630 - acc: 0.5375 - val_loss: 14.0105 - val_acc: 0.4216\n",
      "Epoch 55/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8481 - acc: 0.5389 - val_loss: 14.0205 - val_acc: 0.4118\n",
      "Epoch 56/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8360 - acc: 0.5481 - val_loss: 13.9387 - val_acc: 0.4424\n",
      "Epoch 57/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8314 - acc: 0.5471 - val_loss: 13.9381 - val_acc: 0.4449\n",
      "Epoch 58/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8185 - acc: 0.5471 - val_loss: 14.0486 - val_acc: 0.4044\n",
      "Epoch 59/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8129 - acc: 0.5485 - val_loss: 13.9522 - val_acc: 0.4277\n",
      "Epoch 60/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7927 - acc: 0.5527 - val_loss: 13.9480 - val_acc: 0.4289\n",
      "Epoch 61/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7780 - acc: 0.5625 - val_loss: 13.9450 - val_acc: 0.4167\n",
      "Epoch 62/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7698 - acc: 0.5640 - val_loss: 14.2785 - val_acc: 0.4154\n",
      "Epoch 63/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.8279 - acc: 0.5476 - val_loss: 13.9832 - val_acc: 0.4130\n",
      "Epoch 64/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7542 - acc: 0.5589 - val_loss: 13.9359 - val_acc: 0.4265\n",
      "Epoch 65/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7440 - acc: 0.5687 - val_loss: 13.9401 - val_acc: 0.4216\n",
      "Epoch 66/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7306 - acc: 0.5785 - val_loss: 13.9006 - val_acc: 0.4265\n",
      "Epoch 67/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7204 - acc: 0.5749 - val_loss: 13.8842 - val_acc: 0.4400\n",
      "Epoch 68/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.7117 - acc: 0.5782 - val_loss: 13.9305 - val_acc: 0.4338\n",
      "Epoch 69/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.7063 - acc: 0.5755 - val_loss: 13.9698 - val_acc: 0.4363\n",
      "Epoch 70/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6942 - acc: 0.5843 - val_loss: 13.8610 - val_acc: 0.4498\n",
      "Epoch 71/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6850 - acc: 0.5833 - val_loss: 13.9130 - val_acc: 0.4338\n",
      "Epoch 72/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6644 - acc: 0.5882 - val_loss: 13.8844 - val_acc: 0.4559\n",
      "Epoch 73/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6614 - acc: 0.5803 - val_loss: 13.8377 - val_acc: 0.4387\n",
      "Epoch 74/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6668 - acc: 0.5881 - val_loss: 13.9303 - val_acc: 0.4449\n",
      "Epoch 75/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6502 - acc: 0.5902 - val_loss: 13.8218 - val_acc: 0.4669\n",
      "Epoch 76/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6284 - acc: 0.5977 - val_loss: 13.9125 - val_acc: 0.4510\n",
      "Epoch 77/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6265 - acc: 0.5982 - val_loss: 13.8929 - val_acc: 0.4534\n",
      "Epoch 78/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6200 - acc: 0.5992 - val_loss: 13.9106 - val_acc: 0.4461\n",
      "Epoch 79/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.6083 - acc: 0.5984 - val_loss: 13.8338 - val_acc: 0.4755\n",
      "Epoch 80/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5973 - acc: 0.6043 - val_loss: 13.7790 - val_acc: 0.4730\n",
      "Epoch 81/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5819 - acc: 0.6080 - val_loss: 13.7604 - val_acc: 0.5049\n",
      "Epoch 82/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5879 - acc: 0.6019 - val_loss: 13.7710 - val_acc: 0.5245\n",
      "Epoch 83/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5681 - acc: 0.6115 - val_loss: 13.8370 - val_acc: 0.4779\n",
      "Epoch 84/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5641 - acc: 0.6132 - val_loss: 13.8082 - val_acc: 0.4963\n",
      "Epoch 85/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5577 - acc: 0.6103 - val_loss: 13.7667 - val_acc: 0.4804\n",
      "Epoch 86/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.5425 - acc: 0.6182 - val_loss: 13.8600 - val_acc: 0.4632\n",
      "Epoch 87/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5370 - acc: 0.6166 - val_loss: 13.7792 - val_acc: 0.4816\n",
      "Epoch 88/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.5272 - acc: 0.6214 - val_loss: 13.8790 - val_acc: 0.4792\n",
      "Epoch 89/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5173 - acc: 0.6254 - val_loss: 13.7680 - val_acc: 0.4902\n",
      "Epoch 90/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5017 - acc: 0.6274 - val_loss: 13.8214 - val_acc: 0.4804\n",
      "Epoch 91/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.5032 - acc: 0.6220 - val_loss: 13.7888 - val_acc: 0.5159\n",
      "Epoch 92/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4964 - acc: 0.6281 - val_loss: 13.8653 - val_acc: 0.4828\n",
      "Epoch 93/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4877 - acc: 0.6293 - val_loss: 13.7686 - val_acc: 0.4865\n",
      "Epoch 94/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4610 - acc: 0.6445 - val_loss: 13.7506 - val_acc: 0.4951\n",
      "Epoch 95/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4614 - acc: 0.6336 - val_loss: 13.7505 - val_acc: 0.4914\n",
      "Epoch 96/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4588 - acc: 0.6356 - val_loss: 13.7347 - val_acc: 0.5025\n",
      "Epoch 97/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4579 - acc: 0.6422 - val_loss: 13.7308 - val_acc: 0.4988\n",
      "Epoch 98/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4378 - acc: 0.6467 - val_loss: 13.7515 - val_acc: 0.4926\n",
      "Epoch 99/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4328 - acc: 0.6460 - val_loss: 13.6764 - val_acc: 0.5404\n",
      "Epoch 100/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4293 - acc: 0.6426 - val_loss: 13.6593 - val_acc: 0.5453\n",
      "Epoch 101/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4264 - acc: 0.6404 - val_loss: 14.1093 - val_acc: 0.4730\n",
      "Epoch 102/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4763 - acc: 0.6248 - val_loss: 13.6780 - val_acc: 0.5208\n",
      "Epoch 103/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4042 - acc: 0.6518 - val_loss: 13.7182 - val_acc: 0.4926\n",
      "Epoch 104/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.3832 - acc: 0.6573 - val_loss: 13.7327 - val_acc: 0.5110\n",
      "Epoch 105/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3859 - acc: 0.6511 - val_loss: 13.8098 - val_acc: 0.4988\n",
      "Epoch 106/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3800 - acc: 0.6525 - val_loss: 13.8429 - val_acc: 0.5000\n",
      "Epoch 107/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3856 - acc: 0.6489 - val_loss: 13.7835 - val_acc: 0.5012\n",
      "Epoch 108/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3712 - acc: 0.6568 - val_loss: 13.7129 - val_acc: 0.5086\n",
      "Epoch 109/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3473 - acc: 0.6667 - val_loss: 13.7377 - val_acc: 0.5159\n",
      "Epoch 110/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3488 - acc: 0.6645 - val_loss: 13.7208 - val_acc: 0.5049\n",
      "Epoch 111/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3350 - acc: 0.6589 - val_loss: 13.8062 - val_acc: 0.5049\n",
      "Epoch 112/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3363 - acc: 0.6621 - val_loss: 13.6478 - val_acc: 0.5576\n",
      "Epoch 113/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3112 - acc: 0.6710 - val_loss: 14.1546 - val_acc: 0.4743\n",
      "Epoch 114/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.4845 - acc: 0.6173 - val_loss: 13.6364 - val_acc: 0.5515\n",
      "Epoch 115/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3122 - acc: 0.6644 - val_loss: 13.6344 - val_acc: 0.5368\n",
      "Epoch 116/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.3011 - acc: 0.6729 - val_loss: 13.6473 - val_acc: 0.5564\n",
      "Epoch 117/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2950 - acc: 0.6701 - val_loss: 13.7282 - val_acc: 0.5208\n",
      "Epoch 118/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2863 - acc: 0.6747 - val_loss: 13.7614 - val_acc: 0.5061\n",
      "Epoch 119/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2755 - acc: 0.6761 - val_loss: 13.6699 - val_acc: 0.5490\n",
      "Epoch 120/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2753 - acc: 0.6740 - val_loss: 13.5894 - val_acc: 0.5723\n",
      "Epoch 121/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2697 - acc: 0.6722 - val_loss: 13.6896 - val_acc: 0.5306\n",
      "Epoch 122/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2564 - acc: 0.6787 - val_loss: 13.6347 - val_acc: 0.5637\n",
      "Epoch 123/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2332 - acc: 0.6879 - val_loss: 13.6005 - val_acc: 0.5686\n",
      "Epoch 124/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2375 - acc: 0.6798 - val_loss: 13.6322 - val_acc: 0.5588\n",
      "Epoch 125/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2192 - acc: 0.6880 - val_loss: 13.6158 - val_acc: 0.5650\n",
      "Epoch 126/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2145 - acc: 0.6877 - val_loss: 13.6702 - val_acc: 0.5355\n",
      "Epoch 127/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2129 - acc: 0.6882 - val_loss: 13.6925 - val_acc: 0.5453\n",
      "Epoch 128/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1998 - acc: 0.6904 - val_loss: 13.6425 - val_acc: 0.5674\n",
      "Epoch 129/150\n",
      "7074/7074 [==============================] - 4s - loss: 13.1917 - acc: 0.6979 - val_loss: 13.5799 - val_acc: 0.5821\n",
      "Epoch 130/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2039 - acc: 0.6890 - val_loss: 13.5690 - val_acc: 0.6078\n",
      "Epoch 131/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1931 - acc: 0.6879 - val_loss: 13.6035 - val_acc: 0.5674\n",
      "Epoch 132/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1663 - acc: 0.6956 - val_loss: 13.6082 - val_acc: 0.5772\n",
      "Epoch 133/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1674 - acc: 0.6952 - val_loss: 13.6642 - val_acc: 0.5343\n",
      "Epoch 134/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1630 - acc: 0.6937 - val_loss: 13.5709 - val_acc: 0.5882\n",
      "Epoch 135/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1516 - acc: 0.6995 - val_loss: 13.5748 - val_acc: 0.5882\n",
      "Epoch 136/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1405 - acc: 0.6980 - val_loss: 13.6381 - val_acc: 0.5478\n",
      "Epoch 137/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1341 - acc: 0.7048 - val_loss: 13.6012 - val_acc: 0.5821\n",
      "Epoch 138/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1416 - acc: 0.7012 - val_loss: 13.5821 - val_acc: 0.5882\n",
      "Epoch 139/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1198 - acc: 0.7024 - val_loss: 13.5991 - val_acc: 0.5907\n",
      "Epoch 140/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1227 - acc: 0.7027 - val_loss: 13.5897 - val_acc: 0.6054\n",
      "Epoch 141/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.1092 - acc: 0.7031 - val_loss: 13.6138 - val_acc: 0.5944\n",
      "Epoch 142/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0984 - acc: 0.7150 - val_loss: 13.8952 - val_acc: 0.4902\n",
      "Epoch 143/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.2223 - acc: 0.6644 - val_loss: 13.5943 - val_acc: 0.5833\n",
      "Epoch 144/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0975 - acc: 0.7029 - val_loss: 13.6222 - val_acc: 0.5895\n",
      "Epoch 145/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0750 - acc: 0.7166 - val_loss: 13.6767 - val_acc: 0.5319\n",
      "Epoch 146/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0888 - acc: 0.7115 - val_loss: 13.5874 - val_acc: 0.5968\n",
      "Epoch 147/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0756 - acc: 0.7062 - val_loss: 13.5509 - val_acc: 0.5968\n",
      "Epoch 148/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0583 - acc: 0.7167 - val_loss: 13.6569 - val_acc: 0.5809\n",
      "Epoch 149/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0791 - acc: 0.7016 - val_loss: 13.5624 - val_acc: 0.5846\n",
      "Epoch 150/150\n",
      "7074/7074 [==============================] - 3s - loss: 13.0462 - acc: 0.7208 - val_loss: 13.5678 - val_acc: 0.6017\n",
      "training time: 480.2168116569519\n",
      "800/837 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.5830\n",
      "\n",
      "Error Rate = 0.4170\n",
      "training time: 0.6426217555999756\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "acc_list = []\n",
    "\n",
    "for test_fold in range(1, 11):\n",
    "    print('opening fold:', str(test_fold))\n",
    "    keras.backend.clear_session()\n",
    "    model = build_model()\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True), metrics=['accuracy'])\n",
    "    train_x, train_y, valid_x, valid_y, test_x, test_y = load_all_folds(test_fold)\n",
    "\n",
    "    # for each channel, compute scaling factor\n",
    "    scaler_list = []\n",
    "    (n_clips, n_time, n_freq, n_channel) = train_x.shape\n",
    "\n",
    "    for channel in range(n_channel):\n",
    "        t1 = time.time()\n",
    "        xtrain_2d = train_x[:, :, :, channel].reshape((n_clips * n_time, n_freq))\n",
    "        scaler = sklearn.preprocessing.StandardScaler().fit(xtrain_2d)\n",
    "        # print(\"Channel %d Mean: %s\" % (channel, scaler.mean_,))\n",
    "        # print(\"Channel %d Std: %s\" % (channel, scaler.scale_,))\n",
    "        # print(\"Calculating scaler time: %s\" % (time.time() - t1,))\n",
    "        scaler_list += [scaler]\n",
    "\n",
    "    train_x = do_scale(train_x)\n",
    "    valid_x = do_scale(valid_x)\n",
    "    test_x = do_scale(test_x)\n",
    "\n",
    "    # use a batch size to fully utilize GPU power\n",
    "    t1 = time.time()\n",
    "    print(\"training model...hold tight\")\n",
    "    history = model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=callbacks,\n",
    "                        batch_size=1000,\n",
    "                        epochs=150)\n",
    "    print(\"training time: %s\" % (time.time() - t1,))\n",
    "    \n",
    "    t2 = time.time()\n",
    "    acc = evaluate(model, test_x, test_y)\n",
    "    print(\"training time: %s\" % (time.time() - t2,))\n",
    "\n",
    "    acc_list += [acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc mean 0.5638 acc std 0.0911\n"
     ]
    }
   ],
   "source": [
    "acc_array = np.array(acc_list)\n",
    "print(\"acc mean %.4f acc std %.4f\" % (acc_array.mean(), acc_array.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History keys: dict_keys(['acc', 'val_loss', 'val_acc', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAHzCAYAAADy2UoqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMiQk3FXbfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc55d1abc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "print(\"History keys:\", (history.history.keys()))\n",
    "# summarise history for training and validation set accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarise history for training and validation set loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss', fontsize = 'large')\n",
    "plt.xlabel('epoch', fontsize = 'large' )\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py:913: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/837 [===========================>..] - ETA: 0s\n",
      "Accuracy = 0.5830\n",
      "\n",
      "Error Rate = 0.4170\n",
      "Showing Confusion Matrix\n",
      "                    air conditioner            horn        children             dog           drill          engine             gun          hammer           siren           music \n",
      "    air conditioner              67               0               0               0               0               0               0              33               0               0 \n",
      "               horn               1              11               5               7               1               0               1               4               1               2 \n",
      "           children               2               5              63              11               2               2               0               0               8               7 \n",
      "                dog               2               7              12              67               3               0               0               0               5               4 \n",
      "              drill               0               5              10               4              45               9               1              25               1               0 \n",
      "             engine              13               0               1               2              12              48               0              16               0               1 \n",
      "                gun               0               3               0               2               1               0              26               0               0               0 \n",
      "             hammer               0               5               0               0              28               1               0              62               0               0 \n",
      "              siren              11               2              22               9               1               3               0               0              35               0 \n",
      "              music               1               0              20               0               8               0               0               3               4              64 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc54946c240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAHRCAYAAADAAuC2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhh9hzoPikb8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc55c7c3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# run a separate instance of model evaluation on test set\n",
    "# to create a single confusion matrix\n",
    "\n",
    "acc = evaluate(model, test_x, test_y) \n",
    "\n",
    "labels = [\"air conditioner\", \"horn\", \"children\", \"dog\", \"drill\", \"engine\", \"gun\", \"hammer\", \"siren\", \"music\"]\n",
    "print(\"Showing Confusion Matrix\")\n",
    "y_prob = model.predict(test_x, verbose=0)\n",
    "y_pred = np.argmax(y_prob, axis=-1)\n",
    "y_true = np.argmax(test_y, 1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=' ')\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=' ')\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}s\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=' ')\n",
    "        print()\n",
    "\n",
    "print_cm(cm, labels)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, labels, labels)\n",
    "plt.figure(figsize=(16, 8))\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14}, fmt='g', linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
